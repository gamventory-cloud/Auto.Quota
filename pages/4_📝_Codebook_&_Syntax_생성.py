import streamlit as st
import pandas as pd
import sys
import os
import re
import io
import textwrap
import collections
from collections import Counter

# ì›Œë“œ/ì—‘ì…€ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from docx import Document
    from docx.document import Document as _Document
    from docx.oxml.text.paragraph import CT_P
    from docx.oxml.table import CT_Tbl
    from docx.table import _Cell, Table
    from docx.text.paragraph import Paragraph
    from docx.oxml.ns import qn 
    from openpyxl.styles import Font, PatternFill, Alignment
except ImportError:
    st.error("í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. requirements.txtì— 'python-docx'ì™€ 'openpyxl'ì„ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# 1. ìƒìœ„ í´ë”ì˜ utils.pyë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import utils

# 2. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ì„¤ë¬¸ì§€ ì½”ë“œë¶ ìƒì„±", layout="wide")

# 3. ë¹„ë°€ë²ˆí˜¸ ì ê¸ˆ
if not utils.check_password():
    st.stop()

st.title("ğŸ“ ì„¤ë¬¸ì§€ ì½ê¸° & ì½”ë“œë¶/ì‹ í…ìŠ¤ ìë™ ìƒì„± (AHP & Full Logic)")

# ==============================================================================
# [Part 0] ë™ê·¸ë¼ë¯¸ ìˆ«ì ë§¤í•‘ (ì¶”ê°€ë¨)
# ==============================================================================
CIRCLE_MAP = {'â‘ ':'1','â‘¡':'2','â‘¢':'3','â‘£':'4','â‘¤':'5','â‘¥':'6','â‘¦':'7','â‘§':'8','â‘¨':'9','â‘©':'10'}

# ==============================================================================
# [Part 1] í•µì‹¬ íŒŒì‹± í•¨ìˆ˜
# ==============================================================================

def iter_block_items(parent):
    if isinstance(parent, _Document):
        parent_elm = parent.element.body
    elif isinstance(parent, _Cell):
        parent_elm = parent._tc
    else:
        raise ValueError("iter_block_items: ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶€ëª¨ ê°ì²´ì…ë‹ˆë‹¤.")

    for child in parent_elm.iterchildren():
        if isinstance(child, CT_P):
            yield Paragraph(child, parent)
        elif isinstance(child, CT_Tbl):
            yield Table(child, parent)

# ==============================================================================
# [Part 2] ìœ í‹¸ë¦¬í‹° ë° í…ìŠ¤íŠ¸ ì²˜ë¦¬ í•¨ìˆ˜
# ==============================================================================

def clean_empty_parentheses(text):
    if not text: return text
    return re.sub(r"\(\s*\)", "", text).strip()

def clean_header_text(text):
    text = text.strip()
    # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì ëŒ€ì‘
    match = re.search(r"([â‘ -â‘©]|\d+)", text)
    if match:
        raw_code = match.group(1)
        code = CIRCLE_MAP.get(raw_code, raw_code)
        label = re.sub(r"[\(\[\{\<]?\s*" + re.escape(raw_code) + r"\s*[\)\]\}\>]?[\.]?", "", text).strip()
        if not label: label = f"{code}ì "
        return f"{code}={label}"
    return f"{text}={text}"

def extract_options_from_line(text):
    # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì í¬í•¨ íŒ¨í„´
    pattern = re.compile(r"([â‘ -â‘©]|(?:\d+|[a-zA-Z])[\)\.])")
    matches = list(pattern.finditer(text))
    if not matches:
        return []
    results = []
    for i in range(len(matches)):
        start = matches[i].start()
        end = matches[i+1].start() if i + 1 < len(matches) else len(text)
        item = text[start:end].strip()
        item = clean_empty_parentheses(item)
        if item:
            results.append(item)
    return results

def summarize_label_regex(text):
    if not text: return ""
    text = re.sub(r"\(PROG.*?\)", "", text, flags=re.IGNORECASE)
    text = re.sub(r"\[PROG.*?\]", "", text, flags=re.IGNORECASE)
    text = re.sub(r"\(.*?(ì…ë ¥|ê¸°ì…|ë²”ìœ„|ì„ íƒ).*?\)", "", text)
    text = re.sub(r"\[.*?(ì„ íƒ|ê¸°ì…|ì‘ë‹µ).*?\]", "", text)
    text = re.sub(r"^ë‹¤ìŒì€.*?ì§ˆë¬¸ì…ë‹ˆë‹¤\.?", "", text).strip()
    text = re.sub(r"^ë‹¤ìŒ.*?ëŒ€í•´.*?(ì„ íƒ|ì‘ë‹µ).*?ì£¼ì‹­ì‹œì˜¤\.?", "", text).strip()
    text = text.replace("ê·€í•˜ì˜ ", "").replace("ê·€í•˜ê»˜ì„œëŠ” ", "").replace("ê·€ ëŒì˜ ", "")
    text = text.replace("ì‘ë‹µì ë³¸ì¸ì˜ ", "").replace("í‰ì†Œ ", "")
    patterns = [
        r"ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ\?*$", r"ëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ\?*$", r"ëŠ” ë¬´ì—‡ì¸ê°€ìš”\?*$",
        r"ì„ ì„ íƒí•´ ì£¼ì‹­ì‹œì˜¤\.?$", r"ë¥¼ ì„ íƒí•´ ì£¼ì‹­ì‹œì˜¤\.?$",
        r"ì„ ì„ íƒí•´ ì£¼ì„¸ìš”\.?$", r"ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”\.?$",
        r"ì„ ê¸°ì…í•´ ì£¼ì‹­ì‹œì˜¤\.?$", r"ë¥¼ ê¸°ì…í•´ ì£¼ì‹­ì‹œì˜¤\.?$",
        r"ì„ ì…ë ¥í•˜ì—¬ ì£¼ì‹­ì‹œì˜¤\.?$", r"ë¥¼ ì…ë ¥í•˜ì—¬ ì£¼ì‹­ì‹œì˜¤\.?$",
        r"ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ì‹­ë‹ˆê¹Œ\?*$",
        r"ì •ë„ì…ë‹ˆê¹Œ\?*$", r"ë˜ì‹­ë‹ˆê¹Œ\?*$", r"ì¸ê°€ìš”\?*$", r"ìˆìŠµë‹ˆê¹Œ\?*$"
    ]
    for pat in patterns: text = re.sub(pat, "", text)
    replacements = { "ë§Œì¡±í•˜ëŠ” ì •ë„": "ë§Œì¡±ë„", "ì–¼ë§ˆë‚˜ ë§Œì¡±í•˜ì‹­ë‹ˆê¹Œ": "ë§Œì¡±ë„", "ì–¼ë§ˆë‚˜ ìì£¼": "ë¹ˆë„", "ì´ìœ ëŠ” ë¬´ì—‡": "ì´ìœ ", "ìƒê°ë‚˜ëŠ” ì´ë¯¸ì§€": "ì´ë¯¸ì§€", "êµ¬ì…í•œ ì ì´": "êµ¬ì… ê²½í—˜", "ì´ìš©í•œ ê²½í—˜": "ì´ìš© ê²½í—˜", "ì–´ë””ì…ë‹ˆê¹Œ": "ì¥ì†Œ", "ëˆ„êµ¬ì…ë‹ˆê¹Œ": "ëŒ€ìƒ" }
    for old, new in replacements.items(): 
        if old in text: text = text.replace(old, new)
    text = text.strip(); text = re.sub(r"\?+$", "", text); text = re.sub(r"\.$", "", text)
    return text.strip()

def check_section_header(text, current_prefix):
    clean_text = text.strip()
    new_prefix = current_prefix
    if re.search(r"Screening", clean_text, re.IGNORECASE) or "ìŠ¤í¬ë¦¬ë‹" in clean_text:
        new_prefix = "SQ"
    elif re.search(r"Part\s*([A-Z])", clean_text, re.IGNORECASE):
        match = re.search(r"Part\s*([A-Z])", clean_text, re.IGNORECASE)
        new_prefix = match.group(1).upper()
    elif re.search(r"^DQ", clean_text, re.IGNORECASE) or "ì¸êµ¬ í†µê³„" in clean_text:
        new_prefix = "DQ"
    return new_prefix

# ==============================================================================
# [Part 3] í…Œì´ë¸” ì¶”ì¶œê¸° (Extractors)
# ==============================================================================

# [NEW] AHP ì´ì›ë¹„êµ í…Œì´ë¸” ì „ìš© ì¶”ì¶œê¸° (Q11 ë“± ëŒ€ì‘)
def extract_ahp_table(table, current_var):
    rows = table.rows
    if len(rows) < 2: return None
    
    # í—¤ë” ë¶„ì„: Aì™€ Bê°€ ìˆê³  ì²™ë„(9, 7, 5...)ê°€ ìˆëŠ”ì§€ í™•ì¸
    header_text = " ".join([c.text for c in rows[0].cells])
    if not ("A" in header_text and "B" in header_text and ("ì¤‘ìš”" in header_text or "9" in header_text)):
        return None

    # AHP 9ì  ì²™ë„ ì •ì˜
    ahp_scale_pairs = [
        "1=A ì ˆëŒ€ ì¤‘ìš”(9)", "2=A ë§¤ìš° ì¤‘ìš”(7)", "3=A ìƒë‹¹íˆ ì¤‘ìš”(5)", "4=A ì•½ê°„ ì¤‘ìš”(3)", 
        "5=Aì™€ B ë™ë“±(1)", 
        "6=B ì•½ê°„ ì¤‘ìš”(3)", "7=B ìƒë‹¹íˆ ì¤‘ìš”(5)", "8=B ë§¤ìš° ì¤‘ìš”(7)", "9=B ì ˆëŒ€ ì¤‘ìš”(9)"
    ]
    scale_str = "\n".join(ahp_scale_pairs)
    
    extracted_entries = []
    
    for i, row in enumerate(rows[1:]):
        cells = row.cells
        if len(cells) < 3: continue
        
        # ì¢Œì¸¡ í•­ëª©(A)ê³¼ ìš°ì¸¡ í•­ëª©(B) ì¶”ì¶œ
        # ë³‘í•©ëœ ì…€ì´ë‚˜ ë¹ˆ ì…€ì„ ê±´ë„ˆë›°ê³  í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ì²«/ë§ˆì§€ë§‰ ì…€ ì°¾ê¸°
        item_a = cells[0].text.strip()
        item_b = cells[-1].text.strip()
        
        # ì¤‘ê°„ì— ìˆ«ìê°€ ì—†ê±°ë‚˜ A, Bê°€ ë¹„ì–´ìˆìœ¼ë©´ ìœ íš¨í•œ í–‰ì´ ì•„ë‹˜
        if not item_a or not item_b or item_a == item_b: 
            continue
            
        var_name = f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}"
        label = f"[{current_var['ë³€ìˆ˜ëª…']}] {item_a} vs {item_b}"
        
        extracted_entries.append({
            "ë³€ìˆ˜ëª…": var_name,
            "ì§ˆë¬¸ ë‚´ìš©": label,
            "ë³´ê¸° ê°’": scale_str,
            "ìœ í˜•": "Scale"
        })
        
    return extracted_entries

def check_mixed_text_input(entry):
    if entry["ìœ í˜•"] != "Single" and entry["ìœ í˜•"] != "Open": return [entry]
    full_text = entry["ì§ˆë¬¸ ë‚´ìš©"]
    if "ë³´ê¸°_list" in entry: full_text += " " + " ".join(entry["ë³´ê¸°_list"])
    pattern = re.compile(r"\([^)]*?ì…ë ¥[^)]*?\)\s*([ê°€-í£a-zA-Z]+)")
    matches = list(pattern.finditer(full_text))
    if len(matches) < 2: return [entry]
    new_entries = []
    base_var = entry["ë³€ìˆ˜ëª…"]; base_label = entry["ì§ˆë¬¸ ë‚´ìš©"]
    clean_base = re.sub(r"\([^)]*?ì…ë ¥[^)]*?\)\s*[ê°€-í£a-zA-Z]*", "", base_label).strip()
    for i, match in enumerate(matches):
        unit = match.group(1)
        new_entries.append({ "ë³€ìˆ˜ëª…": f"{base_var}_{i+1}", "ì§ˆë¬¸ ë‚´ìš©": f"[{base_var}] {clean_base} ({unit})", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
    return new_entries

def extract_embedded_open_entry(entry):
    if entry["ìœ í˜•"] not in ["Single", "Multi"]: return []
    vals_str = entry.get("ë³´ê¸° ê°’", "")
    if not vals_str: return []
    new_entries = []
    lines = vals_str.split('\n')
    normalized_lines = [line.replace("ï¼ˆ", "(").replace("ï¼‰", ")").replace("[", "(").replace("]", ")") for line in lines]
    for line in normalized_lines:
        if "=" not in line: continue
        parts = line.split("=", 1)
        code = parts[0].strip(); label = parts[1].strip()
        if "(" in label and ")" in label:
            paren_content_match = re.search(r"\(([^)]+)\)", label)
            if paren_content_match:
                content = paren_content_match.group(1)
                if any(k in content for k in ["ì…ë ¥", "ê¸°ì…", "ë²”ìœ„", "êµ¬ì²´ì ", "ì‘ì„±"]):
                    unit = ""
                    suffix_match = re.search(r"\)[^)]*$", label)
                    if suffix_match:
                        suffix = suffix_match.group(0).replace(")", "").strip()
                        if suffix: unit = f" ({suffix})"
                    new_entries.append({
                        "ë³€ìˆ˜ëª…": f"{entry['ë³€ìˆ˜ëª…']}_{code}",
                        "ì§ˆë¬¸ ë‚´ìš©": f"[{entry['ë³€ìˆ˜ëª…']}] {code}ë²ˆ ì„ íƒ ì‹œ êµ¬ì²´ì  ë‚´ìš©{unit}",
                        "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)" if "ë²”ìœ„" in content or "ìˆ˜" in content or "ëª…" in suffix else "(ì£¼ê´€ì‹)",
                        "ìœ í˜•": "Open"
                    })
    return new_entries

# ë³€ìˆ˜ ë§¤í•‘ í…Œì´ë¸” (SQ8, SQ8-1, SQ10-1 ë“±)
def extract_mapped_option_table(table, extracted_data, variable_map, current_entry):
    rows = table.rows
    if len(rows) < 2: return None
    header_cells = [c.text.strip() for c in rows[0].cells]
    
    option_col_idx = -1
    for i, h in enumerate(header_cells):
        if "ë³´ê¸°" in h: option_col_idx = i; break
    if option_col_idx == -1: return None
    
    multi_keywords = ["ë³µìˆ˜ì‘ë‹µ", "ëª¨ë‘ ì„ íƒ", "ì¤‘ë³µì„ íƒ", "ì¤‘ë³µ ì‘ë‹µ", "ëª¨ë‘ ê³¨ë¼", "ì¤‘ë³µ ì„ íƒ", "ë³µìˆ˜ ì„ íƒ", "ëª¨ë‘ ì²´í¬"]

    target_vars = {} 
    existing_vars = list(variable_map.keys())
    current_var_name = current_entry["ë³€ìˆ˜ëª…"] if current_entry else None
    if current_var_name: existing_vars.append(current_var_name)
    
    def normalize_name(n): return re.sub(r"[^a-zA-Z0-9]", "", n).upper()

    for i, h in enumerate(header_cells):
        if i == option_col_idx: continue
        norm_h = normalize_name(h)
        if not norm_h: continue
        for var_name in existing_vars:
            norm_v = normalize_name(var_name)
            if norm_h == norm_v or (len(norm_h) > 2 and norm_h in norm_v):
                target_vars[i] = var_name
                break
                
    if not target_vars: return None
    
    var_options_map = {v: [] for v in target_vars.values()} 
    
    for row in rows[1:]:
        if len(row.cells) <= option_col_idx: continue
        opt_text = row.cells[option_col_idx].text.strip()
        if not opt_text: continue
        
        code = ""; val = ""
        # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì ëŒ€ì‘
        match = re.match(r"^([â‘ -â‘©]|\d+|[a-zA-Z])[\)\.]?\s*(.*)", opt_text)
        if match:
            raw = match.group(1).replace(')','').replace('.','') 
            code = CIRCLE_MAP.get(raw, raw)
            val = match.group(2).strip()
        else: val = opt_text
            
        for col_idx, var_name in target_vars.items():
            if len(row.cells) > col_idx:
                check_val = row.cells[col_idx].text.strip()
                if check_val:
                    final_code = check_val if check_val.isdigit() else code
                    if final_code: var_options_map[var_name].append((final_code, val))

    updates = 0
    vars_to_process = [v for v in var_options_map.keys() if v in variable_map]
    vars_to_process.sort(key=lambda x: variable_map[x], reverse=True) 
    
    for var_name in vars_to_process:
        opts_tuples = var_options_map[var_name] 
        if not opts_tuples: continue
        idx = variable_map[var_name]
        original_item = extracted_data[idx]
        is_multi = any(k in original_item["ì§ˆë¬¸ ë‚´ìš©"] for k in multi_keywords)
        
        if is_multi:
            new_items = []
            full_opts_str = "\n".join([f"{c}={l}" for c, l in opts_tuples])
            for c, l in opts_tuples:
                new_items.append({ "ë³€ìˆ˜ëª…": f"{var_name}_{c}", "ì§ˆë¬¸ ë‚´ìš©": f"{original_item['ì§ˆë¬¸ ë‚´ìš©']} ({l})", "ë³´ê¸° ê°’": full_opts_str, "ìœ í˜•": "Multi" })
            del extracted_data[idx]
            for item in reversed(new_items): extracted_data.insert(idx, item)
            updates += 1
        else:
            opts_str = "\n".join([f"{c}={l}" for c, l in opts_tuples])
            extracted_data[idx]["ë³´ê¸° ê°’"] = opts_str
            updates += 1

    if current_entry and current_entry["ë³€ìˆ˜ëª…"] in var_options_map:
        opts_tuples = var_options_map[current_entry["ë³€ìˆ˜ëª…"]]
        if opts_tuples:
            if "ë³´ê¸°_list" not in current_entry: current_entry["ë³´ê¸°_list"] = []
            opts_str = "\n".join([f"{c}={l}" for c, l in opts_tuples])
            current_entry["ë³´ê¸° ê°’"] = opts_str
            for c, l in opts_tuples: current_entry["ë³´ê¸°_list"].append(f"{c}) {l}")
            updates += 1
                
    if updates > 0:
        new_map = {}
        for i, item in enumerate(extracted_data): new_map[item['ë³€ìˆ˜ëª…']] = i
        variable_map.clear(); variable_map.update(new_map)
    return updates > 0

def extract_unit_input_table(table, current_var):
    extracted = []
    unit_keywords = ["ëª…", "ì„¸", "ê°œ", "ì›", "ë…„", "ì›”"]
    unit_col_idx = -1
    for i, cell in enumerate(table.rows[0].cells):
        if any(u in cell.text for u in unit_keywords): unit_col_idx = i; break
    if unit_col_idx == -1 and len(table.rows) > 1:
         for i, cell in enumerate(table.rows[-1].cells):
            if any(u in cell.text for u in unit_keywords): unit_col_idx = i; break
    label_col_idx = 0
    if len(table.columns) > 1:
        if unit_col_idx == 1: label_col_idx = 0
        else: label_col_idx = 1
    for i, row in enumerate(table.rows):
        cells = row.cells
        if len(cells) <= label_col_idx: continue
        row_label = cells[label_col_idx].text.strip()
        if row_label.isdigit() and len(cells) > label_col_idx + 1: row_label = cells[label_col_idx + 1].text.strip()
        if not row_label or "ì…ë ¥" in row_label: continue
        unit = ""
        if unit_col_idx != -1 and len(cells) > unit_col_idx:
            unit_text = cells[unit_col_idx].text.strip()
            if unit_text in unit_keywords: unit = f" ({unit_text})"
        extracted.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {row_label}{unit}", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
    return extracted

def extract_child_demographics_table(table, current_var):
    headers = [c.text.strip() for c in table.rows[0].cells]
    gender_col_idx = -1; birth_col_idx = -1
    for idx, h in enumerate(headers):
        if "ì„±ë³„" in h: gender_col_idx = idx
        if "ìƒë…„" in h or "ìƒì¼" in h or "ìƒì›”" in h: birth_col_idx = idx
    if gender_col_idx == -1 or birth_col_idx == -1: return None 
    extracted_entries = []
    for i, row in enumerate(table.rows[1:]): 
        cells = row.cells
        if len(cells) <= max(gender_col_idx, birth_col_idx): continue
        row_label = cells[0].text.strip(); gender_text = cells[gender_col_idx].text.strip(); birth_text = cells[birth_col_idx].text.strip()
        if not row_label: continue 
        gender_opts = extract_options_from_line(gender_text); gender_vals_str = ""
        if gender_opts:
            g_lines = []
            for opt in gender_opts:
                # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì ëŒ€ì‘
                m = re.match(r"^([â‘ -â‘©]|\d+|[a-zA-Z])[\)\.]?\s*(.*)", opt)
                if m: 
                    code = CIRCLE_MAP.get(m.group(1), m.group(1).replace(')','').replace('.',''))
                    g_lines.append(f"{code}={m.group(2).strip()}")
                else: g_lines.append(opt)
            gender_vals_str = "\n".join(g_lines)
        extracted_entries.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}_1", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {row_label} - ì„±ë³„", "ë³´ê¸° ê°’": gender_vals_str, "ìœ í˜•": "Single" })
        has_year = "ë…„" in birth_text; has_month = "ì›”" in birth_text
        if has_year: extracted_entries.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}_2", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {row_label} - ìƒë…„ (ë…„)", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
        if has_month: extracted_entries.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}_3", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {row_label} - ìƒì›” (ì›”)", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
    return extracted_entries

def extract_time_split_table(table, current_var):
    extracted = []
    for i, row in enumerate(table.rows):
        cells_text = [c.text.strip() for c in row.cells if c.text.strip()]
        if not cells_text: continue
        row_full_text = " ".join(cells_text)
        is_header_row = ("ì‹œê°„" in row_full_text and "ë¶„" in row_full_text and "ì…ë ¥" not in row_full_text and "ë²”ìœ„" not in row_full_text and "(" not in row_full_text)
        if is_header_row: continue
        row_label = cells_text[0]
        clean_label = re.sub(r"â€».*", "", row_label).strip().replace(":", "").strip()
        if len(clean_label) > 40 or not clean_label: continue
        extracted.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}_H", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {clean_label} (ì‹œê°„)", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
        extracted.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}_M", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {clean_label} (ë¶„)", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
    return extracted

def extract_horizontal_scale_table(table, current_var):
    rows = table.rows
    if len(rows) < 2: return None
    
    numeric_row_idx = -1
    label_row_idx = -1
    
    for i, row in enumerate(rows):
        cells_text = [c.text.strip() for c in row.cells if c.text.strip()]
        if not cells_text: continue
        # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì ê°ì§€ ê°•í™”
        numeric_count = sum(1 for t in cells_text if t.isdigit() or t in CIRCLE_MAP)
        if len(cells_text) > 0 and (numeric_count / len(cells_text)) > 0.7:
            numeric_row_idx = i
        elif len(cells_text) > 0:
            label_row_idx = i
            
    if numeric_row_idx == -1: return None
    
    codes = []
    for c in rows[numeric_row_idx].cells:
        t = c.text.strip()
        if not t: continue
        # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ìë¥¼ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜
        codes.append(CIRCLE_MAP.get(t, t))

    labels = []
    if label_row_idx != -1:
        labels = [c.text.strip() for c in rows[label_row_idx].cells if c.text.strip()]
    
    scale_pairs = []
    
    # ëª¨ë“  ì½”ë“œë¥¼ ì‚´ë¦¬ë˜, ë¼ë²¨ì´ ë¶€ì¡±í•˜ë©´ ì–‘ê·¹ë‹¨ ë§¤í•‘
    if codes:
        if len(labels) == 2: # ì–‘ê·¹ë‹¨
            scale_pairs.append(f"{codes[0]}={labels[0]}")
            for c in codes[1:-1]: scale_pairs.append(f"{c}={c}ì ")
            scale_pairs.append(f"{codes[-1]}={labels[1]}")
        elif len(labels) == len(codes): # 1:1 ë§¤í•‘
             for i in range(len(codes)): scale_pairs.append(f"{codes[i]}={labels[i]}")
        else: # ë§¤í•‘ ì• ë§¤í•˜ë©´ ê·¸ëƒ¥ ìˆœì„œëŒ€ë¡œ ë„£ê³  ë‚˜ë¨¸ì§„ ì ìˆ˜
             for i, c in enumerate(codes):
                 if i < len(labels): scale_pairs.append(f"{c}={labels[i]}")
                 else: scale_pairs.append(f"{c}={c}ì ")

    if scale_pairs:
        current_var["ë³´ê¸° ê°’"] = "\n".join(scale_pairs)
        return [current_var]
    return None

def extract_horizontal_input_table(table, current_var):
    rows = table.rows
    if len(rows) < 2: return None
    extracted = []
    headers = rows[0].cells
    values = rows[1].cells
    for i in range(len(headers)):
        header_text = headers[i].text.strip()
        value_text = values[i].text.strip()
        if not header_text: continue
        clean_label = clean_empty_parentheses(header_text)
        if "ì‹œê°„" in value_text and "ë¶„" in value_text and ("ì…ë ¥" in value_text or "(" in value_text):
             extracted.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}_H", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {clean_label} (ì‹œê°„)", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
             extracted.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}_M", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {clean_label} (ë¶„)", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
        else:
            extracted.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {clean_label}", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
    return extracted

def extract_plain_input_table(table, current_var):
    extracted = []
    for i, row in enumerate(table.rows):
        cells_text = [c.text.strip() for c in row.cells if c.text.strip()]
        if not cells_text: continue
        row_full_text = " ".join(cells_text)
        # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì íŒ¨í„´ íšŒí”¼
        if re.search(r"([â‘ -â‘©]|\d+|[a-zA-Z])[\)\.]", row_full_text): continue
        clean_label = re.sub(r"\(\s*ì…ë ¥.*?\)", "", row_full_text).replace(":", "").strip()
        clean_label = re.sub(r"[a-zA-Z]+$", "", clean_label).strip()
        if not clean_label: continue
        extracted.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {clean_label}", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
    return extracted

def extract_constant_sum_table(table, current_var):
    extracted_entries = []
    q_text = current_var.get("ì§ˆë¬¸ ë‚´ìš©", "")
    for i, row in enumerate(table.rows):
        cells = row.cells
        if len(cells) < 2: continue
        label_cell = cells[0].text.strip(); input_cell = cells[1].text.strip()
        if not label_cell: continue
        if "í•©ê³„" in label_cell or "Total" in label_cell or "TOTAL" in label_cell: continue
        sub_var_name = f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}"
        final_label = f"[{current_var['ë³€ìˆ˜ëª…']}] {label_cell}"
        if "%" in input_cell or "í¼ì„¼íŠ¸" in q_text: final_label += " (%)"
        extracted_entries.append({ "ë³€ìˆ˜ëª…": sub_var_name, "ì§ˆë¬¸ ë‚´ìš©": final_label, "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
    return extracted_entries

def is_multiple_choice(entry):
    vals = str(entry.get("ë³´ê¸° ê°’", "")); q_text = str(entry.get("ì§ˆë¬¸ ë‚´ìš©", ""))
    if re.search(r"([â‘ -â‘©]|\d+[\)\.])", vals) or "=" in vals: return True
    if "ì„ íƒ]" in q_text: return True
    return False

def check_and_split_time(entry):
    if is_multiple_choice(entry): return [entry]
    val = str(entry.get("ë³´ê¸° ê°’", "")) + str(entry.get("ì§ˆë¬¸ ë‚´ìš©", ""))
    is_time_related = ("ì‹œê°„" in val or "ì‹œ" in val or "ë¶„" in val) and ("ì…ë ¥" in val or "ê¸°ì…" in val)
    if not is_time_related: return [entry]
    has_hour_unit = bool(re.search(r"(\)|\]|\}|_)\s*ì‹œê°„", val) or re.search(r"ì‹œê°„\s*(\(|\[|\{|_)", val))
    has_minute_unit = bool(re.search(r"(\)|\]|\}|_)\s*ë¶„", val) or re.search(r"ë¶„\s*(\(|\[|\{|_)", val))
    if has_hour_unit and has_minute_unit:
        entry_h = entry.copy(); entry_h["ë³€ìˆ˜ëª…"] += "_H"; entry_h["ì§ˆë¬¸ ë‚´ìš©"] += " (ì‹œê°„)"; entry_h["ìœ í˜•"] = "Open"
        entry_m = entry.copy(); entry_m["ë³€ìˆ˜ëª…"] += "_M"; entry_m["ì§ˆë¬¸ ë‚´ìš©"] += " (ë¶„)"; entry_m["ìœ í˜•"] = "Open"
        return [entry_h, entry_m]
    elif has_hour_unit:
        entry_h = entry.copy(); entry_h["ë³€ìˆ˜ëª…"] += "_H"; entry_h["ì§ˆë¬¸ ë‚´ìš©"] += " (ì‹œê°„)"; entry_h["ìœ í˜•"] = "Open"
        return [entry_h]
    elif has_minute_unit:
        entry_m = entry.copy(); entry_m["ë³€ìˆ˜ëª…"] += "_M"; entry_m["ì§ˆë¬¸ ë‚´ìš©"] += " (ë¶„)"; entry_m["ìœ í˜•"] = "Open"
        return [entry_m]
    if "ë¶„" in val and "ì‹œê°„" in val:
        entry_m = entry.copy(); entry_m["ë³€ìˆ˜ëª…"] += "_M"; entry_m["ì§ˆë¬¸ ë‚´ìš©"] += " (ë¶„)"; entry_m["ìœ í˜•"] = "Open"
        return [entry_m]
    return [entry]

def check_and_split_date(entry):
    if is_multiple_choice(entry): return [entry]
    val = str(entry.get("ë³´ê¸° ê°’", "")) + str(entry.get("ì§ˆë¬¸ ë‚´ìš©", ""))
    if "ì–µ" in val: return [entry]
    if re.search(r"(ëª‡\s*ëª…|ëª…\s*ìˆ˜|ì¸ì›|\(\s*\)\s*ëª…|\[\s*\]\s*ëª…)", val): return [entry]
    def has_unit(text, unit):
        p1 = re.search(r"(\)|\]|\}|_)\s*" + unit, text); p2 = re.search(unit + r"\s*(\(|\[|\{|_)", text)
        p3 = (unit in text) and ("ì…ë ¥" in text or "ê¸°ì…" in text); return bool(p1 or p2 or p3)
    has_year = has_unit(val, "ë…„"); has_month = has_unit(val, "ì›”") or has_unit(val, "ê°œì›”"); has_day = has_unit(val, "ì¼")
    if not (has_year or has_month or has_day): return [entry]
    new_entries = []
    if has_year: y = entry.copy(); y["ë³€ìˆ˜ëª…"] += "_Y"; y["ì§ˆë¬¸ ë‚´ìš©"] += " (ë…„)"; y["ìœ í˜•"] = "Open"; new_entries.append(y)
    if has_month: m = entry.copy(); m["ë³€ìˆ˜ëª…"] += "_M"; m["ì§ˆë¬¸ ë‚´ìš©"] += " (ì›”)"; m["ìœ í˜•"] = "Open"; new_entries.append(m)
    if has_day: d = entry.copy(); d["ë³€ìˆ˜ëª…"] += "_D"; d["ì§ˆë¬¸ ë‚´ìš©"] += " (ì¼)"; d["ìœ í˜•"] = "Open"; new_entries.append(d)
    if new_entries: return new_entries
    return [entry]

def check_and_split_money(entry):
    if is_multiple_choice(entry): return [entry]
    val = str(entry.get("ë³´ê¸° ê°’", "")) + str(entry.get("ì§ˆë¬¸ ë‚´ìš©", ""))
    val_clean = val.replace(" ", "")
    if "ë§Œì›" not in val_clean and "ë§Œ ì›" not in val: return [entry]
    new_entries = []
    if "ì–µ" in val_clean: e = entry.copy(); e["ë³€ìˆ˜ëª…"] += "_E"; e["ì§ˆë¬¸ ë‚´ìš©"] += " (ì–µ)"; e["ìœ í˜•"] = "Open"; new_entries.append(e)
    if "ì²œ" in val_clean: c = entry.copy(); c["ë³€ìˆ˜ëª…"] += "_C"; c["ì§ˆë¬¸ ë‚´ìš©"] += " (ì²œ)"; c["ìœ í˜•"] = "Open"; new_entries.append(c)
    if "ë°±" in val_clean: b = entry.copy(); b["ë³€ìˆ˜ëª…"] += "_B"; b["ì§ˆë¬¸ ë‚´ìš©"] += " (ë°±)"; b["ìœ í˜•"] = "Open"; new_entries.append(b)
    if new_entries: return new_entries
    return [entry]

def check_and_split_percent(entry):
    val = str(entry.get("ë³´ê¸° ê°’", "")) + str(entry.get("ì§ˆë¬¸ ë‚´ìš©", ""))
    if "ë‚˜" in val and "ë°°ìš°ì" in val and ("%" in val or "100" in val):
        entry_me = entry.copy(); entry_me["ë³€ìˆ˜ëª…"] += "_1"; entry_me["ì§ˆë¬¸ ë‚´ìš©"] += " (ë‚˜)"; entry_me["ìœ í˜•"] = "Open"
        entry_sp = entry.copy(); entry_sp["ë³€ìˆ˜ëª…"] += "_2"; entry_sp["ì§ˆë¬¸ ë‚´ìš©"] += " (ë°°ìš°ì)"; entry_sp["ìœ í˜•"] = "Open"
        entry_sum = entry.copy(); entry_sum["ë³€ìˆ˜ëª…"] += "_3"; entry_sum["ì§ˆë¬¸ ë‚´ìš©"] += " (í•©ê³„)"; entry_sum["ìœ í˜•"] = "Open"
        return [entry_me, entry_sp, entry_sum]
    return [entry]

def collapse_consecutive_duplicates(item_list):
    if not item_list: return []
    collapsed = [item_list[0]]
    for item in item_list[1:]:
        if item != collapsed[-1]: collapsed.append(item)
    return collapsed

def extract_double_scale_table(table, current_var):
    rows = table.rows
    if len(rows) < 3: return None
    raw_cat_cells = [c.text.strip() for c in rows[0].cells]; non_empty_cats = [c for c in raw_cat_cells if c]
    if len(non_empty_cats) < 2: return None 
    categories = collapse_consecutive_duplicates(non_empty_cats)
    if len(categories) != 2: return None
    scale_row_cells = [c.text.strip() for c in rows[1].cells]; scales = scale_row_cells[1:]
    if len(scales) % 2 != 0: return None
    mid = len(scales) // 2
    left_scale = scales[:mid]; right_scale = scales[mid:]
    left_norm = "".join(left_scale).replace(" ", ""); right_norm = "".join(right_scale).replace(" ", "")
    if left_norm != right_norm: return None
    scale_pairs = []
    for idx, txt in enumerate(left_scale):
        if txt: scale_pairs.append(f"{idx+1}={txt}")
    scale_str = "\n".join(scale_pairs)
    cat1_label = categories[0]; cat2_label = categories[1]
    extracted_entries = []
    for r_idx, row in enumerate(rows[2:]):
        cells = row.cells
        if not cells: continue
        q_text = cells[0].text.strip()
        if not q_text: continue
        q_text_clean = re.sub(r"^[\d\w]+[\)\.]\s*", "", q_text)
        var_base = f"{current_var['ë³€ìˆ˜ëª…']}_{r_idx+1}"
        entry1 = { "ë³€ìˆ˜ëª…": f"{var_base}_1", "ì§ˆë¬¸ ë‚´ìš©": f"[{cat1_label}] {q_text_clean}", "ë³´ê¸° ê°’": scale_str, "ìœ í˜•": "Scale" }
        entry2 = { "ë³€ìˆ˜ëª…": f"{var_base}_2", "ì§ˆë¬¸ ë‚´ìš©": f"[{cat2_label}] {q_text_clean}", "ë³´ê¸° ê°’": scale_str, "ìœ í˜•": "Scale" }
        extracted_entries.append(entry1); extracted_entries.append(entry2)
    return extracted_entries

def extract_table_scale(table):
    rows = table.rows
    if len(rows) < 2: return None, False
    headers = [cell.text.strip().replace('\n', ' ') for cell in rows[0].cells]
    first_data_row = [cell.text.strip() for cell in rows[1].cells]
    
    numeric_cells = []
    for cell_text in first_data_row:
        if "ì…ë ¥" in cell_text or "ë²”ìœ„" in cell_text or "%" in cell_text: numeric_cells.append(None); continue
        
        # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì ëŒ€ì‘ (B1-B4 ë§¤íŠ¸ë¦­ìŠ¤ ë“±)
        match = re.search(r"([â‘ -â‘©]|\d+)", cell_text)
        if match: 
            raw_code = match.group(1)
            numeric_cells.append(CIRCLE_MAP.get(raw_code, raw_code))
        else: numeric_cells.append(None)
            
    body_numeric_count = sum(1 for x in numeric_cells if x is not None)
    if len(first_data_row) > 0 and (body_numeric_count / len(first_data_row)) >= 0.3:
        scale_pairs = []
        for i, val in enumerate(numeric_cells):
            if i >= len(headers): break
            if val is not None and headers[i]: 
                scale_pairs.append(f"{val}={headers[i].strip()}")
        if scale_pairs: return "\n".join(scale_pairs), True

    # í—¤ë”ì— ìˆ«ìê°€ ìˆëŠ” ê²½ìš° (ê¸°ì¡´ ë¡œì§)
    potential_values = []
    header_numeric_count = sum(1 for h in headers if re.search(r"(\d)", h))
    if len(headers) > 0 and (header_numeric_count / len(headers)) >= 0.3:
        for idx, h_text in enumerate(headers):
            if not h_text: continue
            if idx == 0 and not re.search(r"\d", h_text): continue
            potential_values.append(clean_header_text(h_text))
        if potential_values: return "\n".join(potential_values), False
    return None, False

def is_input_table(table):
    if len(table.rows) < 1: return False
    target_count = 0; total_rows = len(table.rows)
    for row in table.rows:
        if len(row.cells) > 1:
            cell_text = row.cells[1].text
            if "ì…ë ¥" in cell_text or "(" in cell_text or "%" in cell_text or "_" in cell_text: target_count += 1
    if total_rows > 0 and (target_count / total_rows) >= 0.3: return True
    return False

def extract_multi_column_input_table(table, current_var, force_row_count=None):
    rows = table.rows
    if len(rows) < 2: return None
    headers = [cell.text.strip() for cell in rows[0].cells]
    non_empty_headers = [h for h in headers if h]
    if len(non_empty_headers) < 1: return None
    first_data_row_cells = [c.text.strip() for c in rows[1].cells[1:]] 
    # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì ëŒ€ì‘
    digit_count = sum(1 for c in first_data_row_cells if (c.isdigit() or c in CIRCLE_MAP) and len(c) == 1)
    if len(first_data_row_cells) > 0 and (digit_count / len(first_data_row_cells)) > 0.5: return None
    extracted_entries = []
    actual_data_rows = len(rows) - 1
    target_loop_count = actual_data_rows
    if force_row_count and force_row_count > actual_data_rows: target_loop_count = force_row_count
    sub_item_count = 0
    for i in range(target_loop_count):
        sub_item_count += 1
        if i < actual_data_rows:
            curr_row = rows[i+1]
            first_cell = curr_row.cells[0].text.strip()
            row_label = first_cell if first_cell else f"{sub_item_count}ìˆœìœ„"
        else: row_label = f"{sub_item_count}ìˆœìœ„"
        for c_idx in range(len(headers)):
            if c_idx == 0: continue
            raw_header = headers[c_idx] if c_idx < len(headers) else ""
            col_header = raw_header if raw_header else f"Col{c_idx}"
            var_name = f"{current_var['ë³€ìˆ˜ëª…']}_{sub_item_count}_{c_idx}"
            var_label = f"[{current_var['ë³€ìˆ˜ëª…']}] {row_label} - {col_header}"
            extracted_entries.append({ "ë³€ìˆ˜ëª…": var_name, "ì§ˆë¬¸ ë‚´ìš©": var_label, "ë³´ê¸° ê°’": "(ì£¼ê´€ì‹)", "ìœ í˜•": "Open" })
    return extracted_entries

def check_and_split_max_n_text(entry):
    if entry["ìœ í˜•"] != "Single" and entry["ìœ í˜•"] != "Open": return None
    q_text = entry["ì§ˆë¬¸ ë‚´ìš©"]
    if "ë³´ê¸°_list" in entry: q_text += " " + " ".join(entry["ë³´ê¸°_list"])
    q_text_norm = q_text.replace("ï¼»", "[").replace("ï¼½", "]").replace("ï¼ˆ", "(").replace("ï¼‰", ")")
    count = 0
    patterns = [ r"\[\s*ìµœëŒ€\s*(\d+)", r"ìµœëŒ€\s*(\d+)\s*(?:ê°œ|ëŒ€|ê³³|ëª…|ìˆœìœ„)", r"ìµœëŒ€.*?(\d+)", r"(\d+)ê°œ.*?ê¸°ì…" ]
    for pat in patterns:
        match = re.search(pat, q_text_norm)
        if match: count = int(match.group(1)); break
    if count == 0 and "3" in q_text_norm and ("ê¸°ì…" in q_text_norm or "ì‘ì„±" in q_text_norm): count = 3
    if count < 1: return None
    has_manufacturer = "ì œì¡°ì‚¬" in q_text_norm; has_brand = "ë¸Œëœë“œ" in q_text_norm
    new_entries = []
    for i in range(1, count + 1):
        if has_manufacturer and has_brand:
            v1 = entry.copy(); v1["ë³€ìˆ˜ëª…"] = f"{entry['ë³€ìˆ˜ëª…']}_{i}_1"; v1["ì§ˆë¬¸ ë‚´ìš©"] = f"[{entry['ë³€ìˆ˜ëª…']}] {i}ìˆœìœ„ - ì œì¡°ì‚¬"; v1["ìœ í˜•"] = "Open"
            if "ë³´ê¸°_list" in v1: del v1["ë³´ê¸°_list"]
            v2 = entry.copy(); v2["ë³€ìˆ˜ëª…"] = f"{entry['ë³€ìˆ˜ëª…']}_{i}_2"; v2["ì§ˆë¬¸ ë‚´ìš©"] = f"[{entry['ë³€ìˆ˜ëª…']}] {i}ìˆœìœ„ - ë¸Œëœë“œ"; v2["ìœ í˜•"] = "Open"
            if "ë³´ê¸°_list" in v2: del v2["ë³´ê¸°_list"]
            new_entries.append(v1); new_entries.append(v2)
        else:
            v = entry.copy(); v["ë³€ìˆ˜ëª…"] = f"{entry['ë³€ìˆ˜ëª…']}_{i}"; v["ì§ˆë¬¸ ë‚´ìš©"] = f"[{entry['ë³€ìˆ˜ëª…']}] {i}ìˆœìœ„"; v["ìœ í˜•"] = "Open"
            if "ë³´ê¸°_list" in v: del v["ë³´ê¸°_list"]
            new_entries.append(v)
    return new_entries

def is_option_description_table(table):
    if len(table.rows) < 1: return False
    # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì ëŒ€ì‘
    pattern = re.compile(r"^([â‘ -â‘©]|\d+|[a-zA-Z])[\)\.]")
    match_count = 0
    for row in table.rows:
        if not row.cells: continue
        text = row.cells[0].text.strip()
        if pattern.match(text): match_count += 1
    return (match_count / len(table.rows)) >= 0.5

def extract_single_choice_options(table):
    options = []
    for row in table.rows:
        cells_text = [c.text.strip() for c in row.cells if c.text.strip()]
        if not cells_text: continue
        first_cell_text = cells_text[0]
        # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì ëŒ€ì‘
        match = re.match(r"^([â‘ -â‘©]|\d+|[a-zA-Z])[\)\.]", first_cell_text)
        if match:
            raw_code = match.group(1).replace(')','').replace('.','')
            code = CIRCLE_MAP.get(raw_code, raw_code)
            clean_first = first_cell_text[len(match.group(0)):].strip()
            label_parts = []
            if clean_first: label_parts.append(clean_first)
            if len(cells_text) > 1: label_parts.extend(cells_text[1:])
            final_label = " - ".join(label_parts); final_label = clean_empty_parentheses(final_label) 
            options.append(f"{code}={final_label}")
        else:
            row_text = " - ".join(cells_text); row_text = clean_empty_parentheses(row_text) 
            options.append(row_text)
    return "\n".join(options)

def extract_options_from_table(table):
    options = []
    idx = 1
    for row in table.rows:
        for cell in row.cells:
            text = cell.text.strip(); text = clean_empty_parentheses(text)
            if text: options.append(f"{idx}={text}"); idx += 1
    return "\n".join(options)

def check_ranking_selection_question(entry):
    q_text = entry["ì§ˆë¬¸ ë‚´ìš©"]
    if ("ìˆœì„œ" in q_text or "ìˆœìœ„" in q_text) and "ì„ íƒ" in q_text:
        match_rank = re.search(r"~\s*(\d+)\s*ìˆœìœ„", q_text)
        if match_rank: return int(match_rank.group(1))
        match_count = re.search(r"(\d+)ê°œ", q_text)
        if match_count: return int(match_count.group(1))
    return None

# ==============================================================================
# [Part 4] ì§€ëŠ¥í˜• í…Œì´ë¸” ë¶„ì„ (Scanning)
# ==============================================================================

def analyze_table_structure(table):
    rows = table.rows
    if len(rows) < 1: return "UNKNOWN"
    all_text = ""; first_row_text = ""; second_row_text = ""; has_input_pattern = False
    input_keywords = ["ì…ë ¥", "ë²”ìœ„", "cm", "kg", "ëª…", "ê°œ", "íšŒ", "( )", "()"]
    
    row0_digits = 0; row0_len = 0
    row1_digits = 0; row1_len = 0
    
    # [NEW] ë³´ê¸° ëª©ë¡í˜• í…Œì´ë¸” ê°ì§€ (SQ8)
    if "ë³´ê¸°" in [c.text.strip() for c in rows[0].cells]:
        return "MAPPED_OPTION"
    
    # [NEW] ë‹¨ìœ„ ì…ë ¥í˜• í…Œì´ë¸” ê°ì§€ (SQ6)
    unit_keywords = ["ëª…", "ì„¸", "ê°œ", "ì›", "ë…„"]
    has_unit_col = False
    for row in rows:
        if any(cell.text.strip() in unit_keywords for cell in row.cells):
            has_unit_col = True
            break
    if has_unit_col: return "UNIT_INPUT"
    
    # [FIX] ìˆ˜í‰ ì²™ë„í˜• í…Œì´ë¸” ê°ì§€ ë¡œì§ ê°•í™” (B1-1)
    has_numeric_row = False
    for row in rows:
        cells = [c.text.strip() for c in row.cells if c.text.strip()]
        if len(cells) >= 5: # ìµœì†Œ 5ì  ì²™ë„ ì´ìƒ
            # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì ê°ì§€ ê°•í™”
            digit_count = sum(1 for c in cells if c.isdigit() or c in CIRCLE_MAP)
            if digit_count / len(cells) > 0.8: 
                has_numeric_row = True
                break
    if has_numeric_row: return "HORIZONTAL_SCALE"

    for i, row in enumerate(rows):
        row_txt = " ".join([c.text.strip() for c in row.cells])
        all_text += row_txt + " "; 
        if i == 0: 
            first_row_text = row_txt
            row0_len = len(row.cells)
            # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì ê°ì§€
            row0_digits = sum(1 for c in row.cells if re.search(r"^([â‘ -â‘©]|\d+)[\)\.]?$", c.text.strip()))
        if i == 1: 
            second_row_text = row_txt
            row1_len = len(row.cells)
            # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì ê°ì§€
            row1_digits = sum(1 for c in row.cells if (c.text.strip().isdigit() or c.text.strip() in CIRCLE_MAP))
            
        if any(k in row_txt for k in input_keywords): has_input_pattern = True

    # 1. [ìµœìš°ì„ ] ë§¤íŠ¸ë¦­ìŠ¤ ì²™ë„í˜• (E1-1 ë°©ì–´ìš©)
    if len(table.columns) >= 4 and row0_digits >= 3 and not has_input_pattern:
        return "STANDARD"

    # 2. ìë…€ ì •ë³´ (SQ6)
    if "ì„±ë³„" in all_text and ("ìƒë…„" in all_text or "ìƒì¼" in all_text): return "CHILD_DEMO"
    
    # 3. ì‹œê°„ ë¶„í•  (ì„¸ë¡œí˜• - A2, A4)
    if "ì‹œê°„" in all_text and "ë¶„" in all_text and has_input_pattern:
        if len(table.columns) <= 4:
            return "TIME_SPLIT"

    # 4. ê°€ë¡œí˜• ì²™ë„ (B2, A10-1)
    if len(rows) == 2 and not has_input_pattern:
        row0_is_numeric = row0_len > 0 and (row0_digits / row0_len) > 0.5
        row1_is_numeric = row1_len > 0 and (row1_digits / row1_len) > 0.5
        if (row0_is_numeric and not row1_is_numeric) or (not row0_is_numeric and row1_is_numeric):
            return "HORIZONTAL_SCALE"

    # 5. ê°€ë¡œí˜• ì…ë ¥ (B3, B4)
    is_row1_input = any(k in second_row_text for k in input_keywords)
    if len(rows) >= 2 and len(table.columns) >= 2 and is_row1_input:
        return "HORIZONTAL_INPUT"
    
    # 6. ê³ ì • í•©ê³„
    if ("í•©ê³„" in all_text or "Total" in all_text) and ("%" in all_text or "100" in all_text):
        if len(table.columns) == 2: return "CONSTANT_SUM"
        
    # 7. ë‹¨ìˆœ ì…ë ¥ (A1)
    is_option_table = bool(re.search(r"([â‘ -â‘©]|\d+|[a-zA-Z])[\)\.]", first_row_text))
    if has_input_pattern and not is_option_table and len(table.columns) <= 2: return "PLAIN_INPUT"
    
    return "STANDARD"

# ==============================================================================
# [Part 5] ë©”ì¸ íŒŒì„œ
# ==============================================================================

def parse_word_to_df(docx_file):
    doc = Document(docx_file)
    extracted_data = []
    var_pattern = re.compile(r"^([a-zA-Zê°€-í£0-9\-\_]+)(?:[\.\s]|\s+)(.*)")
    # [SQ10 í•´ê²°] ë„ì–´ì“°ê¸° í¬í•¨ëœ í‚¤ì›Œë“œ ì¶”ê°€
    multi_keywords = ["ë³µìˆ˜ì‘ë‹µ", "ëª¨ë‘ ì„ íƒ", "ì¤‘ë³µì„ íƒ", "ì¤‘ë³µ ì‘ë‹µ", "ëª¨ë‘ ê³¨ë¼", "ì¤‘ë³µ ì„ íƒ", "ë³µìˆ˜ ì„ íƒ", "ì¤‘ë³µê°€ëŠ¥", "ëª¨ë‘ ì²´í¬", "ëª¨ë‘ ì‘ë‹µ"]
    current_entry = None
    is_parent_added = False 
    
    # [NEW] ì„¹ì…˜ ì¸ì‹ ë³€ìˆ˜
    current_prefix = "Q"
    prefix_counters = collections.defaultdict(int)
    
    # [NEW] ì›Œë“œ ìë™ë²ˆí˜¸ ì¸ì‹ìš© ì¹´ìš´í„°
    auto_num_counters = collections.defaultdict(int)
    
    variable_map = {} 
    
    pending_ranking_count = None
    ranking_options_buffer = []
    pending_max_n_count = None
    
    allowed_starts = ['Q', 'A', 'S', 'D', 'M', 'P', 'R', 'I', 'B', 'C', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'N', 'O', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'ë¬¸', 'ì„¤ë¬¸']

    def flush_entry(entry):
        nonlocal is_parent_added, pending_max_n_count
        if "ì§ˆë¬¸ ë‚´ìš©" in entry: entry["ì§ˆë¬¸ ë‚´ìš©"] = clean_empty_parentheses(entry["ì§ˆë¬¸ ë‚´ìš©"])
        
        if pending_ranking_count is not None and ranking_options_buffer:
            final_opts_str = "\n".join(ranking_options_buffer)
            results = []
            for i in range(1, pending_ranking_count + 1):
                results.append({ "ë³€ìˆ˜ëª…": f"{entry['ë³€ìˆ˜ëª…']}_{i}", "ì§ˆë¬¸ ë‚´ìš©": f"{entry['ì§ˆë¬¸ ë‚´ìš©']} ({i}ìˆœìœ„)", "ë³´ê¸° ê°’": final_opts_str, "ìœ í˜•": "Ranking_Sel" })
            return results
        if pending_max_n_count is not None:
            # [FIX] ë³´ê¸°ê°€ ìˆëŠ” ê²½ìš°(Mapped Table ë“±ì—ì„œ ìœ ì…), Openì´ ì•„ë‹ˆë¼ Selectionìœ¼ë¡œ ì²˜ë¦¬
            has_options = bool(entry.get("ë³´ê¸° ê°’") or entry.get("ë³´ê¸°_list"))
            opts_str = entry.get("ë³´ê¸° ê°’", "")
            if not opts_str and entry.get("ë³´ê¸°_list"):
                opts_str = "\n".join(entry["ë³´ê¸°_list"])

            new_entries = []
            for i in range(1, pending_max_n_count + 1):
                if has_options:
                    # ë³´ê¸°ê°€ ìˆìœ¼ë©´ Ranking_Selë¡œ ë³€ê²½
                    v = entry.copy()
                    v["ë³€ìˆ˜ëª…"] = f"{entry['ë³€ìˆ˜ëª…']}_{i}"
                    v["ì§ˆë¬¸ ë‚´ìš©"] = f"[{entry['ë³€ìˆ˜ëª…']}] {i}ìˆœìœ„"
                    v["ë³´ê¸° ê°’"] = opts_str
                    v["ìœ í˜•"] = "Ranking_Sel"
                    if "ë³´ê¸°_list" in v: del v["ë³´ê¸°_list"]
                    new_entries.append(v)
                else:
                    # ê¸°ì¡´ ì£¼ê´€ì‹ ì²˜ë¦¬
                    has_manufacturer = "ì œì¡°ì‚¬" in entry["ì§ˆë¬¸ ë‚´ìš©"]; has_brand = "ë¸Œëœë“œ" in entry["ì§ˆë¬¸ ë‚´ìš©"]
                    if has_manufacturer and has_brand:
                        v1 = entry.copy(); v1["ë³€ìˆ˜ëª…"] = f"{entry['ë³€ìˆ˜ëª…']}_{i}_1"; v1["ì§ˆë¬¸ ë‚´ìš©"] = f"[{entry['ë³€ìˆ˜ëª…']}] {i}ìˆœìœ„ - ì œì¡°ì‚¬"; v1["ìœ í˜•"] = "Open"
                        if "ë³´ê¸°_list" in v1: del v1["ë³´ê¸°_list"]
                        v2 = entry.copy(); v2["ë³€ìˆ˜ëª…"] = f"{entry['ë³€ìˆ˜ëª…']}_{i}_2"; v2["ì§ˆë¬¸ ë‚´ìš©"] = f"[{entry['ë³€ìˆ˜ëª…']}] {i}ìˆœìœ„ - ë¸Œëœë“œ"; v2["ìœ í˜•"] = "Open"
                        if "ë³´ê¸°_list" in v2: del v2["ë³´ê¸°_list"]
                        new_entries.append(v1); new_entries.append(v2)
                    else:
                        v = entry.copy(); v["ë³€ìˆ˜ëª…"] = f"{entry['ë³€ìˆ˜ëª…']}_{i}"; v["ì§ˆë¬¸ ë‚´ìš©"] = f"[{entry['ë³€ìˆ˜ëª…']}] {i}ìˆœìœ„"; v["ìœ í˜•"] = "Open"
                        if "ë³´ê¸°_list" in v: del v["ë³´ê¸°_list"]
                        new_entries.append(v)
            pending_max_n_count = None
            return new_entries
        raw_options = entry.get("ë³´ê¸°_list", [])
        
        is_multi = any(k in entry["ì§ˆë¬¸ ë‚´ìš©"] for k in multi_keywords)
        if "D6_2" in entry["ë³€ìˆ˜ëª…"].replace("-", "_"): is_multi = True
        
        if is_multi and raw_options:
            full_options_str_list = []
            for opt in raw_options:
                # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì ëŒ€ì‘
                opt_match = re.match(r"^\s*([â‘ -â‘©]|\d+|[a-zA-Z])[\)\.]\s*(.*)", opt)
                if opt_match:
                    raw_code = opt_match.group(1).replace(')','').replace('.','')
                    code = CIRCLE_MAP.get(raw_code, raw_code)
                    label = clean_empty_parentheses(opt_match.group(2))
                    full_options_str_list.append(f"{code}={label}")
            full_options_str = "\n".join(full_options_str_list)
            results = []
            for opt in raw_options:
                opt_match = re.match(r"^\s*([â‘ -â‘©]|\d+|[a-zA-Z])[\)\.]\s*(.*)", opt)
                if opt_match:
                    raw_code = opt_match.group(1).replace(')','').replace('.','')
                    code = CIRCLE_MAP.get(raw_code, raw_code)
                    label = clean_empty_parentheses(opt_match.group(2))
                    results.append({ "ë³€ìˆ˜ëª…": f"{entry['ë³€ìˆ˜ëª…']}_{code}", "ì§ˆë¬¸ ë‚´ìš©": f"{entry['ì§ˆë¬¸ ë‚´ìš©']} ({label})", "ë³´ê¸° ê°’": full_options_str, "ìœ í˜•": "Multi" })
            return results
        else:
            # ë‹¨ì¼ ì„ íƒ ë³´ê¸° ë³€í™˜
            clean_opts = []
            for opt in raw_options:
                opt_match = re.match(r"^\s*([â‘ -â‘©]|\d+|[a-zA-Z])[\)\.]\s*(.*)", opt)
                if opt_match:
                    raw_code = opt_match.group(1).replace(')','').replace('.','')
                    code = CIRCLE_MAP.get(raw_code, raw_code)
                    clean_opts.append(f"{code}={clean_empty_parentheses(opt_match.group(2))}")
                else: clean_opts.append(opt)

            entry["ë³´ê¸° ê°’"] = "\n".join(clean_opts)
            if "ë³´ê¸°_list" in entry: del entry["ë³´ê¸°_list"]
            
            mixed_input = check_mixed_text_input(entry)
            if len(mixed_input) > 1: return mixed_input
            
            split_entries = check_and_split_time(entry)
            if len(split_entries) == 1: split_entries = check_and_split_date(split_entries[0])
            if len(split_entries) == 1: split_entries = check_and_split_money(split_entries[0])
            if len(split_entries) == 1: split_entries = check_and_split_percent(split_entries[0])
            
            embedded_opens = extract_embedded_open_entry(split_entries[0])
            if embedded_opens:
                split_entries.extend(embedded_opens)
                
            return split_entries

    for block in iter_block_items(doc):
        # í‘œ ë‚´ë¶€ ì„¹ì…˜ í—¤ë” ê°ì§€
        if isinstance(block, Table):
            if len(block.rows) > 0 and len(block.rows[0].cells) > 0:
                first_cell_text = block.rows[0].cells[0].text
                current_prefix = check_section_header(first_cell_text, current_prefix)
        
        if isinstance(block, Paragraph):
            text = block.text.strip()
            current_prefix = check_section_header(text, current_prefix)

            if block._p.pPr is not None and block._p.pPr.numPr is not None:
                try:
                    num_id = block._p.pPr.numPr.numId.val
                    ilvl = block._p.pPr.numPr.ilvl.val if block._p.pPr.numPr.ilvl is not None else 0
                    auto_num_counters[(num_id, ilvl)] += 1
                    num_val = auto_num_counters[(num_id, ilvl)]
                    
                    if not re.match(r"^(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]", text):
                        if "?" in text or "ë‹¤." in text or "ì‹œì˜¤" in text or len(text) > 40:
                            prefix_counters[current_prefix] += 1
                            q_num = prefix_counters[current_prefix]
                            text = f"{current_prefix}{q_num}. {text}"
                        else:
                            text = f"{num_val}) {text}"
                except:
                    pass

            if not text: continue
            if re.match(r"^\[PROG", text, re.IGNORECASE) or re.match(r"^\(PROG", text, re.IGNORECASE): continue
            text = re.sub(r"\[PROG.*?\]", "", text, flags=re.IGNORECASE)
            text = re.sub(r"\(PROG.*?\)", "", text, flags=re.IGNORECASE)
            text = text.strip()
            if not text: continue
            
            match_var = var_pattern.match(text)
            is_new_q = False
            if match_var:
                temp_var = match_var.group(1)
                is_valid_start = False
                for start_char in allowed_starts:
                    if temp_var.upper().startswith(start_char):
                        is_valid_start = True
                        break
                
                if temp_var.replace(".", "").isdigit():
                    if current_entry is None: is_new_code = True
                elif is_valid_start:
                    if temp_var not in ["ë³´ê¸°", "ë‹¤ìŒ", "ì°¸ê³ ", "ì£¼"]: is_new_q = True
            
            if is_new_q:
                if current_entry and not is_parent_added:
                    flushed_data = flush_entry(current_entry)
                    if flushed_data: 
                        for item in flushed_data:
                            variable_map[item['ë³€ìˆ˜ëª…']] = len(extracted_data)
                            extracted_data.append(item)
                            
                var_name = match_var.group(1).replace("-", "_"); label = match_var.group(2)
                inline_opts = extract_options_from_line(label)
                if inline_opts:
                    first_opt = inline_opts[0]; split_idx = label.find(first_opt)
                    if split_idx != -1: q_text = label[:split_idx].strip(); current_entry = { "ë³€ìˆ˜ëª…": var_name, "ì§ˆë¬¸ ë‚´ìš©": q_text, "ë³´ê¸° ê°’": "", "ë³´ê¸°_list": inline_opts, "ìœ í˜•": "Single" }
                    else: current_entry = { "ë³€ìˆ˜ëª…": var_name, "ì§ˆë¬¸ ë‚´ìš©": label.strip(), "ë³´ê¸° ê°’": "", "ë³´ê¸°_list": [], "ìœ í˜•": "Single" }
                else: current_entry = { "ë³€ìˆ˜ëª…": var_name, "ì§ˆë¬¸ ë‚´ìš©": label.strip(), "ë³´ê¸° ê°’": "", "ë³´ê¸°_list": [], "ìœ í˜•": "Single" }
                is_parent_added = False
                rank_count = check_ranking_selection_question(current_entry)
                if rank_count: pending_ranking_count = rank_count; ranking_options_buffer = [] 
                else: pending_ranking_count = None; ranking_options_buffer = []
                
                # [FIX] Force Max N check based on text pattern (regardless of function return)
                q_norm = current_entry["ì§ˆë¬¸ ë‚´ìš©"].replace("ï¼»", "[").replace("ï¼½", "]").replace("ï¼ˆ", "(").replace("ï¼‰", ")")
                max_n_match = re.search(r"ìµœëŒ€\s*(\d+)", q_norm)
                if max_n_match:
                    pending_max_n_count = int(max_n_match.group(1))
                else:
                    pending_max_n_count = None
                
                if "1ê°œ ì„ íƒ" in current_entry["ì§ˆë¬¸ ë‚´ìš©"]: current_entry["ìœ í˜•"] = "Single"
            elif current_entry:
                if not is_parent_added:
                    # [FIX] S5 ë“± ì˜µì…˜ ê°•ì œ ì¸ì‹
                    # ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ë‹¨ì€ ë¬´ì¡°ê±´ ë³´ê¸°ë¡œ ê°„ì£¼ (1) S 2WD ê°™ì€ ê²½ìš°)
                    opts_in_line = extract_options_from_line(text)
                    # [ìˆ˜ì •] ë™ê·¸ë¼ë¯¸ ìˆ«ì í¬í•¨ íŒ¨í„´ ëŒ€ì‘
                    if not opts_in_line and re.match(r"^([â‘ -â‘©]|\d+)[\)\.]", text): opts_in_line = [text]

                    if opts_in_line:
                        if pending_ranking_count:
                            for opt in opts_in_line:
                                opt_match = re.match(r"^(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]\s*(.*)", opt)
                                if opt_match: 
                                    raw_code = opt_match.group(1).replace(')','').replace('.','')
                                    code = CIRCLE_MAP.get(raw_code, raw_code)
                                    val = opt_match.group(2)
                                    ranking_options_buffer.append(f"{code}={val}")
                        else:
                            if "ë³´ê¸°_list" in current_entry: current_entry["ë³´ê¸°_list"].extend(opts_in_line)
                    elif "=" in text or "ì " in text:
                         if "ë³´ê¸°_list" in current_entry: current_entry["ë³´ê¸°_list"].append(text)
                    elif "[ì£¼ê´€ì‹]" in text or "ì§ì ‘ ê¸°ì…" in text:
                        current_entry["ìœ í˜•"] = "Open"
                        if "ë³´ê¸°_list" in current_entry: current_entry["ë³´ê¸°_list"].append("(ì£¼ê´€ì‹)")
                    else:
                        if "ë³´ê¸°_list" in current_entry and not current_entry["ë³´ê¸°_list"]: current_entry["ì§ˆë¬¸ ë‚´ìš©"] += " " + text

        elif isinstance(block, Table):
            rows = block.rows
            if len(rows) < 1: continue

            # ì§€ëŠ¥í˜• í…Œì´ë¸” ë¶„ì„ (Scanning)
            table_type = analyze_table_structure(block)
            
            new_entries = []
            
            # [NEW] AHP ì´ì›ë¹„êµ ìš°ì„  ì²˜ë¦¬
            ahp_entries = extract_ahp_table(block, current_entry)
            if ahp_entries:
                new_entries = ahp_entries
                
            elif table_type == "MAPPED_OPTION":
                is_updated = extract_mapped_option_table(block, extracted_data, variable_map, current_entry)
            
            elif table_type == "UNIT_INPUT":
                if current_entry and not is_parent_added:
                    new_entries = extract_unit_input_table(block, current_entry)

            elif table_type == "CHILD_DEMO":
                if current_entry and not is_parent_added:
                    new_entries = extract_child_demographics_table(block, current_entry)
            
            elif table_type == "HORIZONTAL_SCALE":
                if current_entry and not is_parent_added:
                    new_entries = extract_horizontal_scale_table(block, current_entry)

            elif table_type == "HORIZONTAL_INPUT":
                if current_entry and not is_parent_added:
                    new_entries = extract_horizontal_input_table(block, current_entry)

            elif table_type == "TIME_SPLIT":
                if current_entry and not is_parent_added:
                    new_entries = extract_time_split_table(block, current_entry)
            
            elif table_type == "CONSTANT_SUM":
                if current_entry and not is_parent_added:
                    new_entries = extract_constant_sum_table(block, current_entry)
            
            elif table_type == "PLAIN_INPUT":
                if current_entry and not is_parent_added:
                    new_entries = extract_plain_input_table(block, current_entry)
            
            elif table_type == "STANDARD":
                if current_entry and not is_parent_added:
                    ds = extract_double_scale_table(block, current_entry)
                    if ds: new_entries = ds
                    else:
                        q_type = current_entry.get("ìœ í˜•")
                        if any(k in current_entry["ì§ˆë¬¸ ë‚´ìš©"] for k in multi_keywords): q_type = "Multi"
                        if q_type in ["Single", "Multi"]:
                            is_opt = False
                            fc = rows[0].cells[0].text.strip()
                            if re.match(r"^(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]", fc): is_opt = True
                            if is_opt:
                                opt_str = extract_single_choice_options(block)
                                if q_type == "Single": current_entry["ë³´ê¸° ê°’"] = opt_str; extracted_data.append(current_entry)
                                else:
                                    parsed_opts = []
                                    for line in opt_str.split('\n'):
                                        if '=' in line: c, l = line.split('=', 1); parsed_opts.append(f"{c}) {l}")
                                        else: parsed_opts.append(line)
                                    if "ë³´ê¸°_list" not in current_entry: current_entry["ë³´ê¸°_list"] = []
                                    current_entry["ë³´ê¸°_list"].extend(parsed_opts)
                                    is_parent_added = True
                                    continue
                        
                        if pending_ranking_count and not new_entries:
                            opts = extract_options_from_table(block)
                            if opts: ranking_options_buffer.append(opts)
                            continue
                        
                        if not new_entries:
                            mc = extract_multi_column_input_table(block, current_entry, force_row_count=pending_max_n_count)
                            if mc: new_entries = mc; pending_max_n_count = None
                        
                        if not new_entries and current_entry.get("ìœ í˜•") in ["Single", "Multi"]:
                            if is_option_description_table(block):
                                opt_str = extract_single_choice_options(block)
                                current_entry["ë³´ê¸° ê°’"] = opt_str
                                extracted_data.append(current_entry)
                                is_parent_added = True
                                continue
                        
                        if not new_entries and is_input_table(block):
                            if current_entry:
                                sub_cnt = 0
                                for row in rows:
                                    fc = row.cells[0].text.strip()
                                    if not fc: continue
                                    sub_cnt += 1
                                    new_entries.append({ "ë³€ìˆ˜ëª…": f"{current_entry['ë³€ìˆ˜ëª…']}_{sub_cnt}", "ì§ˆë¬¸ ë‚´ìš©": f"{current_entry['ì§ˆë¬¸ ë‚´ìš©']} ({fc})", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })

                        if not new_entries and current_entry:
                            table_vals_str, is_body_mapped = extract_table_scale(block)
                            is_matrix = False
                            if len(rows) > 1:
                                for row in rows[1:]:
                                    fc = row.cells[0].text.strip()
                                    # ë™ê·¸ë¼ë¯¸ ìˆ«ì ë“±ì˜ ì²™ë„ê°’ì€ ê±´ë„ˆë›°ê³  ì§ˆë¬¸ë¼ë²¨ë§Œ ì²´í¬
                                    if fc and not fc.isdigit() and fc not in ["â—‹", "â—", "V"] and fc not in CIRCLE_MAP: 
                                        is_matrix = True; break
                            
                            # [ìˆ˜ì •] B1-B4 ë§¤íŠ¸ë¦­ìŠ¤ ì²™ë„ ì²˜ë¦¬ ê°•í™”
                            if is_matrix:
                                sub_cnt = 0
                                for row in rows[1:]:
                                    fc = row.cells[0].text.strip()
                                    if not fc or fc in CIRCLE_MAP: continue
                                    sub_cnt += 1
                                    m_var = f"{current_entry['ë³€ìˆ˜ëª…']}_{sub_cnt}"
                                    new_entries.append({ "ë³€ìˆ˜ëª…": m_var, "ì§ˆë¬¸ ë‚´ìš©": f"[{current_entry['ë³€ìˆ˜ëª…']} ì„¸ë¶€] {fc}", "ë³´ê¸° ê°’": table_vals_str if table_vals_str else "(í—¤ë”ì°¸ì¡°)", "ìœ í˜•": "Matrix" })
                            elif not is_parent_added and not is_input_table(block):
                                split = check_and_split_time(current_entry)
                                if len(split) == 1: split = check_and_split_date(split[0])
                                if len(split) == 1: split = check_and_split_money(split[0])
                                if len(split) == 1: split = check_and_split_percent(split[0])
                                new_entries = split

            if new_entries:
                for item in new_entries:
                    variable_map[item['ë³€ìˆ˜ëª…']] = len(extracted_data)
                    extracted_data.append(item)
                is_parent_added = True

    if current_entry and not is_parent_added:
        flushed_data = flush_entry(current_entry)
        if flushed_data: 
            for item in flushed_data:
                variable_map[item['ë³€ìˆ˜ëª…']] = len(extracted_data)
                extracted_data.append(item)
            
    return pd.DataFrame(extracted_data)

def to_excel_with_usage_flag(df):
    rows = []
    code_start_pattern = re.compile(r"^(\d+|[â‘ -â‘©]|[a-zA-Z]|[ê°€-í•˜])[\.\)\s=]\s*(.*)")
    for idx, row in df.iterrows():
        var_name = row['ë³€ìˆ˜ëª…']; raw_q = str(row['ì§ˆë¬¸ ë‚´ìš©']); clean_q = re.sub(r"^\[.*?\]\s*", "", raw_q)
        if "_" in var_name:
            base_var, suffix = var_name.rsplit("_", 1)
            if raw_q.startswith("["): final_q_label = raw_q
            else: final_q_label = f"{base_var}. {suffix}) {clean_q}"
        else: final_q_label = f"{var_name}. {clean_q}"
        vals_str = str(row['ë³´ê¸° ê°’']); formatted_values = ""
        if vals_str and vals_str.strip() != "" and vals_str != "nan":
            lines = vals_str.split('\n'); options = []; current_code = None; current_label_parts = []
            for line in lines:
                line = line.strip()
                if not line: continue
                is_new_code = False; temp_code = ""; temp_label = ""
                if "=" in line: is_new_code = True; temp_code, temp_label = line.split("=", 1)
                else:
                    match = code_start_pattern.match(line)
                    if match: is_new_code = True; temp_code, temp_label = match.groups()
                if is_new_code:
                    if current_code is not None: options.append(f"{current_code.strip()} = {' '.join(current_label_parts).strip()}")
                    current_code = temp_code; current_label_parts = [temp_label]
                else:
                    if current_code is not None: current_label_parts.append(line)
                    else: options.append(line)
            if current_code is not None: options.append(f"{current_code.strip()} = {' '.join(current_label_parts).strip()}")
            formatted_values = "\n".join(options) if options else vals_str
        rows.append({ "ì‚¬ìš©ì—¬ë¶€": "O", "Vë³€ìˆ˜": "", "ë³€ìˆ˜ëª…": var_name, "ì§ˆë¬¸ ë‚´ìš©": final_q_label, "ë³´ê¸°(Values)": formatted_values })
    result_df = pd.DataFrame(rows)
    var_list = df['ë³€ìˆ˜ëª…'].tolist(); var_counts = Counter(var_list); duplicates = [var for var, count in var_counts.items() if count > 1]
    highlight_fill = PatternFill(start_color="E6E6FA", end_color="E6E6FA", fill_type="solid")
    align_center = Alignment(horizontal='center', vertical='center', wrap_text=False)
    align_left = Alignment(horizontal='left', vertical='center', wrap_text=False)
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        result_df.to_excel(writer, index=False, sheet_name='Codebook')
        worksheet = writer.sheets['Codebook']
        for cell in worksheet[1]: cell.font = Font(bold=True); cell.alignment = Alignment(horizontal='center', vertical='center')
        for row in worksheet.iter_rows(min_row=2):
            for cell in row:
                if cell.column <= 3: cell.alignment = align_center; 
                if cell.column == 3 and cell.value in duplicates: cell.fill = highlight_fill
                if cell.column > 3: cell.alignment = align_left
        worksheet.column_dimensions['A'].width = 8; worksheet.column_dimensions['B'].width = 15; worksheet.column_dimensions['C'].width = 20; worksheet.column_dimensions['D'].width = 50; worksheet.column_dimensions['E'].width = 40
    return output.getvalue()

def compress_var_list(var_list):
    if not var_list: return ""
    compressed = []; current_chunk = []; pattern = re.compile(r"^(.*?)(\d+)$")
    for var in var_list:
        if not current_chunk: current_chunk.append(var); continue
        prev_var = current_chunk[-1]; match_prev = pattern.match(prev_var); match_curr = pattern.match(var)
        is_continuous = False
        if match_prev and match_curr:
            prev_prefix, prev_num = match_prev.groups(); curr_prefix, curr_num = match_curr.groups()
            if prev_prefix == curr_prefix and int(curr_num) == int(prev_num) + 1: is_continuous = True
        if is_continuous: current_chunk.append(var)
        else:
            if len(current_chunk) >= 3: compressed.append(f"{current_chunk[0]} TO {current_chunk[-1]}")
            else: compressed.extend(current_chunk)
            current_chunk = [var]
    if len(current_chunk) >= 3: compressed.append(f"{current_chunk[0]} TO {current_chunk[-1]}")
    else: compressed.extend(current_chunk)
    return " ".join(compressed)

# [FIX] utils ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ë‚´ë¶€ í•¨ìˆ˜
def generate_spss_final(df_edited, encoding_type='utf-8'):
    enc_str = "UTF-8" if encoding_type == 'utf-8' else "CP949"
    syntax_lines = ["* SPSS Syntax Generated by Streamlit (Final).", f"* Encoding: {enc_str}.", "", "* 0. Set Working Directory and Load Data.", "CD 'ê²½ë¡œ'.", "GET FILE='project_CE.sav'.", ""]
    if encoding_type == 'utf-8': syntax_lines.insert(2, "SET UNICODE=ON.")
    if 'ì‚¬ìš©ì—¬ë¶€' in df_edited.columns: df_target = df_edited[df_edited['ì‚¬ìš©ì—¬ë¶€'].isin(['O', 'R'])].copy()
    else: df_target = df_edited.copy()
    syntax_lines.append("* 1. Rename Variables (B -> C)."); rename_count = 0
    unique_rows = df_target.drop_duplicates(subset=['ë³€ìˆ˜ëª…'], keep='first')
    for idx, row in unique_rows.iterrows():
        v_clean = str(row['ë³€ìˆ˜ëª…']).strip(); v_raw = str(row['Vë³€ìˆ˜']).strip()
        if v_raw and v_raw.lower() != 'nan' and v_raw != v_clean: syntax_lines.append(f"Rename Var {v_raw}={v_clean}."); rename_count += 1
    if rename_count > 0: syntax_lines.append("EXECUTE."); syntax_lines.append("")
    syntax_lines.append("* 1.5 Recode Variables (Reverse Coding)."); recode_count = 0
    for idx, row in df_target.iterrows():
        if row['ì‚¬ìš©ì—¬ë¶€'] == 'R':
            v_name = row['ë³€ìˆ˜ëª…']; val_text = str(row['ë³´ê¸°(Values)'])
            if not v_name or val_text == 'nan' or not val_text.strip(): continue
            codes = []
            for line in val_text.split('\n'):
                if '=' in line: c = line.split('=', 1)[0].strip(); 
                if c.isdigit(): codes.append(int(c))
            if codes:
                min_c, max_c = min(codes), max(codes); recode_pairs = []; 
                for c in codes: new_c = max_c + min_c - c; recode_pairs.append(f"({c}={new_c})")
                recode_str = " ".join(recode_pairs); syntax_lines.append(f"RECODE {v_name} {recode_str}."); recode_count += 1
    if recode_count > 0: syntax_lines.append("EXECUTE."); syntax_lines.append("")
    syntax_lines.append("VARIABLE LABELS"); unique_vars = df_target.drop_duplicates(subset=['ë³€ìˆ˜ëª…'], keep='first')
    for idx, row in unique_vars.iterrows():
        v = str(row['ë³€ìˆ˜ëª…']).strip(); l = str(row['ì§ˆë¬¸ ë‚´ìš©']).strip().replace('"', "'")
        if v: syntax_lines.append(f'  {v} "{l}"')
    syntax_lines.append(".\nEXECUTE.\n"); syntax_lines.append("VALUE LABELS"); value_map = {}
    for idx, row in df_target.iterrows():
        v = str(row['ë³€ìˆ˜ëª…']).strip(); val_text = str(row['ë³´ê¸°(Values)']); is_reverse = (row['ì‚¬ìš©ì—¬ë¶€'] == 'R')
        if not v or val_text == 'nan' or not val_text.strip(): continue
        lines = val_text.split('\n'); codes_labels = []; codes_int = []
        if is_reverse:
            for line in lines:
                if '=' in line: c = line.split('=', 1)[0].strip(); 
                if c.isdigit(): codes_int.append(int(c))
            if codes_int: min_c, max_c = min(codes_int), max(codes_int)
        for line in lines:
            line = line.strip()
            if '=' in line:
                parts = line.split('=', 1); code = parts[0].strip(); label = parts[1].strip(); final_code = code
                if is_reverse and code.isdigit() and codes_int: c_int = int(code); new_c_int = max_c + min_c - c_int; final_code = str(new_c_int)
                if final_code and label: codes_labels.append((final_code, label))
        if codes_labels:
            try: codes_labels.sort(key=lambda x: int(x[0]))
            except: pass
            val_tuple = tuple(codes_labels)
            if val_tuple not in value_map: value_map[val_tuple] = []
            value_map[val_tuple].append(v)
    group_count = 0; total_groups = len(value_map)
    for val_tuple, var_list in value_map.items():
        group_count += 1
        var_block_str = compress_var_list(var_list); wrapped_vars = textwrap.wrap(var_block_str, width=80)
        for line in wrapped_vars: syntax_lines.append(f"  {line}")
        for code, label in val_tuple:
            label_clean = label.replace('"', "'"); syntax_lines.append(f'    {code} "{code}) {label_clean}"')
        if group_count < total_groups: syntax_lines.append("  /")
        else: syntax_lines.append("  .")
    syntax_lines.append("EXECUTE."); syntax_lines.append(""); syntax_lines.append("* 4. Save Data.")
    keep_vars = df_target['ë³€ìˆ˜ëª…'].drop_duplicates().tolist()
    if keep_vars:
        syntax_lines.append("SAVE OUTFILE='Project_DATA.sav'"); syntax_lines.append("  /KEEP="); 
        for var in keep_vars: syntax_lines.append(f"    {var}")
        syntax_lines.append("  .")
    else: syntax_lines.append("SAVE OUTFILE='Project_DATA.sav'.")
    syntax_lines.append("EXECUTE."); syntax_lines.append(""); syntax_lines.append("* 5. Export to Excel."); syntax_lines.append("GET FILE='Project_DATA.sav'."); syntax_lines.append("EXECUTE.")
    syntax_lines.append(""); syntax_lines.append("*_ SAVE - Values _."); syntax_lines.append("SAVE TRANSLATE OUTFILE='(RAW) Project_DATA.xlsx' /TYPE=XLS /VERSION=12 /MAP /REPLACE /FIELDNAMES /CELLS=VALUES.")
    syntax_lines.append(""); syntax_lines.append("*_ SAVE - Labels _."); syntax_lines.append("SAVE TRANSLATE OUTFILE='(LABEL) Project_DATA.xlsx' /TYPE=XLS /VERSION=12 /MAP /REPLACE /FIELDNAMES /CELLS=LABELS.")
    return "\n".join(syntax_lines)

# ==============================================================================
# Streamlit UI
# ==============================================================================
st.markdown("""
**[ê¸°ëŠ¥ ì„¤ëª…]**
* **ìŠ¤ë§ˆíŠ¸ ìŠ¤ìºë‹:** í‘œ ì „ì²´ë¥¼ ë¨¼ì € ë¶„ì„í•˜ì—¬ **[ìë…€ì •ë³´], [ì‹œê°„/ë¶„ ì…ë ¥], [ë‹¨ìˆœ ì…ë ¥], [ê³ ì • í•©ê³„], [ê°€ë¡œí˜• ì…ë ¥], [ê°€ë¡œí˜• ì²™ë„]** ë“±ì˜ ìœ í˜•ì„ ìë™ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.
* **ë³µí•© ë¬¸í•­ ì§€ì›:** A7 ì²˜ëŸ¼ í…ìŠ¤íŠ¸ ì•ˆì— ì…ë ¥ ì¹¸ì´ ì—¬ëŸ¬ ê°œ ìˆëŠ” ê²½ìš°(íšŒ/ì‹œê°„ ë“±)ë„ ìë™ìœ¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
* **ì§ˆë¬¸ ìš”ì•½ (Beta):** ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•˜ë©´, ì§ˆë¬¸ ë‚´ìš©ì˜ ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ë¥¼ ì œê±°í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•©ë‹ˆë‹¤.
""")

tab1, tab2 = st.tabs(["1ë‹¨ê³„: ì›Œë“œ â¡ï¸ ì—‘ì…€ ìƒì„±", "2ë‹¨ê³„: ì—‘ì…€ â¡ï¸ SPSS ìƒì„±"])

with tab1:
    st.header("1. ì›Œë“œ íŒŒì¼ íŒŒì‹±")
    uploaded_word = st.file_uploader("ì„¤ë¬¸ì§€(.docx) ì—…ë¡œë“œ", type=["docx"], key="word_uploader")
    if uploaded_word:
        if st.button("ë¶„ì„ ì‹œì‘", key="btn_analyze"):
            with st.spinner("ë¬¸ì„œ êµ¬ì¡° ì •ë°€ ë¶„ì„ ì¤‘..."):
                try: 
                    df_raw = parse_word_to_df(uploaded_word)
                    st.session_state['df_raw'] = df_raw
                    st.success(f"ë¶„ì„ ì™„ë£Œ! {len(df_raw)}ê°œ í•­ëª© ì¶”ì¶œë¨")
                except Exception as e: 
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                    
    if 'df_raw' in st.session_state:
        st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(st.session_state['df_raw'], use_container_width=True, height=400)
        
        # ìš”ì•½ ì˜µì…˜
        st.markdown("---")
        use_summary = st.checkbox("âœ‚ï¸ ê¸´ ì§ˆë¬¸ ë‚´ìš©ì„ ê°„ëµí•˜ê²Œ ìš”ì•½í•˜ê¸° (Beta)", 
                                  help="ì§ˆë¬¸ ëì˜ '~ì…ë‹ˆê¹Œ?', 'ê·€í•˜ì˜' ê°™ì€ ë¶ˆí•„ìš”í•œ ë¬¸êµ¬ë¥¼ ìë™ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤.")
        
        st.info("ì•„ë˜ ì—‘ì…€ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë‚´ìš©ì„ ìˆ˜ì •í•˜ì„¸ìš”.")
        
        if use_summary:
            df_to_download = st.session_state['df_raw'].copy()
            df_to_download['ì§ˆë¬¸ ë‚´ìš©'] = df_to_download['ì§ˆë¬¸ ë‚´ìš©'].apply(summarize_label_regex)
            excel_data = to_excel_with_usage_flag(df_to_download)
        else:
            excel_data = to_excel_with_usage_flag(st.session_state['df_raw'])
            
        st.download_button(
            label="ğŸ“¥ í¸ì§‘ìš© ì½”ë“œë¶ ë‹¤ìš´ë¡œë“œ (Codebook.xlsx)",
            data=excel_data,
            file_name="Codebook_Draft.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )

with tab2:
    st.header("2. SPSS ì‹ íƒìŠ¤ ìƒì„±")
    uploaded_excel = st.file_uploader("ìˆ˜ì •ëœ ì½”ë“œë¶(.xlsx) ì—…ë¡œë“œ", type=["xlsx"], key="excel_uploader")
    if uploaded_excel:
        try:
            df_edited = pd.read_excel(uploaded_excel)
            if 'ì‚¬ìš©ì—¬ë¶€' not in df_edited.columns: 
                st.error("âš ï¸ 1ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ì—‘ì…€ íŒŒì¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
            else:
                st.success("íŒŒì¼ ë¡œë“œ ì„±ê³µ!")
                df_filtered = df_edited[df_edited['ì‚¬ìš©ì—¬ë¶€'].isin(['O', 'R'])].copy()
                st.write(f"ì´ {len(df_edited)}ê°œ ì¤‘ {len(df_filtered)}ê°œ ë¬¸í•­ ì„ íƒë¨")
                
                col1, col2 = st.columns(2)
                
                # Option 1: UTF-8
                with col1:
                    try:
                        spss_utf8 = utils.generate_spss_final(df_edited, encoding_type='utf-8')
                    except:
                        spss_utf8 = generate_spss_final(df_edited, encoding_type='utf-8')
                        
                    st.download_button(
                        label="ğŸ’¾ (ì¶”ì²œ) SPSS ì‹ íƒìŠ¤ ë‹¤ìš´ë¡œë“œ (UTF-8)",
                        data=spss_utf8.encode('utf-8-sig'), 
                        file_name="Syntax_UTF8.sps",
                        mime="text/plain",
                        type="primary",
                        use_container_width=True
                    )
                    st.caption("ìµœì‹  ë²„ì „ SPSS ì‚¬ìš© ì‹œ ê¶Œì¥")

                # Option 2: CP949
                with col2:
                    try:
                        spss_cp949 = utils.generate_spss_final(df_edited, encoding_type='cp949')
                    except:
                        spss_cp949 = generate_spss_final(df_edited, encoding_type='cp949')

                    st.download_button(
                        label="ğŸ’¾ (êµ¬ë²„ì „) SPSS ì‹ íƒìŠ¤ ë‹¤ìš´ë¡œë“œ (CP949)",
                        data=spss_cp949.encode('cp949', errors='ignore'), 
                        file_name="Syntax_CP949.sps",
                        mime="text/plain",
                        type="secondary",
                        use_container_width=True
                    )
                    st.caption("SPSSì—ì„œ í•œê¸€ì´ ê¹¨ì§ˆ ë•Œ ì‚¬ìš©")
                
                with st.expander("ì‹ íƒìŠ¤ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (UTF-8 ê¸°ì¤€)"):
                    st.code(spss_utf8, language="spss")
        except Exception as e: 
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
