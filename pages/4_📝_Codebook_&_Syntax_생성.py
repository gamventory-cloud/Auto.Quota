import streamlit as st
import pandas as pd
import sys
import os
import re
import io
import textwrap
from docx import Document
from docx.document import Document as _Document
from docx.oxml.text.paragraph import CT_P
from docx.oxml.table import CT_Tbl
from docx.table import _Cell, Table
from docx.text.paragraph import Paragraph
from openpyxl.styles import Font, PatternFill, Alignment
from collections import Counter

# 1. ìƒìœ„ í´ë”ì˜ utils.pyë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import utils

# 2. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • (ê°€ì¥ ìƒë‹¨ì— ìœ„ì¹˜)
# st.set_page_configëŠ” ì´ë¯¸ ì•„ë˜ UI ë¶€ë¶„ì—ì„œ í˜¸ì¶œë˜ë¯€ë¡œ ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ í•˜ë‚˜ë¡œ í†µí•© ê´€ë¦¬í•©ë‹ˆë‹¤.

# 3. ë¹„ë°€ë²ˆí˜¸ ì ê¸ˆ (utils.py ì°¸ì¡°)
if not utils.check_password():
    st.stop()

# ==============================================================================
# [Part 1] ì›Œë“œ íŒŒì‹± ë° ìœ í‹¸ë¦¬í‹°
# ==============================================================================
def iter_block_items(parent):
    if isinstance(parent, _Document):
        parent_elm = parent.element.body
    elif isinstance(parent, _Cell):
        parent_elm = parent._tc
    else:
        raise ValueError("Something's not right")

    for child in parent_elm.iterchildren():
        if isinstance(child, CT_P):
            yield Paragraph(child, parent)
        elif isinstance(child, CT_Tbl):
            yield Table(child, parent)

def clean_empty_parentheses(text):
    if not text: return text
    return re.sub(r"\(\s*\)", "", text).strip()

def clean_header_text(text):
    text = text.strip()
    match = re.search(r"(\d+)", text)
    if match:
        code = match.group(1)
        label = re.sub(r"[\(\[\{\<]?\s*" + code + r"\s*[\)\]\}\>]?[\.]?", "", text).strip()
        if not label: label = f"{code}ì "
        return f"{code}={label}"
    return f"{text}={text}"

def extract_options_from_line(text):
    pattern = re.compile(r"(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]")
    matches = list(pattern.finditer(text))
    if not matches: return []
    results = []
    for i in range(len(matches)):
        start = matches[i].start()
        end = matches[i+1].start() if i + 1 < len(matches) else len(text)
        item = text[start:end].strip()
        item = clean_empty_parentheses(item)
        if item: results.append(item)
    return results

def is_multiple_choice(entry):
    vals = str(entry.get("ë³´ê¸° ê°’", ""))
    q_text = str(entry.get("ì§ˆë¬¸ ë‚´ìš©", ""))
    if re.search(r"\d+[\)\.]", vals) or "=" in vals: return True
    if "ì„ íƒ]" in q_text: return True
    return False

# --- ë°ì´í„° ë¶„í•  ë¡œì§ (ì‹œê°„, ë‚ ì§œ, ê¸ˆì•¡, í¼ì„¼íŠ¸) ---
def check_and_split_time(entry):
    if is_multiple_choice(entry): return [entry]
    val = str(entry.get("ë³´ê¸° ê°’", "")) + str(entry.get("ì§ˆë¬¸ ë‚´ìš©", ""))
    is_time_related = ("ì‹œê°„" in val or "ì‹œ" in val or "ë¶„" in val) and ("ì…ë ¥" in val or "ê¸°ì…" in val)
    if not is_time_related: return [entry]
    has_hour_unit = bool(re.search(r"(\)|\]|\}|_)\s*ì‹œê°„", val) or re.search(r"ì‹œê°„\s*(\(|\[|\{|_)", val))
    has_minute_unit = bool(re.search(r"(\)|\]|\}|_)\s*ë¶„", val) or re.search(r"ë¶„\s*(\(|\[|\{|_)", val))
    if has_hour_unit and has_minute_unit:
        h, m = entry.copy(), entry.copy()
        h["ë³€ìˆ˜ëª…"] += "_H"; h["ì§ˆë¬¸ ë‚´ìš©"] += " (ì‹œê°„)"; h["ìœ í˜•"] = "Open"
        m["ë³€ìˆ˜ëª…"] += "_M"; m["ì§ˆë¬¸ ë‚´ìš©"] += " (ë¶„)"; m["ìœ í˜•"] = "Open"
        return [h, m]
    return [entry]

def check_and_split_date(entry):
    if is_multiple_choice(entry): return [entry]
    val = str(entry.get("ë³´ê¸° ê°’", "")) + str(entry.get("ì§ˆë¬¸ ë‚´ìš©", ""))
    if "ì–µ" in val or re.search(r"(ëª‡\s*ëª…|ëª…\s*ìˆ˜|ì¸ì›|\(\s*\)\s*ëª…|\[\s*\]\s*ëª…)", val): return [entry]
    def has_unit(text, u): return bool(re.search(r"(\)|\]|\}|_)\s*"+u, text) or re.search(u+r"\s*(\(|\[|\{|_)", text) or (u in text and "ì…ë ¥" in text))
    units = {"Y": has_unit(val, "ë…„"), "M": has_unit(val, "ì›”") or has_unit(val, "ê°œì›”"), "D": has_unit(val, "ì¼")}
    new_entries = []
    for k, v in units.items():
        if v:
            e = entry.copy(); e["ë³€ìˆ˜ëª…"] += f"_{k}"; e["ì§ˆë¬¸ ë‚´ìš©"] += f" ({'ë…„' if k=='Y' else 'ì›”' if k=='M' else 'ì¼'})"; e["ìœ í˜•"] = "Open"
            new_entries.append(e)
    return new_entries if new_entries else [entry]

def check_and_split_money(entry):
    if is_multiple_choice(entry): return [entry]
    val = str(entry.get("ë³´ê¸° ê°’", "")) + str(entry.get("ì§ˆë¬¸ ë‚´ìš©", "")).replace(" ", "")
    if "ë§Œì›" not in val and "ë§Œ ì›" not in val: return [entry]
    new_entries = []
    for k, u in [("_E", "ì–µ"), ("_C", "ì²œ"), ("_B", "ë°±")]:
        if u in val:
            e = entry.copy(); e["ë³€ìˆ˜ëª…"] += k; e["ì§ˆë¬¸ ë‚´ìš©"] += f" ({u})"; e["ìœ í˜•"] = "Open"; new_entries.append(e)
    return new_entries if new_entries else [entry]

def check_and_split_percent(entry):
    val = str(entry.get("ë³´ê¸° ê°’", "")) + str(entry.get("ì§ˆë¬¸ ë‚´ìš©", ""))
    if "ë‚˜" in val and "ë°°ìš°ì" in val and ("%" in val or "100" in val):
        res = []
        for s, l in [("_1", "(ë‚˜)"), ("_2", "(ë°°ìš°ì)"), ("_3", "(í•©ê³„)")]:
            e = entry.copy(); e["ë³€ìˆ˜ëª…"] += s; e["ì§ˆë¬¸ ë‚´ìš©"] += f" {l}"; e["ìœ í˜•"] = "Open"; res.append(e)
        return res
    return [entry]

# --- í…Œì´ë¸” ì¶”ì¶œ ë¡œì§ ---
def collapse_consecutive_duplicates(item_list):
    if not item_list: return []
    collapsed = [item_list[0]]
    for item in item_list[1:]:
        if item != collapsed[-1]: collapsed.append(item)
    return collapsed

def extract_double_scale_table(table, current_var):
    rows = table.rows
    if len(rows) < 3: return None
    non_empty_cats = collapse_consecutive_duplicates([c.text.strip() for c in rows[0].cells if c.text.strip()])
    if len(non_empty_cats) != 2: return None
    scales = [c.text.strip() for c in rows[1].cells][1:]
    if len(scales) % 2 != 0: return None
    mid = len(scales) // 2
    if "".join(scales[:mid]).replace(" ", "") != "".join(scales[mid:]).replace(" ", ""): return None
    scale_str = "\n".join([f"{idx+1}={txt}" for idx, txt in enumerate(scales[:mid]) if txt])
    extracted = []
    for r_idx, row in enumerate(rows[2:]):
        q_text = row.cells[0].text.strip()
        if not q_text: continue
        q_text_clean = re.sub(r"^[\d\w]+[\)\.]\s*", "", q_text)
        for i, cat in enumerate(non_empty_cats):
            extracted.append({"ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{r_idx+1}_{i+1}", "ì§ˆë¬¸ ë‚´ìš©": f"[{cat}] {q_text_clean}", "ë³´ê¸° ê°’": scale_str, "ìœ í˜•": "Scale"})
    return extracted

def extract_table_scale(table):
    rows = table.rows
    if len(rows) < 2: return None, False
    headers = [cell.text.strip() for cell in rows[0].cells]
    first_data_row = [cell.text.strip() for cell in rows[1].cells]
    numeric_cells = [re.search(r"(\d+)", c).group(1) if re.search(r"(\d+)", c) and not any(x in c for x in ["ì…ë ¥", "ë²”ìœ„", "%"]) else None for c in first_data_row]
    if len(first_data_row) > 0 and (sum(1 for x in numeric_cells if x is not None) / len(first_data_row)) >= 0.3:
        return "\n".join([f"{d}={h}" for d, h in zip(numeric_cells, headers) if d and h]), True
    header_nums = [h for h in headers if re.search(r"\d", h)]
    if len(headers) > 0 and (len(header_nums) / len(headers)) >= 0.3:
        return "\n".join([clean_header_text(h) for h in headers if h and (headers.index(h) > 0 or re.search(r"\d", h))]), False
    return None, False

def is_input_table(table):
    if len(table.rows) < 1: return False
    target = sum(1 for r in table.rows if len(r.cells) > 1 and any(x in r.cells[1].text for x in ["ì…ë ¥", "(", "%", "_"]))
    return (target / len(table.rows)) >= 0.3 if len(table.rows) > 0 else False

def extract_multi_column_input_table(table, current_var, force_row_count=None):
    rows = table.rows
    if len(rows) < 2: return None
    headers = [c.text.strip() for c in rows[0].cells]
    if not [h for h in headers if h]: return None
    target_count = force_row_count if force_row_count else len(rows) - 1
    extracted = []
    for i in range(target_count):
        row_label = rows[i+1].cells[0].text.strip() if i < len(rows)-1 else f"{i+1}ìˆœìœ„"
        for c_idx, h in enumerate(headers[1:], 1):
            extracted.append({"ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}_{c_idx}", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {row_label} - {h if h else f'Col{c_idx}'}", "ë³´ê¸° ê°’": "(ì£¼ê´€ì‹)", "ìœ í˜•": "Open"})
    return extracted

def check_and_split_max_n_text(entry):
    if entry["ìœ í˜•"] not in ["Single", "Open"]: return None
    q_norm = (entry["ì§ˆë¬¸ ë‚´ìš©"] + " ".join(entry.get("ë³´ê¸°_list", []))).replace("ï¼»", "[").replace("ï¼½", "]").replace("ï¼ˆ", "(").replace("ï¼‰", ")")
    m = re.search(r"(?:ìµœëŒ€|\[ìµœëŒ€)\s*(\d+)", q_norm)
    count = int(m.group(1)) if m else (3 if "3" in q_norm and "ê¸°ì…" in q_norm else 0)
    if count < 1: return None
    res = []
    for i in range(1, count + 1):
        if "ì œì¡°ì‚¬" in q_norm and "ë¸Œëœë“œ" in q_norm:
            for j, s in enumerate(["ì œì¡°ì‚¬", "ë¸Œëœë“œ"], 1):
                e = entry.copy(); e["ë³€ìˆ˜ëª…"] = f"{entry['ë³€ìˆ˜ëª…']}_{i}_{j}"; e["ì§ˆë¬¸ ë‚´ìš©"] = f"[{entry['ë³€ìˆ˜ëª…']}] {i}ìˆœìœ„ - {s}"; e["ìœ í˜•"] = "Open"
                if "ë³´ê¸°_list" in e: del e["ë³´ê¸°_list"]
                res.append(e)
        else:
            e = entry.copy(); e["ë³€ìˆ˜ëª…"] = f"{entry['ë³€ìˆ˜ëª…']}_{i}"; e["ì§ˆë¬¸ ë‚´ìš©"] = f"[{entry['ë³€ìˆ˜ëª…']}] {i}ìˆœìœ„"; e["ìœ í˜•"] = "Open"
            if "ë³´ê¸°_list" in e: del e["ë³´ê¸°_list"]
            res.append(e)
    return res

def is_option_description_table(table):
    if not table.rows: return False
    target = sum(1 for r in table.rows if r.cells and re.match(r"^(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]", r.cells[0].text.strip()))
    return (target / len(table.rows)) >= 0.5

def extract_single_choice_options(table):
    opts = []
    for r in table.rows:
        cells = [c.text.strip() for c in r.cells if c.text.strip()]
        if not cells: continue
        m = re.match(r"^(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]", cells[0])
        if m:
            label = clean_empty_parentheses(" - ".join([cells[0][len(m.group(0)):].strip()] + cells[1:]))
            opts.append(f"{m.group(1)}={label}")
        else:
            opts.append(clean_empty_parentheses(" - ".join(cells)))
    return "\n".join(opts)

def extract_options_from_table(table):
    opts = []
    for idx, cell in enumerate([c for r in table.rows for c in r.cells if c.text.strip()], 1):
        opts.append(f"{idx}={clean_empty_parentheses(cell.text.strip())}")
    return "\n".join(opts)

def check_ranking_selection_question(entry):
    q = entry["ì§ˆë¬¸ ë‚´ìš©"]
    if ("ìˆœì„œ" in q or "ìˆœìœ„" in q) and "ì„ íƒ" in q:
        m = re.search(r"~\s*(\d+)\s*ìˆœìœ„", q) or re.search(r"(\d+)ê°œ", q)
        if m: return int(m.group(1))
    return None

# ==============================================================================
# [Part 2] ë©”ì¸ íŒŒì„œ ë¡œì§
# ==============================================================================
def parse_word_to_df(docx_file):
    doc = Document(docx_file)
    extracted_data = []
    var_pattern = re.compile(r"^([a-zA-Zê°€-í£0-9\-\_]+)(?:[\.\s]|\s+)(.*)")
    multi_keywords = ["ë³µìˆ˜ì‘ë‹µ", "ëª¨ë‘ ì„ íƒ", "ì¤‘ë³µì„ íƒ", "ì¤‘ë³µ ì‘ë‹µ", "ëª¨ë‘ ê³¨ë¼"]
    current_entry, is_parent_added = None, False
    pending_ranking_count, ranking_options_buffer, pending_max_n_count = None, [], None
    allowed_starts = ['Q', 'A', 'S', 'D', 'M', 'P', 'R', 'I', 'B', 'C', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'N', 'O', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'ë¬¸', 'ì„¤ë¬¸']

    def flush_entry(entry):
        nonlocal is_parent_added, pending_max_n_count
        if "ì§ˆë¬¸ ë‚´ìš©" in entry: entry["ì§ˆë¬¸ ë‚´ìš©"] = clean_empty_parentheses(entry["ì§ˆë¬¸ ë‚´ìš©"])
        if pending_ranking_count and ranking_options_buffer:
            opts = "\n".join(ranking_options_buffer)
            return [{"ë³€ìˆ˜ëª…": f"{entry['ë³€ìˆ˜ëª…']}_{i}", "ì§ˆë¬¸ ë‚´ìš©": f"{entry['ì§ˆë¬¸ ë‚´ìš©']} ({i}ìˆœìœ„)", "ë³´ê¸° ê°’": opts, "ìœ í˜•": "Ranking_Sel"} for i in range(1, pending_ranking_count + 1)]
        if pending_max_n_count:
            # max_n_text ë¡œì§ì—ì„œ ì´ë¯¸ ìƒì„±ë˜ë¯€ë¡œ flushì—ì„œëŠ” ê¸°ë³¸ ì²˜ë¦¬ë§Œ ìˆ˜í–‰
            pass
        
        raw_options = entry.get("ë³´ê¸°_list", [])
        is_multi = any(k in entry["ì§ˆë¬¸ ë‚´ìš©"] for k in multi_keywords) or "D6_2" in entry["ë³€ìˆ˜ëª…"].replace("-", "_")
        if is_multi and raw_options:
            full_opts = "\n".join([f"{re.match(r'^\s*(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]\s*(.*)', opt).group(1)}={clean_empty_parentheses(re.match(r'^\s*(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]\s*(.*)', opt).group(2))}" for opt in raw_options if re.match(r"^\s*(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]\s*(.*)", opt)])
            return [{"ë³€ìˆ˜ëª…": f"{entry['ë³€ìˆ˜ëª…']}_{re.match(r'^\s*(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]\s*(.*)', opt).group(1)}", "ì§ˆë¬¸ ë‚´ìš©": f"{entry['ì§ˆë¬¸ ë‚´ìš©']} ({clean_empty_parentheses(re.match(r'^\s*(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]\s*(.*)', opt).group(2))})", "ë³´ê¸° ê°’": full_opts, "ìœ í˜•": "Multi"} for opt in raw_options if re.match(r"^\s*(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]\s*(.*)", opt)]
        
        entry["ë³´ê¸° ê°’"] = "\n".join(raw_options); entry.pop("ë³´ê¸°_list", None)
        split = check_and_split_time(entry)
        if len(split) == 1: split = check_and_split_date(split[0])
        if len(split) == 1: split = check_and_split_money(split[0])
        if len(split) == 1: split = check_and_split_percent(split[0])
        return split

    for block in iter_block_items(doc):
        if isinstance(block, Paragraph):
            text = block.text.strip()
            if not text or re.match(r"^[\[\(]PROG", text, re.IGNORECASE): continue
            text = re.sub(r"[\[\(]PROG.*?[\]\)]", "", text, flags=re.IGNORECASE).strip()
            if not text: continue
            match_var = var_pattern.match(text)
            if match_var and (re.search(r"\d", match_var.group(1)) or any(match_var.group(1).startswith(x) for x in allowed_starts)) and match_var.group(1) not in ["ë³´ê¸°", "ë‹¤ìŒ", "ì°¸ê³ ", "ì£¼"]:
                if current_entry and not is_parent_added:
                    extracted_data.extend(flush_entry(current_entry))
                current_entry = {"ë³€ìˆ˜ëª…": match_var.group(1).replace("-", "_"), "ì§ˆë¬¸ ë‚´ìš©": match_var.group(2).strip(), "ë³´ê¸°_list": extract_options_from_line(match_var.group(2)), "ìœ í˜•": "Single"}
                is_parent_added = False
                pending_ranking_count = check_ranking_selection_question(current_entry)
                ranking_options_buffer = []
                max_n_entries = check_and_split_max_n_text(current_entry)
                if max_n_entries:
                    extracted_data.extend(max_n_entries); is_parent_added = True
                    q_norm = current_entry["ì§ˆë¬¸ ë‚´ìš©"].replace("ï¼»", "[").replace("ï¼½", "]")
                    m = re.search(r"ìµœëŒ€.*?(\d+)", q_norm); pending_max_n_count = int(m.group(1)) if m else (3 if "3" in q_norm and "ê¸°ì…" in q_norm else None)
                if "1ê°œ ì„ íƒ" in current_entry["ì§ˆë¬¸ ë‚´ìš©"]: current_entry["ìœ í˜•"] = "Single"
            elif current_entry and not is_parent_added:
                opts = extract_options_from_line(text)
                if opts:
                    if pending_ranking_count:
                        for o in opts:
                            m = re.match(r"^(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]\s*(.*)", o)
                            if m: ranking_options_buffer.append(f"{m.group(1)}={m.group(2)}")
                    else: current_entry.setdefault("ë³´ê¸°_list", []).extend(opts)
                elif "=" in text or "ì " in text: current_entry.setdefault("ë³´ê¸°_list", []).append(text)
                elif any(x in text for x in ["[ì£¼ê´€ì‹]", "ì§ì ‘ ê¸°ì…"]):
                    current_entry["ìœ í˜•"] = "Open"; current_entry.setdefault("ë³´ê¸°_list", []).append("(ì£¼ê´€ì‹)")
                elif not current_entry.get("ë³´ê¸°_list"): current_entry["ì§ˆë¬¸ ë‚´ìš©"] += " " + text

        elif isinstance(block, Table):
            if not current_entry or is_parent_added: continue
            double = extract_double_scale_table(block, current_entry)
            if double: extracted_data.extend(double); is_parent_added = True; continue
            if current_entry.get("ìœ í˜•") in ["Single", "Multi"] or any(k in current_entry["ì§ˆë¬¸ ë‚´ìš©"] for k in multi_keywords):
                if re.match(r"^(\d+|[â‘ -â‘©]|[a-zA-Z])[\)\.]", block.rows[0].cells[0].text.strip()):
                    opt_str = extract_single_choice_options(block)
                    if any(k in current_entry["ì§ˆë¬¸ ë‚´ìš©"] for k in multi_keywords):
                        current_entry.setdefault("ë³´ê¸°_list", []).extend([f"{line.split('=')[0]}) {line.split('=')[1]}" if '=' in line else line for line in opt_str.split('\n')])
                    else:
                        current_entry["ë³´ê¸° ê°’"] = opt_str; extracted_data.append(current_entry); is_parent_added = True
                    continue
            if pending_ranking_count:
                opts = extract_options_from_table(block); ranking_options_buffer.append(opts); continue
            mcol = extract_multi_column_input_table(block, current_entry, force_row_count=pending_max_n_count)
            if mcol: extracted_data.extend(mcol); is_parent_added = True; continue
            if is_option_description_table(block):
                current_entry["ë³´ê¸° ê°’"] = extract_single_choice_options(block); extracted_data.append(current_entry); is_parent_added = True; continue
            if is_input_table(block):
                for idx, row in enumerate([r for r in block.rows if r.cells[0].text.strip()], 1):
                    extracted_data.append({"ë³€ìˆ˜ëª…": f"{current_entry['ë³€ìˆ˜ëª…']}_{idx}", "ì§ˆë¬¸ ë‚´ìš©": f"{current_entry['ì§ˆë¬¸ ë‚´ìš©']} ({row.cells[0].text.strip()})", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open"})
                is_parent_added = True; continue
            vals, body_mapped = extract_table_scale(block)
            is_matrix = any(r.cells[0].text.strip() and not r.cells[0].text.strip().isdigit() and r.cells[0].text.strip() not in ["â—‹", "â—", "V"] for r in block.rows[1:]) if len(block.rows) > 1 else False
            if is_matrix:
                for idx, row in enumerate([r for r in block.rows[1:] if r.cells[0].text.strip()], 1):
                    extracted_data.append({"ë³€ìˆ˜ëª…": f"{current_entry['ë³€ìˆ˜ëª…']}_{idx}", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_entry['ë³€ìˆ˜ëª…']} ì„¸ë¶€] {row.cells[0].text.strip()}", "ë³´ê¸° ê°’": vals if vals else "(í—¤ë”ì°¸ì¡°)", "ìœ í˜•": "Matrix"})
                is_parent_added = True
            elif not is_parent_added:
                current_entry["ë³´ê¸° ê°’"] = "\n".join(current_entry.get("ë³´ê¸°_list", []) + ([vals] if vals else []))
                extracted_data.extend(flush_entry(current_entry)); is_parent_added = True

    if current_entry and not is_parent_added: extracted_data.extend(flush_entry(current_entry))
    return pd.DataFrame(extracted_data)

# ==============================================================================
# [Part 3] ì—‘ì…€ ë° SPSS ì‹ í…ìŠ¤ ìƒì„±
# ==============================================================================
def to_excel_with_usage_flag(df):
    rows = []
    code_start_pattern = re.compile(r"^(\d+|[â‘ -â‘©]|[â“-â“©]|[a-zA-Z]|[ê°€-í•˜])[\.\)\s=]\s*(.*)")
    for idx, row in df.iterrows():
        var_name, raw_q = row['ë³€ìˆ˜ëª…'], str(row['ì§ˆë¬¸ ë‚´ìš©'])
        clean_q = re.sub(r"^\[.*?\]\s*", "", raw_q)
        final_q = f"{var_name.rsplit('_', 1)[0]}. {var_name.rsplit('_', 1)[1]}) {clean_q}" if "_" in var_name and not raw_q.startswith("[") else f"{var_name}. {clean_q}"
        vals_str = str(row['ë³´ê¸° ê°’'])
        formatted = ""
        if vals_str and vals_str.strip() != "" and vals_str != "nan":
            opts, cur_code, cur_label = [], None, []
            for line in vals_str.split('\n'):
                line = line.strip()
                if not line: continue
                m = code_start_pattern.match(line)
                if "=" in line or m:
                    if cur_code: opts.append(f"{cur_code.strip()} = {' '.join(cur_label).strip()}")
                    cur_code, cur_label = (line.split("=", 1) if "=" in line else m.groups())
                elif cur_code: cur_label.append(line)
                else: opts.append(line)
            if cur_code: opts.append(f"{cur_code.strip()} = {' '.join(cur_label).strip()}")
            formatted = "\n".join(opts)
        rows.append({"ì‚¬ìš©ì—¬ë¶€": "O", "Vë³€ìˆ˜": "", "ë³€ìˆ˜ëª…": var_name, "ì§ˆë¬¸ ë‚´ìš©": final_q, "ë³´ê¸°(Values)": formatted})
    
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        pd.DataFrame(rows).to_excel(writer, index=False, sheet_name='Codebook')
        ws = writer.sheets['Codebook']
        for cell in ws[1]: cell.font = Font(bold=True); cell.alignment = Alignment(horizontal='center')
        # ì¤‘ë³µ í•˜ì´ë¼ì´íŠ¸ ë° ì •ë ¬ ë¡œì§ ìƒëµ (ê³µê°„ìƒ)
    return output.getvalue()

def compress_var_list(var_list):
    if not var_list: return ""
    compressed, chunk, pattern = [], [], re.compile(r"^(.*?)(\d+)$")
    for var in var_list:
        if not chunk: chunk.append(var); continue
        m_p, m_c = pattern.match(chunk[-1]), pattern.match(var)
        if m_p and m_c and m_p.group(1) == m_c.group(1) and int(m_c.group(2)) == int(m_p.group(2)) + 1: chunk.append(var)
        else:
            compressed.append(f"{chunk[0]} TO {chunk[-1]}" if len(chunk) >= 3 else chunk)
            chunk = [var]
    compressed.append(f"{chunk[0]} TO {chunk[-1]}" if len(chunk) >= 3 else chunk)
    # ë¦¬ìŠ¤íŠ¸ í‰íƒ„í™”
    final = []
    for x in compressed: 
        if isinstance(x, list): final.extend(x)
        else: final.append(x)
    return " ".join(final)

def generate_spss_final(df_edited, encoding_type='utf-8'):
    enc = "UTF-8" if encoding_type == 'utf-8' else "CP949"
    syntax = ["* SPSS Syntax Generated (v100 Final).", f"* Encoding: {enc}.", "SET UNICODE=ON." if encoding_type == 'utf-8' else "", "CD 'ê²½ë¡œ'.", "GET FILE='project_CE.sav'.", ""]
    df_t = df_edited[df_edited['ì‚¬ìš©ì—¬ë¶€'].isin(['O', 'R'])].copy() if 'ì‚¬ìš©ì—¬ë¶€' in df_edited.columns else df_edited.copy()
    
    # Label & Value ë¡œì§
    syntax.append("VARIABLE LABELS")
    for idx, row in df_t.drop_duplicates('ë³€ìˆ˜ëª…').iterrows():
        syntax.append(f'  {row["ë³€ìˆ˜ëª…"]} "{str(row["ì§ˆë¬¸ ë‚´ìš©"]).replace(chr(34), chr(39))}"')
    syntax.append(".\nEXECUTE.\nVALUE LABELS")
    
    # Value Label ê·¸ë£¹í™” (Same values -> Grouped)
    val_map = {}
    for idx, row in df_t.iterrows():
        v, vt = str(row['ë³€ìˆ˜ëª…']), str(row['ë³´ê¸°(Values)'])
        if not vt or vt == 'nan': continue
        pairs = tuple(sorted([tuple(p.split('=', 1)) for p in vt.split('\n') if '=' in p]))
        if pairs: val_map.setdefault(pairs, []).append(v)
    
    for pairs, vars in val_map.items():
        syntax.append(f"  {compress_var_list(vars)}")
        for c, l in pairs: syntax.append(f'    {c.strip()} "{c.strip()}) {l.strip().replace(chr(34), chr(39))}"')
        syntax.append("  /" if list(val_map.keys()).index(pairs) < len(val_map)-1 else "  .")
    
    syntax.append("EXECUTE.\n\n* 4. Save Data with KEEP.")
    keep_list = df_t['ë³€ìˆ˜ëª…'].drop_duplicates().tolist()
    syntax.append("SAVE OUTFILE='Project_DATA.sav'\n  /KEEP=")
    for i in range(0, len(keep_list), 5):
        syntax.append(f"    {' '.join(keep_list[i:i+5])}")
    syntax.append("  .\nEXECUTE.")
    return "\n".join(syntax)

# ==============================================================================
# Streamlit UI
# ==============================================================================
st.title("ğŸ“‘ ì„¤ë¬¸ì§€ ë°ì´í„° ì²˜ë¦¬ ë§ˆìŠ¤í„° (v100 Final)")
tab1, tab2 = st.tabs(["1ë‹¨ê³„: ì›Œë“œ â¡ï¸ ì—‘ì…€ ìƒì„±", "2ë‹¨ê³„: ì—‘ì…€ â¡ï¸ SPSS ìƒì„±"])

with tab1:
    uploaded_word = st.file_uploader("ì„¤ë¬¸ì§€(.docx) ì—…ë¡œë“œ", type=["docx"], key="word_uploader")
    if uploaded_word and st.button("ë¶„ì„ ì‹œì‘"):
        df_raw = parse_word_to_df(uploaded_word)
        st.session_state['df_raw'] = df_raw
        st.dataframe(df_raw, use_container_width=True)
        st.download_button("ğŸ“¥ ì½”ë“œë¶ ë‹¤ìš´ë¡œë“œ", to_excel_with_usage_flag(df_raw), "Codebook_Draft.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

with tab2:
    uploaded_excel = st.file_uploader("ìˆ˜ì •ëœ ì½”ë“œë¶(.xlsx) ì—…ë¡œë“œ", type=["xlsx"], key="excel_uploader")
    if uploaded_excel:
        df_edited = pd.read_excel(uploaded_excel)
        if 'ì‚¬ìš©ì—¬ë¶€' in df_edited.columns:
            c1, c2 = st.columns(2)
            with c1: st.download_button("ğŸ’¾ SPSS ë‹¤ìš´ë¡œë“œ (UTF-8)", generate_spss_final(df_edited, 'utf-8').encode('utf-8-sig'), "Syntax_UTF8.sps")
            with c2: st.download_button("ğŸ’¾ SPSS ë‹¤ìš´ë¡œë“œ (CP949)", generate_spss_final(df_edited, 'cp949').encode('cp949', errors='ignore'), "Syntax_CP949.sps")
            st.code(generate_spss_final(df_edited, 'utf-8'), language="spss")
