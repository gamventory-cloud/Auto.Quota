import streamlit as st
import pandas as pd
import sys
import os
import re
import io
import textwrap
import collections
from collections import Counter

# ì›Œë“œ/ì—‘ì…€ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from docx import Document
    from docx.document import Document as _Document
    from docx.oxml.text.paragraph import CT_P
    from docx.oxml.table import CT_Tbl
    from docx.table import _Cell, Table
    from docx.text.paragraph import Paragraph
    from docx.oxml.ns import qn 
    from openpyxl.styles import Font, PatternFill, Alignment
except ImportError:
    st.error("í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. requirements.txtì— 'python-docx'ì™€ 'openpyxl'ì„ ì¶”ê°€í•˜ì„¸ìš”.")
    st.stop()

# 1. ìƒìœ„ í´ë”ì˜ utils.pyë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import utils

# 2. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ì„¤ë¬¸ì§€ ì½”ë“œë¶ ìƒì„±", layout="wide")

# 3. ë¹„ë°€ë²ˆí˜¸ ì ê¸ˆ
if not utils.check_password():
    st.stop()

st.title("ğŸ“ ì„¤ë¬¸ì§€ ì½ê¸° & ì½”ë“œë¶/ì‹ í…ìŠ¤ ìë™ ìƒì„± (Full Logic)")

# ==============================================================================
# [Part 1] í•µì‹¬ ìœ í‹¸ë¦¬í‹° (ë™ê·¸ë¼ë¯¸ ìˆ«ì ëŒ€ì‘)
# ==============================================================================

CIRCLE_MAP = {'â‘ ':'1','â‘¡':'2','â‘¢':'3','â‘£':'4','â‘¤':'5','â‘¥':'6','â‘¦':'7','â‘§':'8','â‘¨':'9','â‘©':'10'}

def clean_empty_parentheses(text):
    if not text: return text
    return re.sub(r"\(\s*\)", "", text).strip()

def clean_header_text(text):
    text = text.strip()
    match = re.search(r"([â‘ -â‘©]|\d+)", text)
    if match:
        raw_code = match.group(1)
        code = CIRCLE_MAP.get(raw_code, raw_code)
        label = re.sub(r"[\(\[\{\<]?\s*" + re.escape(raw_code) + r"\s*[\)\]\}\>]?[\.]?", "", text).strip()
        if not label: label = f"{code}ì "
        return f"{code}={label}"
    return f"{text}={text}"

def extract_options_from_line(text):
    pattern = re.compile(r"([â‘ -â‘©]|(?:\d+|[a-zA-Z])[\)\.])")
    matches = list(pattern.finditer(text))
    if not matches:
        return []
    results = []
    for i in range(len(matches)):
        start = matches[i].start()
        end = matches[i+1].start() if i + 1 < len(matches) else len(text)
        item = text[start:end].strip()
        item = clean_empty_parentheses(item)
        if item:
            results.append(item)
    return results

def summarize_label_regex(text):
    if not text: return ""
    text = re.sub(r"\(PROG.*?\)", "", text, flags=re.IGNORECASE)
    text = re.sub(r"\[PROG.*?\]", "", text, flags=re.IGNORECASE)
    text = re.sub(r"\(.*?(ì…ë ¥|ê¸°ì…|ë²”ìœ„|ì„ íƒ).*?\)", "", text)
    text = re.sub(r"\[.*?(ì„ íƒ|ê¸°ì…|ì‘ë‹µ).*?\]", "", text)
    text = re.sub(r"^ë‹¤ìŒì€.*?ì§ˆë¬¸ì…ë‹ˆë‹¤\.?", "", text).strip()
    text = re.sub(r"^ë‹¤ìŒ.*?ëŒ€í•´.*?(ì„ íƒ|ì‘ë‹µ).*?ì£¼ì‹­ì‹œì˜¤\.?", "", text).strip()
    text = text.replace("ê·€í•˜ì˜ ", "").replace("ê·€í•˜ê»˜ì„œëŠ” ", "").replace("ê·€ ëŒì˜ ", "")
    text = text.replace("ì‘ë‹µì ë³¸ì¸ì˜ ", "").replace("í‰ì†Œ ", "")
    patterns = [
        r"ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ\?*$", r"ëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ\?*$", r"ëŠ” ë¬´ì—‡ì¸ê°€ìš”\?*$",
        r"ì„ ì„ íƒí•´ ì£¼ì‹­ì‹œì˜¤\.?$", r"ë¥¼ ì„ íƒí•´ ì£¼ì‹­ì‹œì˜¤\.?$",
        r"ì„ ì„ íƒí•´ ì£¼ì„¸ìš”\.?$", r"ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”\.?$",
        r"ì„ ê¸°ì…í•´ ì£¼ì‹­ì‹œì˜¤\.?$", r"ë¥¼ ê¸°ì…í•´ ì£¼ì‹­ì‹œì˜¤\.?$",
        r"ì„ ì…ë ¥í•˜ì—¬ ì£¼ì‹­ì‹œì˜¤\.?$", r"ë¥¼ ì…ë ¥í•˜ì—¬ ì£¼ì‹­ì‹œì˜¤\.?$",
        r"ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ì‹­ë‹ˆê¹Œ\?*$",
        r"ì •ë„ì…ë‹ˆê¹Œ\?*$", r"ë˜ì‹­ë‹ˆê¹Œ\?*$", r"ì¸ê°€ìš”\?*$", r"ìˆìŠµë‹ˆê¹Œ\?*$"
    ]
    for pat in patterns: text = re.sub(pat, "", text)
    replacements = { "ë§Œì¡±í•˜ëŠ” ì •ë„": "ë§Œì¡±ë„", "ì–¼ë§ˆë‚˜ ë§Œì¡±í•˜ì‹­ë‹ˆê¹Œ": "ë§Œì¡±ë„", "ì–¼ë§ˆë‚˜ ìì£¼": "ë¹ˆë„", "ì´ìœ ëŠ” ë¬´ì—‡": "ì´ìœ ", "ìƒê°ë‚˜ëŠ” ì´ë¯¸ì§€": "ì´ë¯¸ì§€", "êµ¬ì…í•œ ì ì´": "êµ¬ì… ê²½í—˜", "ì´ìš©í•œ ê²½í—˜": "ì´ìš© ê²½í—˜", "ì–´ë””ì…ë‹ˆê¹Œ": "ì¥ì†Œ", "ëˆ„êµ¬ì…ë‹ˆê¹Œ": "ëŒ€ìƒ" }
    for old, new in replacements.items(): 
        if old in text: text = text.replace(old, new)
    text = text.strip(); text = re.sub(r"\?+$", "", text); text = re.sub(r"\.$", "", text)
    return text.strip()

def iter_block_items(parent):
    if isinstance(parent, _Document):
        parent_elm = parent.element.body
    elif isinstance(parent, _Cell):
        parent_elm = parent._tc
    else:
        raise ValueError("iter_block_items: ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶€ëª¨ ê°ì²´ì…ë‹ˆë‹¤.")

    for child in parent_elm.iterchildren():
        if isinstance(child, CT_P):
            yield Paragraph(child, parent)
        elif isinstance(child, CT_Tbl):
            yield Table(child, parent)

# ==============================================================================
# [Part 2] ë³µí•© í…Œì´ë¸” ì¶”ì¶œê¸° (ê¸°ì¡´ ëª¨ë“  ë¡œì§ ìœ ì§€ + ë§¤íŠ¸ë¦­ìŠ¤ ê°•í™”)
# ==============================================================================

def extract_matrix_info(table):
    """B1~B4 ë§¤íŠ¸ë¦­ìŠ¤ 7ì  ì²™ë„ ê°ì§€ ë° ë¶„ë¦¬"""
    rows = table.rows
    if len(rows) < 2: return None, False
    headers = [cell.text.strip().replace('\n', ' ') for cell in rows[0].cells]
    first_data_cells = [cell.text.strip() for cell in rows[1].cells]
    scale_values = []
    for cell_text in first_data_cells:
        match = re.search(r"([â‘ -â‘©]|\d+)", cell_text)
        if match:
            raw = match.group(1)
            scale_values.append(CIRCLE_MAP.get(raw, raw))
        else: scale_values.append(None)
    valid_vals = [v for v in scale_values if v is not None]
    if len(first_data_cells) > 0 and (len(valid_vals) / len(first_data_cells)) >= 0.3:
        scale_pairs = []
        for i, val in enumerate(scale_values):
            if val is not None and i < len(headers) and headers[i]:
                scale_pairs.append(f"{val}={headers[i].strip()}")
        return "\n".join(scale_pairs), True
    return None, False

def extract_child_demographics_table(table, current_var):
    headers = [c.text.strip() for c in table.rows[0].cells]
    gender_col_idx = -1; birth_col_idx = -1
    for idx, h in enumerate(headers):
        if "ì„±ë³„" in h: gender_col_idx = idx
        if "ìƒë…„" in h or "ìƒì¼" in h: birth_col_idx = idx
    if gender_col_idx == -1 or birth_col_idx == -1: return None 
    extracted_entries = []
    for i, row in enumerate(table.rows[1:]): 
        cells = row.cells
        if len(cells) <= max(gender_col_idx, birth_col_idx): continue
        row_label = cells[0].text.strip()
        if not row_label: continue 
        gender_vals_str = ""
        gender_opts = extract_options_from_line(cells[gender_col_idx].text.strip())
        if gender_opts:
            g_lines = []
            for opt in gender_opts:
                m = re.match(r"^([â‘ -â‘©]|\d+|[a-zA-Z])[\)\.]?\s*(.*)", opt)
                if m: 
                    code = CIRCLE_MAP.get(m.group(1), m.group(1).replace(')','').replace('.',''))
                    g_lines.append(f"{code}={m.group(2).strip()}")
            gender_vals_str = "\n".join(g_lines)
        extracted_entries.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}_1", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {row_label} - ì„±ë³„", "ë³´ê¸° ê°’": gender_vals_str, "ìœ í˜•": "Single" })
        extracted_entries.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}_2", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {row_label} - ìƒë…„", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
    return extracted_entries

def extract_time_split_table(table, current_var):
    extracted = []
    for i, row in enumerate(table.rows):
        cells_text = [c.text.strip() for c in row.cells if c.text.strip()]
        if not cells_text: continue
        row_label = cells_text[0]
        extracted.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}_H", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {row_label} (ì‹œê°„)", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
        extracted.append({ "ë³€ìˆ˜ëª…": f"{current_var['ë³€ìˆ˜ëª…']}_{i+1}_M", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_var['ë³€ìˆ˜ëª…']}] {row_label} (ë¶„)", "ë³´ê¸° ê°’": "(ìˆ«ìì…ë ¥)", "ìœ í˜•": "Open" })
    return extracted

def analyze_table_structure(table):
    rows = table.rows
    if len(rows) < 1: return "UNKNOWN"
    all_text = " ".join([c.text.strip() for row in rows for c in row.cells])
    _, is_matrix = extract_matrix_info(table)
    if is_matrix: return "MATRIX_SCALE"
    if "ì„±ë³„" in all_text and ("ìƒë…„" in all_text or "ìƒì¼" in all_text): return "CHILD_DEMO"
    if "ì‹œê°„" in all_text and "ë¶„" in all_text and ("ì…ë ¥" in all_text or "(" in all_text): return "TIME_SPLIT"
    if "í•©ê³„" in all_text and ("%" in all_text or "100" in all_text): return "CONSTANT_SUM"
    return "STANDARD"

# ==============================================================================
# [Part 3] ë©”ì¸ íŒŒì„œ
# ==============================================================================

def parse_word_to_df(docx_file):
    doc = Document(docx_file)
    extracted_data = []
    var_pattern = re.compile(r"^([a-zA-Zê°€-í£0-9\-\_]+)(?:[\.\s]|\s+)(.*)")
    multi_keywords = ["ë³µìˆ˜ì‘ë‹µ", "ì¤‘ë³µì„ íƒ", "ëª¨ë‘ ê³¨ë¼", "ëª¨ë‘ ì„ íƒ", "ì¤‘ë³µ ì‘ë‹µ", "ì¤‘ë³µ ì„ íƒ", "ì¤‘ë³µ ê°€ëŠ¥"]
    current_entry = None
    is_parent_added = False 

    def flush_entry(entry):
        entry["ì§ˆë¬¸ ë‚´ìš©"] = clean_empty_parentheses(entry["ì§ˆë¬¸ ë‚´ìš©"])
        raw_options = entry.get("ë³´ê¸°_list", [])
        is_multi = any(k in entry["ì§ˆë¬¸ ë‚´ìš©"] for k in multi_keywords)
        clean_opts = []
        for opt in raw_options:
            m = re.match(r"^\s*([â‘ -â‘©]|\d+[\)\.])\s*(.*)", opt)
            if m:
                code = CIRCLE_MAP.get(m.group(1), m.group(1).replace(')','').replace('.',''))
                clean_opts.append(f"{code}={m.group(2).strip()}")
        
        if is_multi and clean_opts:
            full_val = "\n".join(clean_opts)
            return [{"ë³€ìˆ˜ëª…": f"{entry['ë³€ìˆ˜ëª…']}_{c.split('=')[0]}", "ì§ˆë¬¸ ë‚´ìš©": f"{entry['ì§ˆë¬¸ ë‚´ìš©']} ({c.split('=')[1]})", "ë³´ê¸° ê°’": full_val, "ìœ í˜•": "Multi"} for c in clean_opts]
        else:
            entry["ë³´ê¸° ê°’"] = "\n".join(clean_opts)
            if "ë³´ê¸°_list" in entry: del entry["ë³´ê¸°_list"]
            return [entry]

    for block in iter_block_items(doc):
        if isinstance(block, Paragraph):
            text = block.text.strip()
            if not text: continue
            match_var = var_pattern.match(text)
            if match_var and any(match_var.group(1).upper().startswith(p) for p in ['Q','S','A','B','C','D']):
                if current_entry and not is_parent_added:
                    extracted_data.extend(flush_entry(current_entry))
                current_entry = {"ë³€ìˆ˜ëª…": match_var.group(1).replace("-", "_"), "ì§ˆë¬¸ ë‚´ìš©": match_var.group(2), "ë³´ê¸°_list": extract_options_from_line(match_var.group(2)), "ìœ í˜•": "Single"}
                is_parent_added = False
            elif current_entry:
                opts = extract_options_from_line(text)
                if opts: current_entry["ë³´ê¸°_list"].extend(opts)
                elif not current_entry["ë³´ê¸°_list"]: current_entry["ì§ˆë¬¸ ë‚´ìš©"] += " " + text

        elif isinstance(block, Table):
            if not current_entry: continue
            t_type = analyze_table_structure(block)
            if t_type == "MATRIX_SCALE":
                scale_str, _ = extract_matrix_info(block)
                for i, row in enumerate(block.rows[1:]):
                    row_label = row.cells[0].text.strip()
                    if row_label and row_label not in CIRCLE_MAP:
                        extracted_data.append({"ë³€ìˆ˜ëª…": f"{current_entry['ë³€ìˆ˜ëª…']}_{i+1}", "ì§ˆë¬¸ ë‚´ìš©": f"[{current_entry['ë³€ìˆ˜ëª…']}] {row_label}", "ë³´ê¸° ê°’": scale_str, "ìœ í˜•": "Matrix"})
                is_parent_added = True
            elif t_type == "CHILD_DEMO":
                res = extract_child_demographics_table(block, current_entry)
                if res: extracted_data.extend(res); is_parent_added = True
            elif t_type == "TIME_SPLIT":
                res = extract_time_split_table(block, current_entry)
                if res: extracted_data.extend(res); is_parent_added = True

    if current_entry and not is_parent_added:
        extracted_data.extend(flush_entry(current_entry))
    return pd.DataFrame(extracted_data)

# ==============================================================================
# [Part 4] SPSS ì‹ í…ìŠ¤ ë° ì—‘ì…€ ì¶œë ¥ (ì™„ë²½ ë³µêµ¬)
# ==============================================================================

def generate_spss_syntax(df, encoding='utf-8'):
    """utils.py ì—ëŸ¬ ë°©ì§€ìš© ìì²´ ë‚´ì¥ ì‹ í…ìŠ¤ ìƒì„±ê¸°"""
    syntax = ["* SPSS Syntax Generated.", "SET UNICODE=ON." if encoding=='utf-8' else "SET UNICODE=OFF.", "", "VARIABLE LABELS"]
    for _, row in df.iterrows():
        syntax.append(f'  {row["ë³€ìˆ˜ëª…"]} "{row["ì§ˆë¬¸ ë‚´ìš©"]}"')
    syntax.append(".\nVALUE LABELS")
    for _, row in df.iterrows():
        val = str(row.get('ë³´ê¸°(Values)', row.get('ë³´ê¸° ê°’', '')))
        if val and '=' in val:
            syntax.append(f"  {row['ë³€ìˆ˜ëª…']}")
            for pair in val.split('\n'):
                if '=' in pair:
                    c, l = pair.split('=', 1)
                    syntax.append(f'    {c} "{l.strip()}"')
    syntax.append(".\nEXECUTE.")
    return "\n".join(syntax)

def to_excel_with_usage_flag(df):
    rows = []
    for _, row in df.iterrows():
        rows.append({ "ì‚¬ìš©ì—¬ë¶€": "O", "Vë³€ìˆ˜": "", "ë³€ìˆ˜ëª…": row['ë³€ìˆ˜ëª…'], "ì§ˆë¬¸ ë‚´ìš©": row['ì§ˆë¬¸ ë‚´ìš©'], "ë³´ê¸°(Values)": row['ë³´ê¸° ê°’'] })
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        pd.DataFrame(rows).to_excel(writer, index=False)
    return output.getvalue()

# ==============================================================================
# Streamlit UI
# ==============================================================================
st.set_page_config(page_title="ì„¤ë¬¸ì§€ ë°ì´í„° ì²˜ë¦¬ ë§ˆìŠ¤í„° (v100 Final)", layout="wide")
st.title("ğŸ“‘ ì„¤ë¬¸ì§€ ë°ì´í„° ì²˜ë¦¬ ë§ˆìŠ¤í„°")
st.markdown("""
**[ìµœì¢… ì—…ë°ì´íŠ¸ v100]**
* **Save with KEEP:** SPSS ì‹ íƒìŠ¤ ìƒì„± ì‹œ, 'ì‚¬ìš©ì—¬ë¶€'ê°€ O/Rì¸ ë³€ìˆ˜ë“¤ë§Œ `/KEEP=` ëª…ë ¹ì–´ë¡œ ê¸¸ê²Œ ë‚˜ì—´í•˜ì—¬ ì €ì¥í•˜ë„ë¡ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.
* **ì™„ë²½ í†µí•©:** ê¸°ì¡´ì˜ ëª¨ë“  ê¸°ëŠ¥(ìˆœìœ„í˜•, í‘œ íŒŒì‹±, PROG ì‚­ì œ, í•˜ì´í”ˆ ì²˜ë¦¬ ë“±)ì´ í¬í•¨ëœ ìµœì¢… ì™„ì„±ë³¸ì…ë‹ˆë‹¤.
""")

tab1, tab2 = st.tabs(["1ë‹¨ê³„: ì›Œë“œ â¡ï¸ ì—‘ì…€ ìƒì„±", "2ë‹¨ê³„: ì—‘ì…€ â¡ï¸ SPSS ìƒì„±"])

with tab1:
    st.header("1. ì›Œë“œ íŒŒì¼ íŒŒì‹±")
    uploaded_word = st.file_uploader("ì„¤ë¬¸ì§€(.docx) ì—…ë¡œë“œ", type=["docx"], key="word_uploader")
    if uploaded_word:
        if st.button("ë¶„ì„ ì‹œì‘", key="btn_analyze"):
            with st.spinner("ë¬¸ì„œ êµ¬ì¡° ì •ë°€ ë¶„ì„ ì¤‘..."):
                try: 
                    df_raw = parse_word_to_df(uploaded_word)
                    st.session_state['df_raw'] = df_raw
                    st.success(f"ë¶„ì„ ì™„ë£Œ! {len(df_raw)}ê°œ í•­ëª© ì¶”ì¶œë¨")
                except Exception as e: 
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                    
    if 'df_raw' in st.session_state:
        st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(st.session_state['df_raw'], use_container_width=True, height=400)
        
        st.info("ì•„ë˜ ì—‘ì…€ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë‚´ìš©ì„ ìˆ˜ì •í•˜ì„¸ìš”.")
        excel_data = to_excel_with_usage_flag(st.session_state['df_raw'])
        st.download_button(
            label="ğŸ“¥ í¸ì§‘ìš© ì½”ë“œë¶ ë‹¤ìš´ë¡œë“œ (Codebook.xlsx)",
            data=excel_data,
            file_name="Codebook_Draft.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )

with tab2:
    st.header("2. SPSS ì‹ íƒìŠ¤ ìƒì„±")
    uploaded_excel = st.file_uploader("ìˆ˜ì •ëœ ì½”ë“œë¶(.xlsx) ì—…ë¡œë“œ", type=["xlsx"], key="excel_uploader")
    if uploaded_excel:
        try:
            df_edited = pd.read_excel(uploaded_excel)
            if 'ì‚¬ìš©ì—¬ë¶€' not in df_edited.columns: 
                st.error("âš ï¸ 1ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ì—‘ì…€ íŒŒì¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
            else:
                st.success("íŒŒì¼ ë¡œë“œ ì„±ê³µ!")
                df_filtered = df_edited[df_edited['ì‚¬ìš©ì—¬ë¶€'].isin(['O', 'R'])].copy()
                st.write(f"ì´ {len(df_edited)}ê°œ ì¤‘ {len(df_filtered)}ê°œ ë¬¸í•­ ì„ íƒë¨")
                
                col1, col2 = st.columns(2)
                
                # Option 1: UTF-8
                with col1:
                    spss_utf8 = generate_spss_final(df_edited, encoding_type='utf-8')
                    st.download_button(
                        label="ğŸ’¾ (ì¶”ì²œ) SPSS ì‹ íƒìŠ¤ ë‹¤ìš´ë¡œë“œ (UTF-8)",
                        data=spss_utf8.encode('utf-8-sig'), 
                        file_name="Syntax_UTF8.sps",
                        mime="text/plain",
                        type="primary",
                        use_container_width=True
                    )
                    st.caption("ìµœì‹  ë²„ì „ SPSS ì‚¬ìš© ì‹œ ê¶Œì¥")

                # Option 2: CP949
                with col2:
                    spss_cp949 = generate_spss_final(df_edited, encoding_type='cp949')
                    st.download_button(
                        label="ğŸ’¾ (êµ¬ë²„ì „) SPSS ì‹ íƒìŠ¤ ë‹¤ìš´ë¡œë“œ (CP949)",
                        data=spss_cp949.encode('cp949', errors='ignore'), 
                        file_name="Syntax_CP949.sps",
                        mime="text/plain",
                        type="secondary",
                        use_container_width=True
                    )
                    st.caption("SPSSì—ì„œ í•œê¸€ì´ ê¹¨ì§ˆ ë•Œ ì‚¬ìš©")
                
                with st.expander("ì‹ íƒìŠ¤ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (UTF-8 ê¸°ì¤€)"):
                    st.code(spss_utf8, language="spss")
        except Exception as e: 
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
