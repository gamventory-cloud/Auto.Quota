import streamlit as st
import pandas as pd
import re
import io
import sys
import os

# 1. ìƒìœ„ í´ë”ì˜ utils.pyë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import utils

st.set_page_config(page_title="ì£¼ê´€ì‹ í’ˆì§ˆ ê²€ì‚¬", layout="wide")

if not utils.check_password():
    st.stop()

st.title("ğŸ’¬ ì£¼ê´€ì‹ ì‘ë‹µ í’ˆì§ˆ ê²€ì‚¬ê¸° (Advanced)")
st.markdown("""
* **ë‹¤ì¤‘ ì‹œíŠ¸ ì§€ì›:** ì—‘ì…€ íŒŒì¼ì˜ ì‹œíŠ¸ë³„ ë°ì´í„° ê°œìˆ˜ë¥¼ í™•ì¸í•˜ê³  **ì›í•˜ëŠ” ì‹œíŠ¸ë§Œ** í•©ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **í—¤ë” ì¡°ì •:** ë°ì´í„°ê°€ ëª‡ ë²ˆì§¸ ì¤„ë¶€í„° ì‹œì‘í•˜ëŠ”ì§€ ì§ì ‘ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")

# ==============================================================================
# 1. ë°ì´í„° ë¡œë“œ ë° ì‹œíŠ¸ ë³‘í•© ì„¤ì •
# ==============================================================================
st.subheader("1. ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ")
data_file = st.file_uploader("ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ (CSV, Excel, XLS)", type=['csv', 'xlsx', 'xls'])

if data_file:
    # 1. íŒŒì¼ ê¸°ë³¸ ì •ë³´ í™•ì¸
    filename = data_file.name.lower()
    merged_df = None
    
    # 2. ì—‘ì…€ íŒŒì¼ì¸ ê²½ìš° ì‹œíŠ¸ ë¶„ì„ ë° ì˜µì…˜ ì œê³µ
    if filename.endswith('.xlsx') or filename.endswith('.xls'):
        engine = 'xlrd' if filename.endswith('.xls') else 'openpyxl'
        try:
            # ëª¨ë“  ì‹œíŠ¸ë¥¼ ì¼ë‹¨ ì½ìŒ (í—¤ë” ì—†ì´ ì½ì–´ì„œ êµ¬ì¡° íŒŒì•…)
            xls = pd.ExcelFile(data_file, engine=engine)
            sheet_names = xls.sheet_names
            
            st.info(f"ğŸ“„ ì´ {len(sheet_names)}ê°œì˜ ì‹œíŠ¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # --- [ì„¤ì • ì˜µì…˜] ---
            c_opt1, c_opt2 = st.columns(2)
            with c_opt1:
                # ì‹œíŠ¸ ì„ íƒ (ê¸°ë³¸: ëª¨ë‘ ì„ íƒ)
                selected_sheets = st.multiselect("í•©ì¹  ì‹œíŠ¸ ì„ íƒ", sheet_names, default=sheet_names)
            with c_opt2:
                # í—¤ë” ìœ„ì¹˜ ì§€ì • (ê¸°ë³¸: 0ë²ˆì§¸ ì¤„)
                header_row_idx = st.number_input("ë³€ìˆ˜ëª…(Header)ì´ ìˆëŠ” í–‰ ë²ˆí˜¸ (0ë¶€í„° ì‹œì‘)", min_value=0, value=0)
            
            if not selected_sheets:
                st.warning("ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                st.stop()
                
            # --- [ë³‘í•© ë¡œì§] ---
            all_dfs = []
            valid_rows_log = []
            
            for sht in selected_sheets:
                # ì‚¬ìš©ìê°€ ì§€ì •í•œ header ìœ„ì¹˜ë¡œ ë‹¤ì‹œ ì½ê¸°
                df_sht = pd.read_excel(data_file, sheet_name=sht, header=header_row_idx, engine=engine)
                
                # ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬
                if not df_sht.empty:
                    df_sht['_Origin_Sheet'] = sht # ì¶œì²˜ ê¸°ë¡
                    all_dfs.append(df_sht)
                    valid_rows_log.append(f"- **{sht}**: {len(df_sht)}ëª…")
                else:
                    valid_rows_log.append(f"- {sht}: (ë¹„ì–´ìˆìŒ)")
            
            if all_dfs:
                # ignore_index=Trueë¡œ ì¸ë±ìŠ¤ ì¬ì„¤ì • (í‘œì§€ ì‹œíŠ¸ì˜ ë¹ˆ ê³µê°„ ì œê±° íš¨ê³¼)
                merged_df = pd.concat(all_dfs, ignore_index=True)
                
                # ë³‘í•© ë¡œê·¸ ì¶œë ¥
                with st.expander(f"ğŸ“Š ì‹œíŠ¸ë³„ ë°ì´í„° í˜„í™© í™•ì¸ (ì´ {len(merged_df)}í–‰)"):
                    st.markdown("\n".join(valid_rows_log))
                    
        except Exception as e:
            st.error(f"ì—‘ì…€ ì½ê¸° ì˜¤ë¥˜: {e}")
            st.stop()
            
    else: # CSV íŒŒì¼
        try:
            merged_df = utils.load_df(data_file)
        except Exception as e:
            st.error(f"CSV ì½ê¸° ì˜¤ë¥˜: {e}")
            st.stop()

    # ==============================================================================
    # 2. ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ë° ì»¬ëŸ¼ ì„ íƒ
    # ==============================================================================
    if merged_df is not None and not merged_df.empty:
        st.success(f"âœ… ë°ì´í„° ë³‘í•© ì™„ë£Œ: ì´ {len(merged_df)}í–‰ ë¡œë“œë¨")
        
        # ë¯¸ë¦¬ë³´ê¸° (ì „ì²´ ë°ì´í„°í”„ë ˆì„ ëª¨ë“œ)
        st.caption("â–¼ ë³‘í•©ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒë‹¨ 100ê°œ í–‰)")
        st.dataframe(merged_df.head(100), use_container_width=True)
        
        st.divider()
        st.subheader("2. ê²€ì‚¬ ëŒ€ìƒ ë° ê¸°ì¤€ ì„¤ì •")

        # ê²€ì‚¬í•  ì»¬ëŸ¼ ë‹¤ì¤‘ ì„ íƒ
        # (ìˆ«ìê°€ ì•„ë‹Œ ì»¬ëŸ¼ë§Œ í•„í„°ë§í•´ì„œ ë³´ì—¬ì£¼ë©´ ë” ì°¾ê¸° ì‰¬ì›€)
        cols = merged_df.columns.tolist()
        target_cols = st.multiselect("ê²€ì‚¬í•  ì£¼ê´€ì‹ ë¬¸í•­ ì„ íƒ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)", cols)
        
        # ê²€ì‚¬ ì˜µì…˜
        c1, c2, c3 = st.columns(3)
        with c1:
            min_len = st.number_input("ìµœì†Œ ê¸€ì ìˆ˜ (ì´ê²ƒë³´ë‹¤ ì§§ìœ¼ë©´ ì˜ì‹¬)", 1, 10, 2)
        with c2:
            check_korean_g = st.checkbox("ììŒ/ëª¨ìŒ ë‚¨ë°œ (ì˜ˆ: ã…‹ã…‹ã…‹, ã… ã… )", value=True)
        with c3:
            check_repeat = st.checkbox("ë™ì¼ ë¬¸ì ë°˜ë³µ (ì˜ˆ: aaaa, ...)", value=True)
        
        default_bad_words = "ì—†ìŒ, ëª¨ë¦„, ëª°ë¼, ëª°ë¼ìš”, ê·¸ëƒ¥, êµ¿, good, no, nothing, ., .., -, ?, !!"
        bad_words_input = st.text_area("ğŸš« ê±°ì ˆ/íšŒí”¼ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value=default_bad_words)
        bad_words = [w.strip() for w in bad_words_input.split(",") if w.strip()]

        # ==============================================================================
        # 3. ë¶„ì„ ë¡œì§ (ë‹¤ì¤‘ ì»¬ëŸ¼ ì¼ê´„ ì²˜ë¦¬)
        # ==============================================================================
        if st.button("ğŸ” ì¼ê´„ ë¶„ì„ ì‹œì‘", type="primary"):
            if not target_cols:
                st.warning("ë¶„ì„í•  ì»¬ëŸ¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                st.stop()

            all_bad_records = []
            progress_bar = st.progress(0)
            
            for idx, col in enumerate(target_cols):
                progress_bar.progress((idx + 1) / len(target_cols), text=f"ê²€ì‚¬ ì¤‘: {col}")
                
                # í•´ë‹¹ ì»¬ëŸ¼ ì¶”ì¶œ (ë¬¸ìì—´ ë³€í™˜)
                target_series = merged_df[col].astype(str).fillna("")
                
                for row_idx, text in target_series.items():
                    detected = []
                    clean_text = text.strip()
                    
                    # 'nan', 'None' ë“±ì˜ ë¬¸ìì—´ ì œì™¸
                    if not clean_text or clean_text.lower() in ['nan', 'none', '']:
                        continue

                    # (1) ê¸¸ì´ ì²´í¬
                    if len(clean_text) < min_len: detected.append("ê¸¸ì´ ë¯¸ë‹¬")
                    # (2) íšŒí”¼ ë‹¨ì–´
                    if clean_text in bad_words: detected.append("íšŒí”¼ ë‹¨ì–´")
                    # (3) ììŒ/ëª¨ìŒ
                    if check_korean_g and re.fullmatch(r"[ã„±-ã…ã…-ã…£\s]+", clean_text): detected.append("ììŒ/ëª¨ìŒ ë‚¨ë°œ")
                    # (4) ë°˜ë³µ
                    if check_repeat and re.search(r"(.)\1\1", clean_text): detected.append("ë¬¸ì ë°˜ë³µ")
                    # (5) íŠ¹ìˆ˜ë¬¸ì
                    if re.fullmatch(r"[^ê°€-í£a-zA-Z0-9]+", clean_text): detected.append("íŠ¹ìˆ˜ë¬¸ì/ìˆ«ìë§Œ ìˆìŒ")

                    if detected:
                        record = {
                            'Index': row_idx,
                            'ì¶œì²˜_ì‹œíŠ¸': merged_df.loc[row_idx, '_Origin_Sheet'] if '_Origin_Sheet' in merged_df.columns else 'Single',
                            'ëŒ€ìƒ_ë¬¸í•­': col,
                            'ì‘ë‹µ_ë‚´ìš©': text,
                            'ì˜ì‹¬_ì‚¬ìœ ': ", ".join(detected)
                        }
                        all_bad_records.append(record)

            progress_bar.empty()

            # ê²°ê³¼ ë¦¬í¬íŠ¸
            st.divider()
            if all_bad_records:
                bad_df = pd.DataFrame(all_bad_records)
                
                c_res1, c_res2 = st.columns([1, 3])
                with c_res1:
                    st.error(f"ğŸš¨ ì´ {len(bad_df)}ê±´ ë°œê²¬")
                    st.metric("ë°œê²¬ëœ ë¶ˆì„±ì‹¤ ì‘ë‹µ", f"{len(bad_df)}ê±´")
                with c_res2:
                    st.caption("ë¬¸í•­ë³„ ë°œìƒ ê±´ìˆ˜")
                    st.bar_chart(bad_df['ëŒ€ìƒ_ë¬¸í•­'].value_counts())
                
                st.dataframe(bad_df, use_container_width=True)
                
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    bad_df.to_excel(writer, index=False)
                
                st.download_button(
                    "ğŸ“¥ ë¶ˆì„±ì‹¤ ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ (xlsx)",
                    output.getvalue(),
                    "Bad_OpenEnds_Report.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary"
                )
            else:
                st.success("âœ… ì„ íƒí•œ ë¬¸í•­ë“¤ì—ì„œ ë¶ˆì„±ì‹¤ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    elif merged_df is not None and merged_df.empty:
        st.warning("âš ï¸ ë°ì´í„°ë¥¼ ì½ì–´ì™”ì§€ë§Œ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. 'í—¤ë” í–‰ ë²ˆí˜¸'ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
