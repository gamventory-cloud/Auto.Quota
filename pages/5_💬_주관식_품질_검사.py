import streamlit as st
import pandas as pd
import re
import io
import sys
import os

# 1. ìƒìœ„ í´ë”ì˜ utils.pyë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import utils

st.set_page_config(page_title="ì£¼ê´€ì‹ í’ˆì§ˆ ê²€ì‚¬", layout="wide")

if not utils.check_password():
    st.stop()

st.title("ğŸ’¬ ì£¼ê´€ì‹ ì‘ë‹µ í’ˆì§ˆ ê²€ì‚¬ê¸° (Multi-Sheet & Multi-Column)")
st.markdown("""
* **ë‹¤ì¤‘ ì‹œíŠ¸ ì§€ì›:** ì—‘ì…€ íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ìˆë‹¤ë©´ ìë™ìœ¼ë¡œ **í•˜ë‚˜ë¡œ í•©ì³ì„œ** ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
* **ë‹¤ì¤‘ ì»¬ëŸ¼ ê²€ì‚¬:** ì—¬ëŸ¬ ê°œì˜ ì£¼ê´€ì‹ ë¬¸í•­ì„ **í•œ ë²ˆì— ì„ íƒ**í•´ì„œ ì¼ê´„ ê²€ì‚¬í•©ë‹ˆë‹¤.
""")

# ==============================================================================
# 1. ë°ì´í„° ë¡œë“œ (ëª¨ë“  ì‹œíŠ¸ í†µí•© ê¸°ëŠ¥)
# ==============================================================================
data_file = st.file_uploader("ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ (CSV, Excel, XLS)", type=['csv', 'xlsx', 'xls'])

@st.cache_data(ttl=3600)
def load_data_all_sheets(file):
    """ì—‘ì…€ì˜ ëª¨ë“  ì‹œíŠ¸ë¥¼ ì½ì–´ì„œ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” í•¨ìˆ˜"""
    filename = file.name.lower()
    
    try:
        if filename.endswith('.csv'):
            return utils.load_df(file) # CSVëŠ” ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ
            
        elif filename.endswith('.xlsx') or filename.endswith('.xls'):
            # ì—”ì§„ ì„¤ì •
            engine = 'xlrd' if filename.endswith('.xls') else 'openpyxl'
            
            # sheet_name=Noneì´ë©´ ëª¨ë“  ì‹œíŠ¸ë¥¼ dict í˜•íƒœë¡œ ì½ìŒ {'ì‹œíŠ¸ëª…': df, ...}
            sheets_dict = pd.read_excel(file, sheet_name=None, engine=engine)
            
            # ëª¨ë“  ì‹œíŠ¸ ë°ì´í„°í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸
            all_dfs = []
            for sheet_name, sheet_df in sheets_dict.items():
                # ë°ì´í„°ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì¶”ê°€
                if not sheet_df.empty:
                    # ì‹œíŠ¸ êµ¬ë¶„ì„ ìœ„í•´ 'Sheet_Name' ì»¬ëŸ¼ ì¶”ê°€
                    sheet_df['_Origin_Sheet'] = sheet_name
                    all_dfs.append(sheet_df)
            
            if not all_dfs:
                return None
                
            # í•˜ë‚˜ë¡œ ë³‘í•© (ì»¬ëŸ¼ì´ ë‹¬ë¼ë„ í•©ì§‘í•©ìœ¼ë¡œ í•©ì¹¨)
            merged_df = pd.concat(all_dfs, ignore_index=True)
            return merged_df
            
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    return None

if data_file:
    df = load_data_all_sheets(data_file)
    
    if df is not None and not df.empty:
        st.success(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {len(df)}ëª… (ëª¨ë“  ì‹œíŠ¸ í†µí•©ë¨)")
        
        with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(df.head())
        
        st.markdown("---")
        
        # 2. ê²€ì‚¬í•  ì»¬ëŸ¼ ë‹¤ì¤‘ ì„ íƒ
        target_cols = st.multiselect("ê²€ì‚¬í•  ì£¼ê´€ì‹ ë¬¸í•­ë“¤ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)", df.columns)
        
        # 3. ê²€ì‚¬ ì˜µì…˜ ì„¤ì •
        st.subheader("âš™ï¸ ê²€ì‚¬ ê¸°ì¤€ ì„¤ì •")
        c1, c2, c3 = st.columns(3)
        with c1:
            min_len = st.number_input("ìµœì†Œ ê¸€ì ìˆ˜ (ì´ê²ƒë³´ë‹¤ ì§§ìœ¼ë©´ ì˜ì‹¬)", 1, 10, 2)
        with c2:
            check_korean_g = st.checkbox("ììŒ/ëª¨ìŒ ë‚¨ë°œ (ì˜ˆ: ã…‹ã…‹ã…‹, ã… ã… )", value=True)
        with c3:
            check_repeat = st.checkbox("ë™ì¼ ë¬¸ì ë°˜ë³µ (ì˜ˆ: aaaa, ...)", value=True)
        
        # ë¶ˆì„±ì‹¤ í‚¤ì›Œë“œ ì‚¬ì „
        default_bad_words = "ì—†ìŒ, ëª¨ë¦„, ëª°ë¼, ëª°ë¼ìš”, ê·¸ëƒ¥, êµ¿, good, no, nothing, ., .., -, ?, !!"
        bad_words_input = st.text_area("ğŸš« ê±°ì ˆ/íšŒí”¼ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ (ì‰¼í‘œë¡œ êµ¬ë¶„)", value=default_bad_words)
        bad_words = [w.strip() for w in bad_words_input.split(",") if w.strip()]

        # 4. ë¶„ì„ ë¡œì§ (ë‹¤ì¤‘ ì»¬ëŸ¼ ë°˜ë³µ)
        if st.button("ğŸ” ì¼ê´„ ë¶„ì„ ì‹œì‘", type="primary"):
            if not target_cols:
                st.warning("ë¶„ì„í•  ì»¬ëŸ¼ì„ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
                st.stop()

            # ê²°ê³¼ ìˆ˜ì§‘ìš© ë¦¬ìŠ¤íŠ¸
            all_bad_records = []
            
            # ì§„í–‰ë¥  í‘œì‹œ
            progress_bar = st.progress(0)
            
            for idx, col in enumerate(target_cols):
                # ì»¬ëŸ¼ë³„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress_bar.progress((idx + 1) / len(target_cols), text=f"ê²€ì‚¬ ì¤‘: {col}")
                
                # í•´ë‹¹ ì»¬ëŸ¼ ë°ì´í„° ì¶”ì¶œ
                target_series = df[col].astype(str).fillna("")
                
                # í–‰ ë‹¨ìœ„ ê²€ì‚¬
                for row_idx, text in target_series.items():
                    detected = []
                    clean_text = text.strip()
                    
                    # (1) ë¹ˆ ê°’/nan íŒ¨ìŠ¤
                    if not clean_text or clean_text.lower() == 'nan':
                        continue

                    # (2) ê¸¸ì´ ì²´í¬
                    if len(clean_text) < min_len:
                        detected.append("ê¸¸ì´ ë¯¸ë‹¬")
                    
                    # (3) ê±°ì ˆ/íšŒí”¼ ë‹¨ì–´ ì²´í¬
                    if clean_text in bad_words:
                        detected.append("íšŒí”¼ ë‹¨ì–´")
                    
                    # (4) ììŒ/ëª¨ìŒ ë‚¨ë°œ
                    if check_korean_g:
                        if re.fullmatch(r"[ã„±-ã…ã…-ã…£\s]+", clean_text):
                            detected.append("ììŒ/ëª¨ìŒ ë‚¨ë°œ")
                    
                    # (5) ë™ì¼ ë¬¸ì ë°˜ë³µ
                    if check_repeat:
                        if re.search(r"(.)\1\1", clean_text):
                            detected.append("ë¬¸ì ë°˜ë³µ")
                    
                    # (6) íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆëŠ” ê²½ìš°
                    if re.fullmatch(r"[^ê°€-í£a-zA-Z0-9]+", clean_text):
                        detected.append("íŠ¹ìˆ˜ë¬¸ì/ìˆ«ìë§Œ ìˆìŒ")

                    # ë¬¸ì œê°€ ë°œê²¬ë˜ë©´ ê¸°ë¡
                    if detected:
                        record = {
                            'Index': row_idx,
                            'ëŒ€ìƒ_ë¬¸í•­': col,
                            'ì‘ë‹µ_ë‚´ìš©': text,
                            'ì˜ì‹¬_ì‚¬ìœ ': ", ".join(detected),
                            'Origin_Sheet': df.loc[row_idx, '_Origin_Sheet'] if '_Origin_Sheet' in df.columns else 'Single'
                        }
                        all_bad_records.append(record)

            progress_bar.empty()

            # 5. ê²°ê³¼ ë¦¬í¬íŠ¸
            st.divider()
            
            if all_bad_records:
                bad_df = pd.DataFrame(all_bad_records)
                
                st.error(f"ğŸš¨ ì´ {len(bad_df)}ê±´ì˜ ë¶ˆì„±ì‹¤ ì˜ì‹¬ ì‘ë‹µì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                # ë¬¸í•­ë³„ ë°œìƒ ê±´ìˆ˜ ì°¨íŠ¸
                st.caption("ë¬¸í•­ë³„ ì˜ì‹¬ ì‘ë‹µ ê±´ìˆ˜")
                st.bar_chart(bad_df['ëŒ€ìƒ_ë¬¸í•­'].value_counts())
                
                # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
                st.dataframe(bad_df, use_container_width=True)
                
                # ë‹¤ìš´ë¡œë“œ
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    bad_df.to_excel(writer, index=False)
                
                st.download_button(
                    "ğŸ“¥ ë¶ˆì„±ì‹¤ ë¦¬ìŠ¤íŠ¸ í†µí•© ë‹¤ìš´ë¡œë“œ (xlsx)",
                    output.getvalue(),
                    "Bad_OpenEnds_All.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.success("âœ… ì„ íƒí•œ ëª¨ë“  ë¬¸í•­ì—ì„œ ë¶ˆì„±ì‹¤ ì‘ë‹µ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    elif df is None:
        pass # ì—ëŸ¬ ë©”ì‹œì§€ëŠ” load í•¨ìˆ˜ì—ì„œ ì¶œë ¥ë¨
    else:
        st.warning("âš ï¸ ë°ì´í„°ë¥¼ ì½ì–´ì™”ì§€ë§Œ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
