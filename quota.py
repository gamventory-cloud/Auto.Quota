import streamlit as st
import pandas as pd
import chardet
import io
import time
import collections
import traceback
import numpy as np
import re
import os
import altair as alt
from joblib import Parallel, delayed, cpu_count

# ==============================================================================
# [ê³µí†µ í•¨ìˆ˜] í…ìŠ¤íŠ¸ ì •ì œ ë° ë³€ìˆ˜ëª… ì²˜ë¦¬ í•¨ìˆ˜ (ì „ì—­ ìœ„ì¹˜)
# ==============================================================================
def clean_text(text):
    """ì¤„ë°”ê¿ˆ, íƒ­, ë¶ˆí•„ìš”í•œ ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤."""
    if pd.isna(text): return ""
    text = str(text).strip()
    return text.replace("\n", "").replace("\r", "").replace("\t", "")

def extract_base_name(text):
    """ì§ˆë¬¸ ë¼ë²¨ì—ì„œ ë§ˆì¹¨í‘œ(.) ì•ë¶€ë¶„ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    text = clean_text(text)
    if "." in text:
        return text.split(".")[0].strip()
    return text.strip()

def sanitize_var_name(text):
    """SPSS ë³€ìˆ˜ëª… ê·œì¹™ì— ë§ê²Œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤."""
    text = str(text)
    # [ìˆ˜ì •] í•˜ì´í”ˆ(-)ê³¼ ê³µë°±ì„ ë¨¼ì € ì–¸ë”ë°”(_)ë¡œ ì¹˜í™˜í•˜ì—¬ ìˆ«ì ë¶™ìŒ ë°©ì§€
    text = text.replace("-", "_").replace(" ", "_")
    # ê´„í˜¸, ìŠ¬ë˜ì‹œ ë“± ì œê±° (ì•ŒíŒŒë²³, ìˆ«ì, ì–¸ë”ë°”ë§Œ ë‚¨ê¹€)
    text = re.sub(r"[^a-zA-Z0-9_]", "", text)
    # ì—°ì†ëœ ì–¸ë”ë°”ëŠ” í•˜ë‚˜ë¡œ
    text = re.sub(r"__+", "_", text)
    return text

# [ë¹„ë°€ë²ˆí˜¸ ì ê¸ˆ ê¸°ëŠ¥ ì‹œì‘] ---------------------------------------------
def check_password():
    """Returns `True` if the user had the correct password."""

    def password_entered():
        """Checks whether a password entered by the user is correct."""
        if st.session_state["password"] == st.secrets["password"]:
            st.session_state["password_correct"] = True
            del st.session_state["password"]  # ë³´ì•ˆì„ ìœ„í•´ ë¹„ë°€ë²ˆí˜¸ ì‚­ì œ
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        # ì²˜ìŒ ì ‘ì† ì‹œ ì´ˆê¸°í™”
        st.session_state["password_correct"] = False

    if not st.session_state["password_correct"]:
        # ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ì°½ ë³´ì—¬ì£¼ê¸°
        st.title("ğŸ”’ ì ‘ì† ì œí•œ")
        st.text_input(
            "ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password", on_change=password_entered, key="password"
        )
        st.error("ì§€ì¸ë“¤ë§Œ ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ê³µê°œ í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤.")
        return False
    else:
        # ë¹„ë°€ë²ˆí˜¸ ë§ìŒ
        return True

if not check_password():
    st.stop()  # ë¹„ë°€ë²ˆí˜¸ í‹€ë¦¬ë©´ ì—¬ê¸°ì„œ ì½”ë“œ ì‹¤í–‰ ì¤‘ë‹¨! (ì•„ë˜ ë‚´ìš© ì•ˆ ë³´ì—¬ì¤Œ)
# [ë¹„ë°€ë²ˆí˜¸ ì ê¸ˆ ê¸°ëŠ¥ ë] ---------------------------------------------


# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Quota Master Pro", layout="wide")

# ì‚¬ì´ë“œë°”
st.sidebar.title("ğŸ§° ì‘ì—… ë©”ë‰´")
app_mode = st.sidebar.radio(
    "ë©”ë‰´ ì„ íƒ",
    ["ğŸ§¹ 1. ë¶ˆì„±ì‹¤ ì‘ë‹µì ì—ë””í„°", 
     "ğŸ“Š 2. ì¿¼í„° ìë™ í• ë‹¹ ì†”ë£¨ì…˜ (Turbo)", 
     "ğŸ› ï¸ 3. SPSS ë³€ìˆ˜ëª… ì •ì œ"] # ë©”ë‰´ ì¶”ê°€ë¨
)
st.sidebar.markdown("---")
n_cores = cpu_count()
st.sidebar.caption(f"ğŸ–¥ï¸ CPU ì½”ì–´: {n_cores}ê°œ ê°€ë™")

# --- í—¬í¼ í•¨ìˆ˜ ---
def load_df(file):
    if file is None: return None
    try:
        if file.name.endswith('.csv'):
            raw = file.read(); enc = chardet.detect(raw)['encoding']
            return pd.read_csv(io.BytesIO(raw), encoding=enc if enc else 'utf-8')
        return pd.read_excel(file)
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}"); return None

def clean_val(v):
    if pd.isna(v): return "NaN"
    return str(v).strip().split('.')[0]

def collect_values_from_cols(row, columns):
    values = set()
    for c in columns:
        val = row[c]
        if pd.notna(val) and str(val).strip() != "":
            values.add(str(val).strip().split('.')[0])
    return sorted(list(values))

def natural_key(string_):
    target = str(string_)
    return [int(s) if s.isdigit() else s.lower() for s in re.split(r'(\d+)', target)]

def transform_pivoted_quota(df_raw):
    try:
        qt3_labels = [clean_val(x) for x in df_raw.iloc[1, 2:].dropna().values]
        data_rows = df_raw.iloc[2:].copy()
        data_rows.iloc[:, 0] = data_rows.iloc[:, 0].ffill()
        data_rows.columns = ['qt1', 'qt2'] + qt3_labels
        flat = data_rows.melt(id_vars=['qt1', 'qt2'], var_name='qt3', value_name='target')
        for col in ['qt1', 'qt2', 'qt3']: flat[col] = flat[col].apply(clean_val)
        flat['target'] = pd.to_numeric(flat['target'], errors='coerce').fillna(0).astype(int)
        return flat
    except: return None

def sanitize_sheet_name(name):
    safe_name = re.sub(r'[\\/*?:\[\]]', '_', str(name))
    if len(safe_name) > 30:
        return safe_name[:28] + ".."
    return safe_name

# ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤
def simulation_worker(seed, num_iters, indices, scarcity_scores, m_keys, ex_keys_list, main_map, ex_maps, soft_target):
    np.random.seed(seed)
    local_best_cnt = 0
    local_best_idxs = []
    n_rows = len(indices)
    
    for _ in range(num_iters):
        noise = np.random.uniform(0, 0.5, size=n_rows)
        scores = scarcity_scores + noise
        sorted_arg = np.argsort(scores) 
        
        m_cnt = collections.defaultdict(int)
        ex_cnts = [collections.defaultdict(int) for _ in range(len(ex_maps))]
        curr_idx = []
        curr_c = 0
        
        for i in sorted_arg:
            mk = m_keys[i]
            limit = main_map.get(mk, 0)
            if limit > 0 and m_cnt[mk] < limit:
                all_extras_ok = True
                for j, e_map in enumerate(ex_maps):
                    if not e_map: continue 
                    keys = ex_keys_list[j][i]
                    for k in keys:
                        if k in e_map and ex_cnts[j][k] >= e_map[k]:
                            all_extras_ok = False; break
                    if not all_extras_ok: break
                
                if all_extras_ok:
                    m_cnt[mk] += 1
                    for j, e_map in enumerate(ex_maps):
                        if e_map:
                            for k in ex_keys_list[j][i]: ex_cnts[j][k] += 1
                    curr_idx.append(indices[i])
                    curr_c += 1
        
        if curr_c > local_best_cnt:
            local_best_cnt = curr_c
            local_best_idxs = list(curr_idx)
            if local_best_cnt >= soft_target: break
                
    return local_best_cnt, local_best_idxs

# ================================================================================
# APP MODE 1: ë¶ˆì„±ì‹¤ ì—ë””í„°
# ================================================================================
if app_mode == "ğŸ§¹ 1. ë¶ˆì„±ì‹¤ ì‘ë‹µì ì—ë””í„°":
    st.title("ğŸ§¹ ë¶ˆì„±ì‹¤ ì‘ë‹µì ì œê±° ì—ë””í„°")
    data_file = st.file_uploader("ë°ì´í„° ì—…ë¡œë“œ", type=['csv', 'xlsx'])
    if data_file:
        df_raw = load_df(data_file)
        st.write(f"ë°ì´í„°: {len(df_raw)}ëª…")
        
        if 'ed_grps' not in st.session_state: st.session_state.ed_grps = [{'cols':[]}]
        
        c1, c2 = st.columns([1,5])
        with c1: 
            if st.button("â• ê·¸ë£¹ì¶”ê°€"): st.session_state.ed_grps.append({'cols':[]}); st.rerun()
        with c2:
            if len(st.session_state.ed_grps)>1 and st.button("â– ì‚­ì œ"): st.session_state.ed_grps.pop(); st.rerun()

        c_tool1, c_tool2 = st.columns([1, 3])
        with c_tool1:
            target_idx = st.selectbox("ë‹´ì„ ê·¸ë£¹", range(len(st.session_state.ed_grps)), format_func=lambda x: f"ê·¸ë£¹ {x+1}")
            w_key_target = f"ed_ms_{target_idx}"
        with c_tool2:
            t1, t2 = st.tabs(["ğŸ”¤ í‚¤ì›Œë“œ", "â†”ï¸ ë²”ìœ„"])
            with t1:
                ck1, ck2 = st.columns([2,1])
                kwd = ck1.text_input("í‚¤ì›Œë“œ", placeholder="Q1_", label_visibility="collapsed")
                if ck2.button("ë‹´ê¸° (í‚¤ì›Œë“œ)"):
                    if kwd:
                        found = [c for c in df_raw.columns if kwd in c]
                        cur = set(st.session_state.ed_grps[target_idx]['cols'])
                        upd = list(cur.union(set(found)))
                        upd.sort(key=lambda x: list(df_raw.columns).index(x))
                        st.session_state.ed_grps[target_idx]['cols'] = upd
                        st.session_state[w_key_target] = upd
                        st.rerun()
            with t2:
                cr1, cr2, cr3 = st.columns([1,1,1])
                cols = list(df_raw.columns)
                s_c = cr1.selectbox("Start", cols)
                e_c = cr2.selectbox("End", cols)
                if cr3.button("ë‹´ê¸° (ë²”ìœ„)"):
                    try:
                        si = cols.index(s_c); ei = cols.index(e_c)
                        if si<=ei:
                            rng = cols[si:ei+1]
                            cur = set(st.session_state.ed_grps[target_idx]['cols'])
                            upd = list(cur.union(set(rng)))
                            upd.sort(key=lambda x: cols.index(x))
                            st.session_state.ed_grps[target_idx]['cols'] = upd
                            st.session_state[w_key_target] = upd
                            st.rerun()
                    except: pass

        df_cln = df_raw.copy(); bad_ids = set()
        for i, g in enumerate(st.session_state.ed_grps):
            k=f"ed_ms_{i}"; 
            if k not in st.session_state: st.session_state[k]=g['cols']
            sel = st.multiselect(f"ê·¸ë£¹ {i+1}", df_raw.columns, key=k)
            st.session_state.ed_grps[i]['cols']=sel
            if sel:
                try:
                    std = df_raw[sel].apply(pd.to_numeric, errors='coerce').std(axis=1)
                    bad = std[std==0].index.tolist()
                    if bad: st.error(f"{len(bad)}ëª… ë¶ˆì„±ì‹¤"); bad_ids.update(bad)
                except: pass
        
        if bad_ids:
            if st.button("ì œê±° í›„ ë‹¤ìš´ë¡œë“œ"):
                final = df_cln.drop(index=list(bad_ids))
                out = io.BytesIO()
                with pd.ExcelWriter(out, engine='xlsxwriter') as w: final.to_excel(w, index=False)
                st.download_button("ë‹¤ìš´ë¡œë“œ", out.getvalue(), "cleaned.xlsx")

# ================================================================================
# APP MODE 2: ì¿¼í„° ì†”ë£¨ì…˜ (ë³´ì¡´ ë¡œì§ ê°•í™”)
# ================================================================================
elif app_mode == "ğŸ“Š 2. ì¿¼í„° ìë™ í• ë‹¹ ì†”ë£¨ì…˜ (Turbo)":
    st.title("ğŸ“Š ì¿¼í„° ìë™ í• ë‹¹ ì†”ë£¨ì…˜ (Turbo + Visual)")
    
    st.subheader("1. ë°ì´í„° ì—…ë¡œë“œ")
    data_file = st.file_uploader("ì„¤ë¬¸ ë°ì´í„°", type=['csv', 'xlsx'], key="quota_up")
    
    if data_file:
        df_survey = load_df(data_file)
        st.success(f"ë¡œë“œ ì™„ë£Œ: {len(df_survey)}ëª…")
        st.divider()

        st.subheader("2. ì¿¼í„° ì„¤ì •")
        use_main = st.checkbox("âœ… ë©”ì¸ ì¿¼í„° ì‚¬ìš©", value=True)
        main_map = {}; algo_main_cols = []
        
        if use_main:
            q_mode = st.radio("ë©”ì¸ ì¿¼í„° ë°©ì‹", ["ì—‘ì…€ ì—…ë¡œë“œ", "í™”ë©´ ì„¤ê³„"], horizontal=True)
            if q_mode == "ì—‘ì…€ ì—…ë¡œë“œ":
                qf = st.file_uploader("ì¿¼í„° íŒŒì¼", type=['xlsx'])
                c1,c2,c3 = st.columns(3)
                with c1: q1=st.selectbox("qt1", df_survey.columns)
                with c2: q2=st.selectbox("qt2", df_survey.columns)
                with c3: q3=st.selectbox("qt3", df_survey.columns)
                if qf:
                    algo_main_cols=[q1,q2,q3]
                    try:
                        raw = pd.read_excel(qf,0,header=None)
                        flat = transform_pivoted_quota(raw)
                        main_map = {(r.qt1, r.qt2, r.qt3): r.target for r in flat.itertuples()}
                    except: st.error("ì—‘ì…€ ì˜¤ë¥˜")
            else:
                rv = st.multiselect("í–‰(Row) ë³€ìˆ˜", df_survey.columns)
                cv = st.selectbox("ì—´(Col) ë³€ìˆ˜", ["(ì„ íƒ)"]+list(df_survey.columns))
                if rv and cv!="(ì„ íƒ)":
                    algo_main_cols = rv+[cv]
                    base = df_survey.copy()
                    for c in algo_main_cols:
                        base[c]=base[c].apply(clean_val)
                        uv=sorted(base[c].unique(), key=natural_key)
                        base[c]=pd.Categorical(base[c], categories=uv, ordered=True)
                    pi = base.groupby(algo_main_cols, observed=False).size().unstack(fill_value=0)
                    ed = st.data_editor(pi.reset_index(), use_container_width=True, disabled=rv)
                    mlt = ed.melt(id_vars=rv, var_name=cv, value_name='target')
                    for _,r in mlt.iterrows():
                        try:
                            t=int(r['target'])
                            if t>0: main_map[tuple(str(r[c]) for c in algo_main_cols)]=t
                        except: pass
        else:
            main_map = {('All',): st.number_input("ì „ì²´ ëª©í‘œ", 1, 10000, 1000)}; algo_main_cols=[]

        ex_configs = []
        tabs = st.tabs(["ì¶”ê°€ 1", "ì¶”ê°€ 2", "ì¶”ê°€ 3", "ì¶”ê°€ 4"])
        
        for i, tab in enumerate(tabs):
            with tab:
                ex_mode = st.radio(f"ì„¤ì • ë°©ì‹ (ê·¸ë£¹ {i+1})", ["ë‹¨ìˆœí˜• (ë³€ìˆ˜ ê°’ë³„ í• ë‹¹)", "ì¡°í•©í˜• (í–‰/ì—´ êµì°¨ í• ë‹¹)"], key=f"ex_mode_{i}", horizontal=True)
                
                config = {'cols': [], 'map': {}, 'name': f"Extra_{i+1}", 'mode': 'simple'}
                
                if ex_mode.startswith("ë‹¨ìˆœí˜•"):
                    config['mode'] = 'simple'
                    cols = st.multiselect(f"ë³€ìˆ˜ ì„ íƒ (ê·¸ë£¹ {i+1})", df_survey.columns, key=f"ms{i}")
                    if cols:
                        config['cols'] = cols
                        auto_name = "_".join([str(c) for c in cols])
                        config['name'] = sanitize_sheet_name(auto_name)
                        
                        vals = []
                        for _, r in df_survey[cols].fillna("").iterrows(): vals.extend(collect_values_from_cols(r, cols))
                        cnt = pd.DataFrame.from_dict(collections.Counter(vals), orient='index', columns=['í˜„ì¬']).reset_index()
                        cnt.columns=['ê°’','í˜„ì¬']; cnt['ëª©í‘œ']=cnt['í˜„ì¬']
                        cnt['srt']=cnt['ê°’'].apply(natural_key)
                        ed = st.data_editor(cnt.sort_values('srt').drop(columns=['srt']), use_container_width=True, key=f"ed{i}")
                        for _,r in ed.iterrows(): 
                            if r['ëª©í‘œ']>0: config['map'][str(r['ê°’'])]=int(r['ëª©í‘œ'])
                
                else:
                    config['mode'] = 'grid'
                    st.caption("ë©”ì¸ ì¿¼í„°ì²˜ëŸ¼ í–‰ê³¼ ì—´ì„ êµì°¨í•˜ì—¬ ìƒì„¸ ëª©í‘œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.")
                    ex_rv = st.multiselect(f"í–‰(Row) ë³€ìˆ˜ (ê·¸ë£¹ {i+1})", df_survey.columns, key=f"ex_rv_{i}")
                    ex_cv = st.selectbox(f"ì—´(Col) ë³€ìˆ˜ (ê·¸ë£¹ {i+1})", ["(ì„ íƒ)"]+list(df_survey.columns), key=f"ex_cv_{i}")
                    
                    if ex_rv and ex_cv != "(ì„ íƒ)":
                        target_cols = ex_rv + [ex_cv]
                        config['cols'] = target_cols
                        auto_name = "_".join([str(c) for c in target_cols])
                        config['name'] = sanitize_sheet_name(auto_name)
                        
                        base = df_survey.copy()
                        for c in target_cols:
                            base[c] = base[c].apply(clean_val)
                            uv = sorted(base[c].unique(), key=natural_key)
                            base[c] = pd.Categorical(base[c], categories=uv, ordered=True)
                        
                        pi = base.groupby(target_cols, observed=False).size().unstack(fill_value=0)
                        ed = st.data_editor(pi.reset_index(), use_container_width=True, disabled=ex_rv, key=f"ex_ed_grid_{i}")
                        
                        mlt = ed.melt(id_vars=ex_rv, var_name=ex_cv, value_name='target')
                        for _, r in mlt.iterrows():
                            try:
                                t = int(r['target'])
                                if t > 0:
                                    key_tuple = tuple(str(r[c]) for c in target_cols)
                                    config['map'][key_tuple] = t
                            except: pass

                ex_configs.append(config)

        st.divider()
        st.subheader("3. ì‹¤í–‰ ì˜µì…˜")
        c1, c2 = st.columns(2)
        with c1:
            c_no = st.selectbox("ID ì»¬ëŸ¼", df_survey.columns)
            tol = st.number_input("í—ˆìš© ì˜¤ì°¨", 0, 100, 0)
        with c2:
            iters = st.number_input("ì‹œë„ íšŸìˆ˜", 100, 1000000, 10000, 1000)
            use_intval = st.checkbox("intval ìµœì í™”", value=True)
            c_int = st.selectbox("intval ì»¬ëŸ¼", df_survey.columns) if use_intval else None

        if st.button("ğŸš€ ë§¤ì¹­ ì‹œì‘ (Turbo)", type="primary"):
            if not main_map: st.error("ëª©í‘œ ì—†ìŒ"); st.stop()
            
            try:
                with st.spinner("ì¢…í•© í¬ì†Œì„± ê³„ì‚° ë° ë³‘ë ¬ ì—°ì‚° ì¤‘..."):
                    df_proc = df_survey.copy()
                    if use_main:
                        for c in algo_main_cols: df_proc[c] = df_proc[c].apply(clean_val)
                        m_keys = list(zip(*[df_proc[c] for c in algo_main_cols]))
                    else: m_keys = [('All',) for _ in range(len(df_proc))]

                    ex_keys_list = []
                    for cfg in ex_configs:
                        if not cfg['cols']:
                            ex_keys_list.append([[] for _ in range(len(df_proc))])
                            continue
                            
                        if cfg['mode'] == 'simple':
                            keys = df_proc.apply(lambda r: collect_values_from_cols(r, cfg['cols']), axis=1).tolist()
                        else:
                            for c in cfg['cols']: df_proc[c] = df_proc[c].apply(clean_val)
                            tuples = list(zip(*[df_proc[c] for c in cfg['cols']]))
                            keys = [[t] for t in tuples]
                        ex_keys_list.append(keys)

                    target_total = sum(main_map.values())
                    soft_target = target_total - tol
                    
                    # Score Calculation
                    m_cnt = collections.Counter(m_keys)
                    if use_main:
                        score_main = np.array([m_cnt.get(k,0)/main_map.get(k,1) if main_map.get(k,0)>0 else 999 for k in m_keys])
                    else:
                        score_main = np.ones(len(df_proc))

                    score_extras = np.zeros(len(df_proc))
                    for j, cfg in enumerate(ex_configs):
                        if not cfg['cols']: continue
                        all_vals = []
                        for keys in ex_keys_list[j]: all_vals.extend(keys)
                        ex_cnt_total = collections.Counter(all_vals)
                        row_scores = []
                        ex_map = cfg['map']
                        for keys in ex_keys_list[j]:
                            if not keys: row_scores.append(1.0); continue
                            s_vals = []
                            for k in keys:
                                if k in ex_map and ex_map[k] > 0: s_vals.append(ex_cnt_total[k] / ex_map[k])
                                else: s_vals.append(999)
                            row_scores.append(min(s_vals))
                        score_extras += np.array(row_scores)
                    
                    final_scarcity_scores = score_main + score_extras
                    
                    # Parallel
                    ipc = max(1, iters // n_cores)
                    res = Parallel(n_jobs=-1, backend="threading")(delayed(simulation_worker)(
                        i, ipc, df_proc.index.to_numpy(), final_scarcity_scores, m_keys, ex_keys_list, main_map, [c['map'] for c in ex_configs], soft_target
                    ) for i in range(n_cores))
                    
                    g_best_cnt = 0; g_best_idxs = []
                    for c, ixs in res:
                        if c > g_best_cnt: g_best_cnt=c; g_best_idxs=ixs

                is_fail = g_best_cnt < soft_target
                
                # -------------------------------------------------------------
                # ì—‘ì…€ ë°ì´í„° ë° ë¶„ì„ ì¤€ë¹„
                # -------------------------------------------------------------
                fin_idxs = list(g_best_idxs)
                m_keys_map = {idx: k for idx, k in zip(df_proc.index, m_keys)}
                ex_keys_maps = [{idx: k for idx, k in zip(df_proc.index, k_list)} for k_list in ex_keys_list]
                
                final_m = collections.Counter()
                final_exs = [collections.Counter() for _ in range(len(ex_configs))]
                clean_fin_idxs = [int(idx) for idx in fin_idxs]
                
                for idx in clean_fin_idxs:
                    final_m[m_keys_map[idx]] += 1
                    for j, cfg in enumerate(ex_configs):
                        if cfg['cols']:
                            for k in ex_keys_maps[j][idx]: final_exs[j][k] += 1

                recs = []
                # ë¶€ì¡±ë¶„ ë¶„ì„ (ì—‘ì…€ìš©)
                if is_fail:
                    if use_main:
                        for k, tgt in main_map.items():
                            act = final_m.get(k, 0); diff = tgt - act
                            if diff > 0: 
                                raw_avail = m_cnt.get(k, 0)
                                reason = "âš ï¸ ë¬¼ë¦¬ì  ë¶€ì¡±" if raw_avail < tgt else "âš”ï¸ ê²½í•© ë¶€ì¡±"
                                recs.append({'ìˆœì„œ': 0, 'êµ¬ë¶„': 'ë©”ì¸ ì¿¼í„°', 'í•­ëª©': " / ".join(k), 'ëª©í‘œ': tgt, 'í˜„ì¬': act, 'ë¶€ì¡±': diff, 'ì§„ë‹¨': reason, 'ì „ì²´ë³´ìœ ': raw_avail})
                    
                    for j, cfg in enumerate(ex_configs):
                        if cfg['cols']:
                            all_vals_raw = []
                            for keys in ex_keys_list[j]: all_vals_raw.extend(keys)
                            raw_cnt_map = collections.Counter(all_vals_raw)
                            for k, tgt in cfg['map'].items():
                                act = final_exs[j].get(k, 0); diff = tgt - act
                                if diff > 0: 
                                    raw_avail = raw_cnt_map.get(k, 0)
                                    reason = "âš ï¸ ë¬¼ë¦¬ì  ë¶€ì¡±" if raw_avail < tgt else "âš”ï¸ ê²½í•© ë¶€ì¡±"
                                    display_item = " / ".join(k) if isinstance(k, tuple) else k
                                    recs.append({'ìˆœì„œ': j+1, 'êµ¬ë¶„': cfg['name'], 'í•­ëª©': display_item, 'ëª©í‘œ': tgt, 'í˜„ì¬': act, 'ë¶€ì¡±': diff, 'ì§„ë‹¨': reason, 'ì „ì²´ë³´ìœ ': raw_avail})

                # [ì¤‘ìš” ë³€ê²½] ì—‘ì…€ ë°ì´í„° ìƒì„± ì‹œ ì •ë ¬ ê¸°ì¤€ ë³€ê²½
                df_survey['Chk'] = "ì œì™¸"
                df_survey.loc[clean_fin_idxs, 'Chk'] = "í†µê³¼"
                
                # ì‹œíŠ¸1: Result_All (ì „ì²´ ë°ì´í„°)
                # ì˜¤í•´ ë°©ì§€ë¥¼ ìœ„í•´ 'ID' ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œë§Œ ì •ë ¬í•©ë‹ˆë‹¤. (í†µê³¼/ì œì™¸ê°€ ì„ì—¬ì„œ ë‚˜ì˜´ -> ì‚­ì œ ì•ˆ ëœ ê²ƒ í™•ì¸ ê°€ëŠ¥)
                df_all = df_survey.sort_values(by=c_no, ascending=True)
                
                # ì‹œíŠ¸2: Result_Pass (í†µê³¼ ë°ì´í„°ë§Œ)
                # 'í†µê³¼'ì¸ í–‰ë§Œ ë½‘ì•„ì„œ ë³„ë„ë¡œ ì €ì¥
                df_pass = df_survey[df_survey['Chk'] == "í†µê³¼"].sort_values(c_no, ascending=True)
                
                out = io.BytesIO()
                with pd.ExcelWriter(out, engine='xlsxwriter') as w:
                    # ì „ì²´ ë°ì´í„° (ì„ì—¬ìˆìŒ)
                    df_all.to_excel(w, index=False, sheet_name='Result_All')
                    # í†µê³¼ ë°ì´í„° (ê¹”ë”í•¨)
                    df_pass.to_excel(w, index=False, sheet_name='Result_Pass')
                    
                    if recs: 
                        df_excel = pd.DataFrame(recs)
                        df_excel['sort_val'] = df_excel['í•­ëª©'].apply(lambda x: tuple(natural_key(x)))
                        df_excel = df_excel.sort_values(by=['ìˆœì„œ', 'sort_val'], ascending=[True, True])
                        df_excel.drop(columns=['ìˆœì„œ', 'sort_val']).to_excel(w, index=False, sheet_name='Shortage_Analysis')
                    
                    if use_main:
                            pd.DataFrame([{'G':str(k), 'T':v, 'A':final_m[k]} for k,v in main_map.items()]).to_excel(w, sheet_name='Main_Status')

                    for j, cfg in enumerate(ex_configs):
                        if cfg['cols']:
                            data_e = []
                            for k, t in cfg['map'].items():
                                k_str = " / ".join(k) if isinstance(k, tuple) else k
                                data_e.append({'Value': k_str, 'Target': t, 'Actual': final_exs[j][k], 'Diff': t - final_exs[j][k]})
                            pd.DataFrame(data_e).sort_values('Value', key=lambda c: c.map(natural_key)).to_excel(w, sheet_name=cfg['name'], index=False)
                
                # -------------------------------------------------------------
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ë° ê²€ì¦ ë©”ì‹œì§€
                # -------------------------------------------------------------
                st.divider()
                st.subheader("ğŸ“Š í• ë‹¹ ê²°ê³¼ ì‹œê°í™”")
                
                # [NEW] ë°ì´í„° ê²€ì¦ ë©”ì‹œì§€
                total_rows = len(df_survey)
                pass_rows = len(df_pass)
                exclude_rows = total_rows - pass_rows
                st.info(f"ğŸ’¾ **ë°ì´í„° ì €ì¥ ì™„ë£Œ**: ì´ **{total_rows:,}ëª…** (í†µê³¼ {pass_rows:,}ëª… + ì œì™¸ {exclude_rows:,}ëª…)ì´ ì—‘ì…€ì— ëª¨ë‘ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                btn_label = "ğŸ“¥ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (Result.xlsx)" if not is_fail else "âš ï¸ ì‹¤íŒ¨í•œ ê²°ê³¼ë¼ë„ ë‹¤ìš´ë¡œë“œ"
                st.download_button(btn_label, out.getvalue(), "result.xlsx", type="primary", use_container_width=True)
                
                # ìƒë‹¨ ë©”íŠ¸ë¦­
                rate = (g_best_cnt / target_total) * 100
                c1, c2, c3 = st.columns(3)
                c1.metric("ğŸ“Œ ì „ì²´ ëª©í‘œ", f"{target_total:,}ëª…")
                c2.metric("âœ… ë§¤ì¹­ ì„±ê³µ", f"{g_best_cnt:,}ëª…")
                delta_color = "normal" if not is_fail else "inverse"
                c3.metric("ğŸ“ˆ ë‹¬ì„±ë¥ ", f"{rate:.1f}%", delta=f"{g_best_cnt - target_total}ëª…" if is_fail else "ëª©í‘œ ë‹¬ì„±", delta_color=delta_color)

                if is_fail:
                    st.error("âš ï¸ ëª©í‘œ ì¸ì›ì„ ë‹¬ì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                else:
                    st.success("ğŸ‰ ëª©í‘œ ì¸ì›ì„ ëª¨ë‘ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!")
                
                st.markdown("### ğŸ” ì¿¼í„°ë³„ ìƒì„¸ í˜„í™©")
                
                active_ex_cfgs = [(j, cfg) for j, cfg in enumerate(ex_configs) if cfg['cols']]
                v_tabs = st.tabs(["ë©”ì¸ ì¿¼í„°"] + [cfg['name'] for _, cfg in active_ex_cfgs])
                
                with v_tabs[0]:
                    if use_main:
                        data_m = []
                        for k, tgt in main_map.items():
                            k_str = " / ".join(k)
                            act = final_m[k]
                            data_m.append({'Label': k_str, 'Type': '1.ëª©í‘œ', 'Value': tgt})
                            data_m.append({'Label': k_str, 'Type': '2.ë‹¬ì„±', 'Value': act})
                        
                        if data_m:
                            df_chart_m = pd.DataFrame(data_m)
                            df_chart_m['sort_val'] = df_chart_m['Label'].apply(lambda x: tuple(natural_key(x)))
                            df_chart_m = df_chart_m.sort_values('sort_val')
                            sorted_labels = df_chart_m['Label'].unique().tolist()
                            
                            chart_data = df_chart_m.drop(columns=['sort_val'])
                            chart = alt.Chart(chart_data).mark_bar().encode(
                                y=alt.Y('Label:N', axis=alt.Axis(title=None), sort=sorted_labels),
                                x=alt.X('Value:Q', axis=alt.Axis(title='ì¸ì›ìˆ˜')),
                                color=alt.Color('Type:N', scale=alt.Scale(domain=['1.ëª©í‘œ', '2.ë‹¬ì„±'], range=['#e0e0e0', '#4c78a8']), legend=alt.Legend(title="êµ¬ë¶„")),
                                yOffset='Type:N'
                            ).properties(height=max(300, len(main_map)*25))
                            st.altair_chart(chart, use_container_width=True)
                    else:
                        st.info("ë©”ì¸ ì¿¼í„° ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")

                for idx, (j, cfg) in enumerate(active_ex_cfgs):
                    with v_tabs[idx + 1]:
                        data_e = []
                        for k, tgt in cfg['map'].items():
                            k_str = " / ".join(k) if isinstance(k, tuple) else k
                            act = final_exs[j][k]
                            data_e.append({'Label': k_str, 'Type': '1.ëª©í‘œ', 'Value': tgt})
                            data_e.append({'Label': k_str, 'Type': '2.ë‹¬ì„±', 'Value': act})
                        
                        if data_e:
                            df_chart_e = pd.DataFrame(data_e)
                            df_chart_e['sort_val'] = df_chart_e['Label'].apply(lambda x: tuple(natural_key(x)))
                            df_chart_e = df_chart_e.sort_values('sort_val')
                            sorted_labels_e = df_chart_e['Label'].unique().tolist()
                            
                            chart_data_e = df_chart_e.drop(columns=['sort_val'])
                            chart = alt.Chart(chart_data_e).mark_bar().encode(
                                y=alt.Y('Label:N', axis=alt.Axis(title=None), sort=sorted_labels_e),
                                x=alt.X('Value:Q', axis=alt.Axis(title='ì¸ì›ìˆ˜')),
                                color=alt.Color('Type:N', scale=alt.Scale(domain=['1.ëª©í‘œ', '2.ë‹¬ì„±'], range=['#e0e0e0', '#4c78a8']), legend=alt.Legend(title="êµ¬ë¶„")),
                                yOffset='Type:N'
                            ).properties(height=max(300, len(cfg['map'])*25))
                            st.altair_chart(chart, use_container_width=True)
                
                if recs:
                    st.divider()
                    st.subheader("ğŸ“‰ ë¶€ì¡± ì¿¼í„° ë¶„ì„ ë° ì§„ë‹¨")
                    df_recs = pd.DataFrame(recs)
                    df_recs['sort_val'] = df_recs['í•­ëª©'].apply(lambda x: tuple(natural_key(x)))
                    df_recs = df_recs.sort_values(by=['ìˆœì„œ', 'sort_val'], ascending=[True, True])
                    st.dataframe(df_recs.drop(columns=['ìˆœì„œ', 'sort_val']), use_container_width=True, hide_index=True)

            except Exception as e: st.error("ì˜¤ë¥˜ ë°œìƒ"); st.code(traceback.format_exc())

# ==============================================================================
# APP MODE 3: SPSS ë³€ìˆ˜ëª… ì •ì œ (ìˆ˜ì •ë¨: ì¤‘ë³µ ë³€ìˆ˜ëª…ì— ìë™ ë²ˆí˜¸ ë¶€ì—¬)
# ==============================================================================
elif app_mode == "ğŸ› ï¸ 3. SPSS ë³€ìˆ˜ëª… ì •ì œ":
    st.header("ğŸ“Š SPSS ë³€ìˆ˜ëª… ìë™ ì •ì œ & ì‹ í…ìŠ¤ ìƒì„±")
    st.markdown("""
    **Raw ë°ì´í„°**ì™€ **Codeë¶**ì„ ë¹„êµí•˜ì—¬ SPSS ë³€ìˆ˜ëª… ë³€ê²½ ì‹ í…ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    * **Codeë¶ ê·œì¹™:** 1ì—´=ë³€ìˆ˜ëª…(Q1), **2ì—´=ì§ˆë¬¸ë¼ë²¨(SQ1. ì„±ë³„...)**
    * **ê¸°ëŠ¥ 1:** ë¼ë²¨ì˜ ì•ë¶€ë¶„(SQ1)ì„ ì¶”ì¶œí•˜ì—¬ ë³€ìˆ˜ëª…ìœ¼ë¡œ ìë™ ë³€í™˜
    * **ê¸°ëŠ¥ 2:** ì²™ë„ ë¬¸í•­ ë“±ìœ¼ë¡œ ë³€ìˆ˜ëª…ì´ ì¤‘ë³µë  ê²½ìš°, ìë™ìœ¼ë¡œ `_1`, `_2`, `_3`ì„ ë¶™ì—¬ì„œ êµ¬ë¶„
    """)
    
    # 1. íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼(.xlsx) ì—…ë¡œë“œ", type=["xlsx"], key="spss_file_uploader")
    
    if uploaded_file:
        try:
            # ì—‘ì…€ íŒŒì¼ ë¡œë“œ ë° ì‹œíŠ¸ëª… í™•ì¸
            xl = pd.ExcelFile(uploaded_file)
            sheet_names = xl.sheet_names
            
            # ì‹œíŠ¸ ì„ íƒ UI
            col1, col2 = st.columns(2)
            with col1:
                raw_sheet = st.selectbox("Raw ë°ì´í„° ì‹œíŠ¸", sheet_names, index=0, key="raw_sheet_select")
            with col2:
                # ë³´í†µ Codeë¶ì€ ë’¤ìª½ì— ìˆìœ¼ë¯€ë¡œ ìë™ ì„ íƒ ì‹œë„
                code_idx = 2 if len(sheet_names) > 2 else (1 if len(sheet_names) > 1 else 0)
                code_sheet = st.selectbox("Codeë¶ ì‹œíŠ¸", sheet_names, index=code_idx, key="code_sheet_select")
            
            # ë¶„ì„ ì‹œì‘ ë²„íŠ¼
            if st.button("ë¶„ì„ ì‹œì‘", key="analyze_btn"):
                with st.spinner('ë°ì´í„° ë¶„ì„ ë° ë§¤ì¹­ ì¤‘...'):
                    # ë°ì´í„°í”„ë ˆì„ ë¡œë“œ
                    df_raw = pd.read_excel(uploaded_file, sheet_name=raw_sheet)
                    # [ìˆ˜ì •] header=None ì˜µì…˜ ì¶”ê°€: ì²« ë²ˆì§¸ ì¤„(Q1)ë„ ë°ì´í„°ë¡œ ì½ê¸° ìœ„í•´
                    df_code = pd.read_excel(uploaded_file, sheet_name=code_sheet, header=None)
                    
                    # Raw ë°ì´í„° ì»¬ëŸ¼ ë§¤í•‘ (ì†Œë¬¸ì -> ì›ë³¸)
                    raw_cols_map = {str(col).strip().lower(): str(col).strip() for col in df_raw.columns}
                    
                    temp_vars = []
                    
                    # --- [Step 1] Codeë¶ ìˆœíšŒ (ë¬´ì¡°ê±´ 1, 2ì—´ ì‚¬ìš©) ---
                    for idx, row in df_code.iterrows():
                        if len(row) < 2: continue
                        if pd.isna(row.iloc[0]): continue
                        
                        col_a_val = clean_text(row.iloc[0]) # ë³€ìˆ˜ëª… (Code) - ì˜ˆ: Q1
                        col_c_val = clean_text(row.iloc[1]) # ì§ˆë¬¸ ë¼ë²¨ - ì˜ˆ: SQ1. ì„±ë³„
                        
                        if not col_a_val: continue
                        
                        # [í•µì‹¬] ë¼ë²¨ì—ì„œ ê¸°ë³¸ ì´ë¦„ ì¶”ì¶œ (ì˜ˆ: "SQ1. ì„±ë³„" -> "SQ1")
                        label_base = extract_base_name(col_c_val)
                        if not label_base: 
                            label_base = col_a_val # ì‹¤íŒ¨ ì‹œ Codeëª… ì‚¬ìš©

                        # [ìŠ¤ë§ˆíŠ¸ ë§¤ì¹­ ë¡œì§]
                        # 1. ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
                        if col_a_val.lower() in raw_cols_map:
                            raw_original = raw_cols_map[col_a_val.lower()]
                            new_var_name = sanitize_var_name(label_base)
                            
                            temp_vars.append({
                                "Raw ë³€ìˆ˜ëª…": raw_original,
                                "Code ë³€ìˆ˜ëª…": col_a_val,
                                "ì§ˆë¬¸ ë‚´ìš©": col_c_val,
                                "ë³€ê²½í•  ë³€ìˆ˜ëª…": new_var_name,
                                "ìƒíƒœ": "ë§¤ì¹­ ì„±ê³µ"
                            })

                        # 2. ë³µìˆ˜ì‘ë‹µ/ì„¸íŠ¸ ë¬¸í•­ íƒìƒ‰ (ì˜ˆ: Q5 -> q5_1, q5_2...)
                        prefix = col_a_val.lower() + "_"
                        found_multiples = []
                        for rc_lower, rc_original in raw_cols_map.items():
                            if rc_lower.startswith(prefix):
                                found_multiples.append((rc_lower, rc_original))
                        
                        # ì°¾ì€ ë³µìˆ˜ì‘ë‹µ ì»¬ëŸ¼ë“¤ ì¶”ê°€
                        for _, rc_original in found_multiples:
                            # ì ‘ë¯¸ì‚¬ ì¶”ì¶œ
                            suffix = rc_original[len(col_a_val):] 
                            if not suffix.startswith('_') and not suffix.startswith('-'):
                                suffix = "_" + suffix

                            # ë¼ë²¨ ê¸°ë°˜ ì´ë¦„ + ì ‘ë¯¸ì‚¬
                            new_name = sanitize_var_name(label_base + suffix)
                            
                            temp_vars.append({
                                "Raw ë³€ìˆ˜ëª…": rc_original,
                                "Code ë³€ìˆ˜ëª…": col_a_val,
                                "ì§ˆë¬¸ ë‚´ìš©": col_c_val,
                                "ë³€ê²½í•  ë³€ìˆ˜ëª…": new_name,
                                "ìƒíƒœ": "ë§¤ì¹­ ì„±ê³µ (ì„¸íŠ¸)"
                            })

                    # --- [Step 2] ì¤‘ë³µ ë³€ìˆ˜ëª… ì²˜ë¦¬ ë¡œì§ (ì¶”ê°€ë¨) ---
                    # 1. ë¨¼ì € ìƒì„±ëœ ëª¨ë“  ë³€ìˆ˜ëª…ì˜ ë¹ˆë„ìˆ˜ë¥¼ ì²´í¬
                    name_freq = collections.Counter([item['ë³€ê²½í•  ë³€ìˆ˜ëª…'] for item in temp_vars])
                    
                    # 2. ì¤‘ë³µ ì¹´ìš´í„° ì¤€ë¹„
                    name_counter = collections.defaultdict(int)
                    
                    final_data = []
                    seen_raw = set()
                    
                    # 3. ë¦¬ìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ ëŒë©´ì„œ ì¤‘ë³µì¸ ê²½ìš° ë²ˆí˜¸ ë¶€ì—¬
                    for item in temp_vars:
                        # ì´ë¯¸ ì²˜ë¦¬í•œ Raw ë³€ìˆ˜ëŠ” íŒ¨ìŠ¤
                        if item['Raw ë³€ìˆ˜ëª…'] in seen_raw: continue
                        
                        candidate_name = item['ë³€ê²½í•  ë³€ìˆ˜ëª…']
                        
                        # ì¤‘ë³µì´ ë°œìƒí•˜ëŠ” ì´ë¦„ì¸ ê²½ìš°ì—ë§Œ ë²ˆí˜¸ ë¶™ì„ (ë‹¨ë…ì€ ê·¸ëŒ€ë¡œ)
                        if name_freq[candidate_name] > 1:
                            name_counter[candidate_name] += 1
                            # _1, _2 ... ìˆœì„œëŒ€ë¡œ ë¶™ì„
                            final_name = f"{candidate_name}_{name_counter[candidate_name]}"
                        else:
                            final_name = candidate_name
                            
                        item['ë³€ê²½í•  ë³€ìˆ˜ëª…'] = final_name
                        final_data.append(item)
                        seen_raw.add(item['Raw ë³€ìˆ˜ëª…'])

                    # --- [Step 3] ë§¤ì¹­ ì‹¤íŒ¨ í•­ëª© ì°¾ê¸° ---
                    for raw_col in df_raw.columns:
                        raw_col_str = str(raw_col).strip()
                        
                        # [ìˆ˜ì •] NO, ID ë“± ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ì€ ì‹¤íŒ¨ ëª©ë¡ì—ì„œ ì œì™¸
                        if raw_col_str.lower() in ['no', 'id', 'ë²ˆí˜¸', 'ìˆœë²ˆ']: continue
                        
                        if raw_col_str not in seen_raw:
                            final_data.append({
                                "Raw ë³€ìˆ˜ëª…": raw_col_str,
                                "Code ë³€ìˆ˜ëª…": "-",
                                "ì§ˆë¬¸ ë‚´ìš©": "-",
                                "ë³€ê²½í•  ë³€ìˆ˜ëª…": "", 
                                "ìƒíƒœ": "ë§¤ì¹­ ì‹¤íŒ¨ (í™•ì¸ í•„ìš”)"
                            })
                    
                    st.session_state['spss_result_df'] = pd.DataFrame(final_data)
                    st.session_state['spss_file_name'] = uploaded_file.name.split('.')[0]
                    st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ í‘œì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                    
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.code(traceback.format_exc())

    # 2. ê²°ê³¼ í™•ì¸ ë° ìˆ˜ì • ì—ë””í„°
    if 'spss_result_df' in st.session_state:
        st.markdown("---")
        st.markdown("### 2. ê²°ê³¼ í™•ì¸ ë° ìˆ˜ì •")
        st.info("ğŸ’¡ **'ë³€ê²½í•  ë³€ìˆ˜ëª…'** ì»¬ëŸ¼ì„ ë”ë¸”í´ë¦­í•˜ì—¬ ì§ì ‘ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        edited_df = st.data_editor(
            st.session_state['spss_result_df'],
            column_config={
                "ìƒíƒœ": st.column_config.TextColumn("ìƒíƒœ", disabled=True),
                "Raw ë³€ìˆ˜ëª…": st.column_config.TextColumn(disabled=True),
                "Code ë³€ìˆ˜ëª…": st.column_config.TextColumn(disabled=True),
                "ì§ˆë¬¸ ë‚´ìš©": st.column_config.TextColumn(disabled=True),
            },
            use_container_width=True,
            height=600,
            hide_index=True,
            key="data_editor"
        )
        
        # 3. ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        st.markdown("---")
        st.markdown("### 3. íŒŒì¼ ë‚´ë³´ë‚´ê¸°")
        
        c1, c2 = st.columns(2)
        
        with c1:
            if st.button("ğŸ“¥ SPSS Syntax ìƒì„± (.sps)", key="gen_syntax_btn"):
                sps_lines = []
                sps_lines.append(f"* Auto Generated Syntax for {st.session_state['spss_file_name']}.")
                sps_lines.append(f"GET FILE='{st.session_state['spss_file_name']}.sav'.")
                sps_lines.append("RENAME VARIABLES")
                
                count = 0
                for _, row in edited_df.iterrows():
                    old_v = str(row['Raw ë³€ìˆ˜ëª…']).strip()
                    new_v = str(row['ë³€ê²½í•  ë³€ìˆ˜ëª…']).strip()
                    
                    if old_v and new_v and (old_v.lower() != new_v.lower()):
                        sps_lines.append(f"  ({old_v} = {new_v})")
                        count += 1
                        
                sps_lines.append(".")
                sps_lines.append("EXECUTE.")
                sps_lines.append(f"SAVE OUTFILE='{st.session_state['spss_file_name']}_Renamed.sav'.")
                sps_lines.append("EXECUTE.")
                
                final_sps = "\n".join(sps_lines)
                
                st.download_button(
                    label="ğŸ“„ Syntax íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                    data=final_sps,
                    file_name=f"{st.session_state['spss_file_name']}_Rename.sps",
                    mime="text/plain"
                )
                st.success(f"ì´ {count}ê°œì˜ ë³€ìˆ˜ ë³€í™˜ êµ¬ë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

        with c2:
            csv_buffer = io.BytesIO()
            edited_df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“„ ë§¤í•‘ í…Œì´ë¸”(CSV) ë‹¤ìš´ë¡œë“œ",
                data=csv_buffer,
                file_name=f"{st.session_state['spss_file_name']}_Mapping.csv",
                mime="text/csv"
            )
